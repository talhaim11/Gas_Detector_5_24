{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "313516a3",
   "metadata": {},
   "source": [
    "# Flame AI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9254875e",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "003caa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import colorsys\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6cb528",
   "metadata": {},
   "source": [
    "## Contour Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed6a8fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def ensure_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def merge_contours(contours, max_distance=70):\n",
    "    merged_contours = []\n",
    "    used = [False] * len(contours)\n",
    "\n",
    "    def get_centroid(contour):\n",
    "        M = cv2.moments(contour)\n",
    "        if M['m00'] == 0:\n",
    "            return None\n",
    "        return (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "\n",
    "    for i, c1 in enumerate(contours):\n",
    "        if used[i]:\n",
    "            continue\n",
    "        merged = [c1]\n",
    "        centroid1 = get_centroid(c1)\n",
    "        if centroid1 is None:\n",
    "            continue\n",
    "        for j, c2 in enumerate(contours):\n",
    "            if i != j and not used[j]:\n",
    "                centroid2 = get_centroid(c2)\n",
    "                if centroid2 is None:\n",
    "                    continue\n",
    "                dist = np.linalg.norm(np.array(centroid1) - np.array(centroid2))\n",
    "                if dist < max_distance:\n",
    "                    merged.append(c2)\n",
    "                    used[j] = True\n",
    "        merged = np.vstack(merged)\n",
    "        merged_contours.append(merged)\n",
    "        used[i] = True\n",
    "\n",
    "    return merged_contours\n",
    "\n",
    "def extract_features(frame):\n",
    "    img = frame[:, :, 1]  # Use the green channel for analysis\n",
    "    # Apply masking to the edges of the frame to avoid edge effects\n",
    "    img[0:40, :] = 0\n",
    "    img[frame.shape[0] - 21:frame.shape[0] - 1, :] = 0\n",
    "    img[:, 0:40] = 0\n",
    "    img[:, frame.shape[1] - 21:frame.shape[1] - 1] = 0\n",
    "\n",
    "    # Apply binary thresholding and morphological operations to clean up the image\n",
    "    _, B2 = cv2.threshold(img, 60, 255, cv2.THRESH_BINARY)\n",
    "    B2 = cv2.morphologyEx(B2, cv2.MORPH_CLOSE, np.ones((10, 10)))\n",
    "\n",
    "    # Find and merge contours\n",
    "    contours, _ = cv2.findContours(B2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = merge_contours(contours)\n",
    "\n",
    "    features = {}\n",
    "    for contour_id, c in enumerate(contours, start=1):\n",
    "        if cv2.contourArea(c) > 100:\n",
    "            rect = cv2.minAreaRect(c)\n",
    "            center, size, angle = rect\n",
    "            width, height = size\n",
    "            area = width * height\n",
    "            contour_area = cv2.contourArea(c)\n",
    "\n",
    "            # Calculate the area ratio\n",
    "            area_ratio = contour_area / area if area != 0 else 0\n",
    "\n",
    "            features[f'centerX_{contour_id}'] = center[0]\n",
    "            features[f'centerY_{contour_id}'] = center[1]\n",
    "            features[f'width_{contour_id}'] = width\n",
    "            features[f'height_{contour_id}'] = height\n",
    "            features[f'angle_{contour_id}'] = angle\n",
    "            features[f'rect_area_{contour_id}'] = area\n",
    "            features[f'contour_area_{contour_id}'] = contour_area\n",
    "            features[f'area_ratio_{contour_id}'] = area_ratio  # Add the new feature\n",
    "\n",
    "    return features, B2, contours\n",
    "\n",
    "def match_contours(previous_contours, current_contours, max_distance=50):\n",
    "    matches = {}\n",
    "    used = [False] * len(previous_contours)\n",
    "\n",
    "    def get_centroid(contour):\n",
    "        M = cv2.moments(contour)\n",
    "        if M['m00'] == 0:\n",
    "            return None\n",
    "        return (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "\n",
    "    for i, current_contour in enumerate(current_contours):\n",
    "        current_centroid = get_centroid(current_contour)\n",
    "        if current_centroid is None:\n",
    "            continue\n",
    "\n",
    "        best_match_index = None\n",
    "        best_match_distance = max_distance\n",
    "\n",
    "        for j, previous_contour in enumerate(previous_contours):\n",
    "            if used[j]:\n",
    "                continue\n",
    "\n",
    "            previous_centroid = get_centroid(previous_contour)\n",
    "            if previous_centroid is None:\n",
    "                continue\n",
    "\n",
    "            distance = np.linalg.norm(np.array(current_centroid) - np.array(previous_centroid))\n",
    "\n",
    "            if distance < best_match_distance:\n",
    "                best_match_distance = distance\n",
    "                best_match_index = j\n",
    "\n",
    "        if best_match_index is not None:\n",
    "            matches[i] = best_match_index\n",
    "            used[best_match_index] = True\n",
    "\n",
    "    return matches\n",
    "\n",
    "def process_video(video_path):\n",
    "    logger.info(f\"Processing video: {video_path}\")\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    all_features = []\n",
    "    frame_count = 0\n",
    "\n",
    "    # Create a window for display.\n",
    "    cv2.namedWindow(\"Video Preview\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "    previous_contours = []\n",
    "    object_id_map = {}\n",
    "    next_object_id = 1\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        frame_features, B2, current_contours = extract_features(frame)\n",
    "        \n",
    "        matches = match_contours(previous_contours, current_contours)\n",
    "        new_object_id_map = {}\n",
    "        \n",
    "        for current_index, contour in enumerate(current_contours):\n",
    "            if current_index in matches:\n",
    "                previous_index = matches[current_index]\n",
    "                object_id = object_id_map[previous_index]\n",
    "            else:\n",
    "                object_id = next_object_id\n",
    "                next_object_id += 1\n",
    "            \n",
    "            new_object_id_map[current_index] = object_id\n",
    "\n",
    "            rect = cv2.minAreaRect(contour)\n",
    "            center, size, angle = rect\n",
    "            width, height = size\n",
    "            area = width * height\n",
    "            contour_area = cv2.contourArea(contour)\n",
    "            area_ratio = contour_area / area if area != 0 else 0\n",
    "\n",
    "            frame_features[f'centerX_{object_id}'] = center[0]\n",
    "            frame_features[f'centerY_{object_id}'] = center[1]\n",
    "            frame_features[f'width_{object_id}'] = width\n",
    "            frame_features[f'height_{object_id}'] = height\n",
    "            frame_features[f'angle_{object_id}'] = angle\n",
    "            frame_features[f'rect_area_{object_id}'] = area\n",
    "            frame_features[f'contour_area_{object_id}'] = contour_area\n",
    "            frame_features[f'area_ratio_{object_id}'] = area_ratio\n",
    "\n",
    "        previous_contours = current_contours\n",
    "        object_id_map = new_object_id_map\n",
    "        all_features.append(frame_features)\n",
    "\n",
    "        # Draw each contour on the frame\n",
    "        for contour in current_contours:\n",
    "            color = (0, 255, 0)  # Green color for contours\n",
    "            cv2.drawContours(frame, [contour], -1, color, 2)\n",
    "\n",
    "        # Display the frame with contours\n",
    "        cv2.imshow(\"Video Preview\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  # Allow exit with 'q'\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    df = pd.DataFrame(all_features)\n",
    "    return df\n",
    "\n",
    "def process_all_videos(video_folder):\n",
    "    for file in os.listdir(video_folder):\n",
    "        if file.endswith('.mp4'):\n",
    "            video_path = os.path.join(video_folder, file)\n",
    "            start_time = time.time()\n",
    "            features = process_video(video_path)\n",
    "            end_time = time.time()\n",
    "            processing_time = end_time - start_time\n",
    "\n",
    "            logger.info(f\"Processed {file} in {processing_time:.2f} seconds\")\n",
    "\n",
    "            if not features.empty:\n",
    "                csv_file_path = os.path.join(video_folder, f\"{os.path.splitext(file)[0]}_features.csv\")\n",
    "                features.to_csv(csv_file_path, index=False)\n",
    "                logger.info(f\"Features saved to {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9e0d52",
   "metadata": {},
   "source": [
    "## Vector Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5009b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_csv(file_path, output_dir):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Drop rows where all elements are NaN\n",
    "    df = df.dropna(how='all')\n",
    "    \n",
    "    # Define the window size and overlap\n",
    "    window_size = 20\n",
    "    overlap = 19\n",
    "\n",
    "    # Create a directory for the current CSV's output\n",
    "    base_filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    current_output_dir = os.path.join(output_dir, base_filename)\n",
    "    if not os.path.exists(current_output_dir):\n",
    "        os.makedirs(current_output_dir)\n",
    "    \n",
    "    # Process each column\n",
    "    for column in df.columns:\n",
    "        # Drop NaN values from the column\n",
    "        clean_data = df[column].dropna().reset_index(drop=True)\n",
    "        \n",
    "        # Slide window through the data\n",
    "        num_windows = len(clean_data) - window_size + 1\n",
    "        for start in range(num_windows):\n",
    "            end = start + window_size\n",
    "            window_data = clean_data[start:end]\n",
    "            \n",
    "            # Normalize the data in the window except for 'area_ratio'\n",
    "            if column != 'area_ratio':\n",
    "                max_value = window_data.max()\n",
    "                normalized_data = window_data / max_value if max_value > 0 else window_data\n",
    "                vector_file_name = f\"{column}_vector_{start}.csv\"\n",
    "            else:\n",
    "                # For 'area_ratio', just pass the data as is without normalization\n",
    "                normalized_data = window_data\n",
    "                vector_file_name = f\"ratio_vector_{start}.csv\"  # Custom file name for 'area_ratio'\n",
    "            \n",
    "            # Save the window data to a CSV file\n",
    "            vector_file_path = os.path.join(current_output_dir, vector_file_name)\n",
    "            normalized_data.to_csv(vector_file_path, index=False, header=False)\n",
    "\n",
    "def process_all_csvs(input_dir, output_dir):\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Process each CSV file in the directory\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(input_dir, file_name)\n",
    "            process_csv(file_path, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5b9d81",
   "metadata": {},
   "source": [
    "## Labeled Data CSV Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d1804d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data_from_folder(folder_path):\n",
    "    data_frames = []\n",
    "    parameters = {\n",
    "        'area_ratio': 1,\n",
    "        'contour_area': 2,\n",
    "        'rect_area': 3,\n",
    "        'angle': 8,\n",
    "        'height': 4,\n",
    "        'width': 5,\n",
    "        'centerX': 6,\n",
    "        'centerY': 7\n",
    "    }\n",
    "    \n",
    "    for parameter, label in parameters.items():\n",
    "        print(f\"Loading files for parameter: {parameter}\")\n",
    "        \n",
    "        # Initialize tqdm progress bar\n",
    "        parameter_files = [filename for filename in os.listdir(folder_path) if parameter in filename]\n",
    "        for filename in tqdm(parameter_files, desc=f\"Processing {parameter} files\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "            \n",
    "            # Ensure we have 20 data points per file\n",
    "            if len(df) != 20:\n",
    "                raise ValueError(f\"File {filename} does not have 20 data points.\")\n",
    "            \n",
    "            df = df.T  # Transpose the DataFrame\n",
    "            df.columns = [f'value_{i}' for i in range(1, 21)]\n",
    "            df['label'] = label\n",
    "            data_frames.append(df)\n",
    "\n",
    "    combined_df = pd.concat(data_frames, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "def prepare_data(folder_path):\n",
    "    # Load data\n",
    "    df = load_data_from_folder(folder_path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba93e50",
   "metadata": {},
   "source": [
    "## Main code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f63cad3",
   "metadata": {},
   "source": [
    "### Creating Full CSV From Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c932c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "log_file_path = r\"C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\process_08_07_experiment.log\"\n",
    "logger = logging.getLogger(\"FlameDetector\")\n",
    "logger.setLevel(logging.INFO)\n",
    "handler = RotatingFileHandler(log_file_path, maxBytes=5*1024*1024, backupCount=2)  # 5 MB per file, max 2 files\n",
    "formatter = logging.Formatter('%(asctime)s:%(levelname)s:%(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "\n",
    "video_folder = r\"C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\videos for train\\code_check\"\n",
    "process_all_videos(video_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a988a89b",
   "metadata": {},
   "source": [
    "### Creating Vectors For Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbe5688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify the directory paths\n",
    "input_csv_folder = r\"C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\videos for train\\interrupt_for_ai_machine\"\n",
    "output_vectors_dir = r\"C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\videos for train after code\\Interrupt_Objects\"\n",
    "\n",
    "# Process all CSV files in the specified directory\n",
    "process_all_csvs(input_csv_folder, output_vectors_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced22f06",
   "metadata": {},
   "source": [
    "### Creating Prepared Data File With Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24b10e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: area_ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing area_ratio files: 100%|██████████| 47/47 [00:00<00:00, 497.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: contour_area\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing contour_area files: 100%|██████████| 47/47 [00:00<00:00, 558.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: rect_area\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rect_area files: 100%|██████████| 47/47 [00:00<00:00, 553.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: angle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing angle files: 100%|██████████| 47/47 [00:00<00:00, 545.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: height\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing height files: 100%|██████████| 47/47 [00:00<00:00, 680.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: width\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing width files: 100%|██████████| 47/47 [00:00<00:00, 702.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: centerX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing centerX files: 100%|██████████| 47/47 [00:00<00:00, 747.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: centerY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing centerY files: 100%|██████████| 47/47 [00:00<00:00, 710.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved prepared data to C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\videos for train after code\\Interrupt_Objects\\fire_1_features_prepared_data.csv\n",
      "Loading files for parameter: area_ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing area_ratio files: 100%|██████████| 234/234 [00:00<00:00, 566.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: contour_area\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing contour_area files: 100%|██████████| 234/234 [00:00<00:00, 334.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: rect_area\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rect_area files: 100%|██████████| 234/234 [00:00<00:00, 684.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: angle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing angle files: 100%|██████████| 234/234 [00:00<00:00, 551.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: height\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing height files: 100%|██████████| 234/234 [00:00<00:00, 756.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: width\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing width files: 100%|██████████| 234/234 [00:00<00:00, 700.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: centerX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing centerX files: 100%|██████████| 234/234 [00:00<00:00, 712.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: centerY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing centerY files: 100%|██████████| 234/234 [00:00<00:00, 600.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved prepared data to C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\videos for train after code\\Interrupt_Objects\\fire_2_features_prepared_data.csv\n",
      "Loading files for parameter: area_ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing area_ratio files: 100%|██████████| 365/365 [00:00<00:00, 769.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: contour_area\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing contour_area files: 100%|██████████| 365/365 [00:00<00:00, 621.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: rect_area\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rect_area files: 100%|██████████| 365/365 [00:00<00:00, 548.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: angle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing angle files: 100%|██████████| 365/365 [00:00<00:00, 673.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: height\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing height files: 100%|██████████| 365/365 [00:00<00:00, 715.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: width\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing width files: 100%|██████████| 365/365 [00:00<00:00, 454.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: centerX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing centerX files: 100%|██████████| 365/365 [00:00<00:00, 671.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: centerY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing centerY files: 100%|██████████| 365/365 [00:00<00:00, 676.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved prepared data to C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\videos for train after code\\Interrupt_Objects\\fire_3_features_prepared_data.csv\n",
      "Loading files for parameter: area_ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing area_ratio files: 100%|██████████| 330/330 [00:00<00:00, 649.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: contour_area\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing contour_area files: 100%|██████████| 330/330 [00:00<00:00, 619.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: rect_area\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rect_area files: 100%|██████████| 330/330 [00:00<00:00, 752.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: angle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing angle files: 100%|██████████| 330/330 [00:00<00:00, 587.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: height\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing height files: 100%|██████████| 330/330 [00:00<00:00, 559.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: width\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing width files: 100%|██████████| 330/330 [00:00<00:00, 549.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: centerX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing centerX files: 100%|██████████| 330/330 [00:00<00:00, 558.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: centerY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing centerY files: 100%|██████████| 330/330 [00:00<00:00, 393.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved prepared data to C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\videos for train after code\\Interrupt_Objects\\fire_4_features_prepared_data.csv\n",
      "Loading files for parameter: area_ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing area_ratio files: 100%|██████████| 790/790 [00:01<00:00, 522.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: contour_area\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing contour_area files: 100%|██████████| 790/790 [00:01<00:00, 556.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: rect_area\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rect_area files: 100%|██████████| 790/790 [00:01<00:00, 647.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: angle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing angle files: 100%|██████████| 790/790 [00:01<00:00, 590.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: height\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing height files: 100%|██████████| 790/790 [00:01<00:00, 540.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: width\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing width files: 100%|██████████| 790/790 [00:01<00:00, 496.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: centerX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing centerX files: 100%|██████████| 790/790 [00:01<00:00, 546.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: centerY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing centerY files: 100%|██████████| 790/790 [00:01<00:00, 462.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved prepared data to C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\videos for train after code\\Interrupt_Objects\\fire_5_features_prepared_data.csv\n",
      "Loading files for parameter: area_ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing area_ratio files: 100%|██████████| 223/223 [00:00<00:00, 569.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: contour_area\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing contour_area files: 100%|██████████| 223/223 [00:00<00:00, 526.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: rect_area\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rect_area files: 100%|██████████| 223/223 [00:00<00:00, 455.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: angle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing angle files: 100%|██████████| 223/223 [00:00<00:00, 512.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: height\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing height files: 100%|██████████| 223/223 [00:00<00:00, 533.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: width\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing width files: 100%|██████████| 223/223 [00:00<00:00, 565.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: centerX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing centerX files: 100%|██████████| 223/223 [00:00<00:00, 447.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files for parameter: centerY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing centerY files: 100%|██████████| 223/223 [00:00<00:00, 536.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved prepared data to C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\videos for train after code\\Interrupt_Objects\\fire_6_features_prepared_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folders = [\n",
    "    r\"C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\videos for train after code\\fire_1_features\",\n",
    "    r\"C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\videos for train after code\\fire_2_features\",\n",
    "    r\"C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\videos for train after code\\fire_3_features\",\n",
    "    r\"C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\videos for train after code\\fire_4_features\",\n",
    "    r\"C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\videos for train after code\\fire_5_features\",\n",
    "    r\"C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\videos for train after code\\fire_6_features\",\n",
    "]\n",
    "\n",
    "# Output directory for saving CSV files\n",
    "output_dir = r\"C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\videos for train after code\\Interrupt_Objects\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each folder and prepare data\n",
    "for folder_path in folders:\n",
    "    # Prepare data\n",
    "    prepared_df = prepare_data(folder_path)\n",
    "    \n",
    "    # Extract folder name to use in the output file name\n",
    "    folder_name = os.path.basename(folder_path)\n",
    "    \n",
    "    # Define the output file path\n",
    "    output_file = os.path.join(output_dir, f\"{folder_name}_prepared_data.csv\")\n",
    "    \n",
    "    # Save prepared data to CSV\n",
    "    prepared_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Print a message indicating completion\n",
    "    print(f\"Saved prepared data to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76713ad8",
   "metadata": {},
   "source": [
    "## Test codes\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
