{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "313516a3",
   "metadata": {},
   "source": [
    "# Flame AI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9254875e",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "003caa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import colorsys\n",
    "import sys\n",
    "import os\n",
    "import imageio\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import closing, square\n",
    "from skimage.measure import label, regionprops\n",
    "#from utils.util_scripts import is_intersection\n",
    "import logging\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6cb528",
   "metadata": {},
   "source": [
    "### Contour Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed6a8fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###########BEST###################\n",
    "\n",
    "# Initialize plot\n",
    "plt.ion()\n",
    "fig, ax = plt.subplots()\n",
    "areas = []\n",
    "line, = ax.plot([], [])\n",
    "\n",
    "def merge_contours(contours, max_distance=70):\n",
    "    merged_contours = []\n",
    "    used = [False] * len(contours)\n",
    "\n",
    "    def get_centroid(contour):\n",
    "        M = cv2.moments(contour)\n",
    "        if M['m00'] == 0:\n",
    "            return None\n",
    "        return (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "\n",
    "    for i, c1 in enumerate(contours):\n",
    "        if used[i]:\n",
    "            continue\n",
    "        merged = [c1]\n",
    "        centroid1 = get_centroid(c1)\n",
    "        if centroid1 is None:\n",
    "            continue\n",
    "        for j, c2 in enumerate(contours):\n",
    "            if i != j and not used[j]:\n",
    "                centroid2 = get_centroid(c2)\n",
    "                if centroid2 is None:\n",
    "                    continue\n",
    "                dist = np.linalg.norm(np.array(centroid1) - np.array(centroid2))\n",
    "                if dist < max_distance:  # Merge if within max_distance\n",
    "                    merged.append(c2)\n",
    "                    used[j] = True\n",
    "        merged = np.vstack(merged)\n",
    "        merged_contours.append(merged)\n",
    "        used[i] = True\n",
    "\n",
    "    return merged_contours\n",
    "\n",
    "def extract_features(frame):\n",
    "    img = frame[:, :, 1]\n",
    "    img[0:40, :] = 0\n",
    "    img[frame.shape[0] - 21:frame.shape[0] - 1, :] = 0\n",
    "    img[:, 0:40] = 0\n",
    "    img[:, frame.shape[1] - 21:frame.shape[1] - 1] = 0\n",
    "\n",
    "    _, B2 = cv2.threshold(img, 60, 255, cv2.THRESH_BINARY)\n",
    "    B2 = cv2.morphologyEx(B2, cv2.MORPH_CLOSE, np.ones((10, 10)))\n",
    "\n",
    "    contours, _ = cv2.findContours(B2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Merge contours that are close to each other\n",
    "    contours = merge_contours(contours)\n",
    "\n",
    "    features = {}\n",
    "    for contour_id, c in enumerate(contours, start=1):\n",
    "        if cv2.contourArea(c) > 100:\n",
    "            rect = cv2.minAreaRect(c)\n",
    "            center, size, angle = rect\n",
    "            width, height = size\n",
    "            area = width * height\n",
    "\n",
    "            features[f'centerX_{contour_id}'] = center[0]\n",
    "            features[f'centerY_{contour_id}'] = center[1]\n",
    "            features[f'width_{contour_id}'] = width\n",
    "            features[f'height_{contour_id}'] = height\n",
    "            features[f'angle_{contour_id}'] = angle\n",
    "            features[f'area_{contour_id}'] = area\n",
    "\n",
    "    return features, B2, contours\n",
    "\n",
    "def update_plot(frame_area):\n",
    "    areas.append(frame_area)\n",
    "    line.set_xdata(range(len(areas)))\n",
    "    line.set_ydata(areas)\n",
    "    ax.relim()\n",
    "    ax.autoscale_view()\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "\n",
    "def process_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    all_features = []\n",
    "    max_contours = 0\n",
    "    contour_ids = {}\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_features, B2, contours = extract_features(frame)\n",
    "        current_ids = {}\n",
    "\n",
    "        for contour_id, c in enumerate(contours, start=1):\n",
    "            rect = cv2.minAreaRect(c)\n",
    "            center, size, angle = rect\n",
    "            width, height = size\n",
    "            area = width * height\n",
    "            centroid = (int(center[0]), int(center[1]))\n",
    "\n",
    "            # Match contours with existing IDs\n",
    "            matched = False\n",
    "            for existing_id, existing_centroid in contour_ids.items():\n",
    "                if np.linalg.norm(np.array(existing_centroid) - np.array(centroid)) < 50:  # Distance threshold\n",
    "                    current_ids[existing_id] = centroid\n",
    "                    frame_features[f'centerX_{existing_id}'] = center[0]\n",
    "                    frame_features[f'centerY_{existing_id}'] = center[1]\n",
    "                    frame_features[f'width_{existing_id}'] = width\n",
    "                    frame_features[f'height_{existing_id}'] = height\n",
    "                    frame_features[f'angle_{existing_id}'] = angle\n",
    "                    frame_features[f'area_{existing_id}'] = area\n",
    "                    matched = True\n",
    "                    break\n",
    "\n",
    "            if not matched:\n",
    "                new_id = max(contour_ids.keys(), default=0) + 1\n",
    "                current_ids[new_id] = centroid\n",
    "                frame_features[f'centerX_{new_id}'] = center[0]\n",
    "                frame_features[f'centerY_{new_id}'] = center[1]\n",
    "                frame_features[f'width_{new_id}'] = width\n",
    "                frame_features[f'height_{new_id}'] = height\n",
    "                frame_features[f'angle_{new_id}'] = angle\n",
    "                frame_features[f'area_{new_id}'] = area\n",
    "\n",
    "        contour_ids = current_ids\n",
    "        max_contours = max(max_contours, len(contours))\n",
    "        all_features.append(frame_features)\n",
    "\n",
    "        # Draw the contours\n",
    "        for contour_id in contour_ids.keys():\n",
    "            center_x = frame_features.get(f'centerX_{contour_id}')\n",
    "            center_y = frame_features.get(f'centerY_{contour_id}')\n",
    "            width = frame_features.get(f'width_{contour_id}')\n",
    "            height = frame_features.get(f'height_{contour_id}')\n",
    "            angle = frame_features.get(f'angle_{contour_id}')\n",
    "\n",
    "            if center_x is not None and center_y is not None and width is not None and height is not None and angle is not None:\n",
    "                box = cv2.boxPoints(((center_x, center_y), (width, height), angle))\n",
    "                box = np.intp(box)\n",
    "                frame = cv2.drawContours(frame, [box], 0, (255, 0, 0), 2)\n",
    "\n",
    "        # Show the frame with bounding boxes\n",
    "        cv2.imshow(\"preview\", frame)\n",
    "        if len(frame_features) > 0:\n",
    "            total_area = sum((frame_features.get(f'width_{i+1}', 0) or 0) * (frame_features.get(f'height_{i+1}', 0) or 0)for i in range(max_contours))\n",
    "            update_plot(total_area)\n",
    "\n",
    "        k = cv2.waitKey(30) & 0xFF\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Ensure all possible contour columns are present in every frame\n",
    "    for frame in all_features:\n",
    "        for contour_id in range(1, max_contours + 1):\n",
    "            for feature in ['centerX', 'centerY', 'width', 'height', 'angle', 'area']:\n",
    "                frame.setdefault(f'{feature}_{contour_id}', None)\n",
    "\n",
    "    return all_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba93e50",
   "metadata": {},
   "source": [
    "# Main code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c932c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the video and get the feature vectors\n",
    "movie_path = r\"C:\\Users\\thaim\\OneDrive\\Desktop\\Tal_Projects\\Gas_detector\\General_Codes\\Gas_Detector_5_24\\Flame_train_AI\\Flame_AI_test_video_2 - edit.mp4\"\n",
    "features = process_video(movie_path)\n",
    "\n",
    "# Convert the flattened features to a DataFrame\n",
    "df = pd.DataFrame(features)\n",
    "\n",
    "# Save the DataFrame to a CSV file for later use\n",
    "df.to_csv(\"fire_detection_features_corrected.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e41cf59",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2792770",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FL_SIZE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39msgd, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m---> 15\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAI_model_Temporal_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m     18\u001b[0m reduce_lr_acc \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[52], line 4\u001b[0m, in \u001b[0;36mAI_model_Temporal_1\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mAI_model_Temporal_1\u001b[39m():\n\u001b[0;32m      3\u001b[0m     model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[1;32m----> 4\u001b[0m         Dense(\u001b[38;5;241m20\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[43mFL_SIZE\u001b[49m,)),\n\u001b[0;32m      5\u001b[0m         Dropout(\u001b[38;5;241m0.1\u001b[39m),\n\u001b[0;32m      6\u001b[0m         Dense(\u001b[38;5;241m10\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      7\u001b[0m         Dense(\u001b[38;5;241m5\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      8\u001b[0m         Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m     ])\n\u001b[0;32m     11\u001b[0m     sgd \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.003\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[0;32m     12\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39msgd, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'FL_SIZE' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Neural Network Model\n",
    "def AI_model_Temporal_1():\n",
    "    model = Sequential([\n",
    "        Dense(20, activation=\"relu\", input_shape=(FL_SIZE,)),\n",
    "        Dropout(0.1),\n",
    "        Dense(10, activation=\"relu\"),\n",
    "        Dense(5, activation=\"relu\"),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    sgd = keras.optimizers.SGD(learning_rate=0.003, momentum=0.9)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = AI_model_Temporal_1()\n",
    "model.summary()\n",
    "\n",
    "reduce_lr_acc = ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode='max')\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=10, mode='max')\n",
    "callbacks = [earlyStopping, reduce_lr_acc]\n",
    "\n",
    "# Assuming X_train2 and Y_train are defined and preprocessed\n",
    "# history = model.fit(X_train2, Y_train, batch_size=10, epochs=25, validation_split=0.2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6b7cd3",
   "metadata": {},
   "source": [
    "## Load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddab79e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "flame1=(np.load('flame_1.npy'))\n",
    "nflame1=(np.load('not_flame_1.npy'))\n",
    "\n",
    "flame2=(np.load('flame_2.npy'))\n",
    "nflame2=(np.load('not_flame_2.npy'))\n",
    "\n",
    "flame3=(np.load('flame_3.npy'))\n",
    "\n",
    "flame_set=np.concatenate((flame1,flame2))\n",
    "flame_set=np.concatenate((flame_set,flame3))\n",
    "\n",
    "\n",
    "Not_flame_set=np.concatenate((nflame1,nflame2))\n",
    "Not_flame_set=np.concatenate((Not_flame_set,not_flame_array))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a02da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "flame_set.shape\n",
    "flame_label=np.ones(flame_set.shape[0])\n",
    "Not_flame_label=np.zeros(Not_flame_set.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2ebe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.concatenate((flame_set,Not_flame_set))\n",
    "Y_train=np.concatenate((flame_label,Not_flame_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdb28bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range (X_train.shape[0]):\n",
    "    X_train2[i,:]=X_train[i,:]/np.max(X_train[i,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93da7db",
   "metadata": {},
   "source": [
    "## AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17da14a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "#from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22288c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4927d036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  רשת א\n",
    "\n",
    "def AI_model_Temporal_1():   # U\n",
    "    #Create Model\n",
    "    model = keras.models.Sequential([keras.Input(shape=(FL_SIZE,)),\n",
    "                                 keras.layers.Dense(20, activation=\"relu\"),\n",
    "                                 keras.layers.Dropout(.1),\n",
    "                                 keras.layers.Dense(10, activation=\"relu\"),\n",
    "                                 keras.layers.Dense(5, activation=\"relu\"),\n",
    "                                 keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    \n",
    "\n",
    "    sgd=keras.optimizers.SGD(learning_rate=0.003, momentum=0.9, nesterov=False, name=\"SGD\")\n",
    "    adam=keras.optimizers.Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.99,epsilon=1e-07,amsgrad=False,name=\"Adam\",)\n",
    "    Binary_crossentropy=keras.losses.BinaryCrossentropy( from_logits=False, label_smoothing=0.5,axis=-1,reduction=\"auto\",name=\"Binary_crossentropy\",)\n",
    "    \n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=sgd,metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd04db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=AI_model_Temporal_1()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb31b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr_acc = ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode='max')\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=10, verbose=0, mode='max')\n",
    "callbacks=[earlyStopping,reduce_lr_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67bb16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(X_train2, Y_train,batch_size=10, epochs=25,validation_split=0.2,shuffle='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506aad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5)) \n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) #  set  the  vertical  range  to  [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec5e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('Temporal_Model_A_weights_V5.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52219835",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e410b9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##SAGI'S PROGRAM##\n",
    "cap=cv2.VideoCapture(movie_path)\n",
    "\n",
    "\n",
    "\n",
    "frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "img_counter=0\n",
    "FL_SIZE=30\n",
    "max_leng=0\n",
    "max_wid=0\n",
    "CENTER=[]\n",
    "LEFT=[]\n",
    "#CENTER2=[]\n",
    "av_cen=[]\n",
    "av_factor=10\n",
    "WID=[]\n",
    "centroid_x=[]\n",
    "m00=[]\n",
    "m10=[]\n",
    "not_flame=[]\n",
    "flame=[]\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "not_flame_array=[]\n",
    "flame_array=[]\n",
    "sample_size=30\n",
    "textAI='None'\n",
    "textAI1='None'\n",
    "col=(255,0,0)\n",
    "col1=(255,0,0)\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    #frame = fgbg.apply(frame) \n",
    "    img=frame[:,:,1]\n",
    "    img[0:40, :] = 0\n",
    "    img[frameHeight - 21:frameHeight - 1, :] = 0\n",
    "    img[:, 0:40] = 0\n",
    "    img[:, frameWidth - 21:frameWidth - 1] = 0\n",
    "    thresh, B2 = cv2.threshold(img, 60, 255, cv2.THRESH_BINARY)\n",
    "    B2 = cv.morphologyEx(B2, cv.MORPH_CLOSE, np.ones((200, 200)))\n",
    "    \n",
    "\n",
    "    \n",
    "    conturs, hierachy = cv2.findContours(B2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #cv.drawContours(frame, conturs, -1, (0,255,0), 3)\n",
    "    con_id=0\n",
    "\n",
    "    if conturs:\n",
    "        for c in conturs:\n",
    "        #c = max(conturs, key = cv2.contourArea)\n",
    "            con_id=con_id+1\n",
    "            \n",
    "            top_point = (np.min(c[:, :, 0]), np.min(c[:, :, 1]))\n",
    "            bottom_point = (np.max(c[:, :, 0]), np.max(c[:, :, 1]))\n",
    "            box_im=B2[np.min(c[:, :, 1]):np.max(c[:, :, 1]),np.min(c[:, :, 0]):np.max(c[:, :, 0])]\n",
    "            leng=np.max(c[:, :, 0])-np.min(c[:, :, 0])\n",
    "            wid=np.max(c[:, :, 1])-np.min(c[:, :, 1])\n",
    "            BSIZE=leng*wid\n",
    "        \n",
    "#             B4=img.copy() \n",
    "#             B4=cv.drawContours(B4, c, -1, (255,0,0), 1)\n",
    "            if (BSIZE>50):\n",
    "                M = cv2.moments(B2)\n",
    "                cX = int(M[\"m10\"]/ M[\"m00\"])\n",
    "                cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        \n",
    "                CX=cX#+np.min(c[:, :, 0])\n",
    "                m00.append(int(M[\"m00\"]))\n",
    "                m10.append(int(M[\"m10\"]))\n",
    "            \n",
    "            \n",
    "                B3=img.copy() \n",
    "                #frame = cv2.rectangle(frame, top_point,bottom_point, (255,0,0), 2)\n",
    "                img=frame[:,:]\n",
    "                center=np.min(c[:, :, 0])+0.5*(np.max(c[:, :, 0])-np.min(c[:, :, 0]))\n",
    "                if center<200 :\n",
    "                    not_flame.append(BSIZE)\n",
    "                    if len(not_flame)>FL_SIZE:\n",
    "                        input1=not_flame[-1*FL_SIZE:]\n",
    "                        input1=input1/np.max(input1)\n",
    "                        input2=np.expand_dims(input1, axis=0)\n",
    "                        AI_output=(model.predict(input2))\n",
    "                        AI_output=np.round(AI_output)[0][0]\n",
    "                        if AI_output==1:\n",
    "                            textAI='Fire'\n",
    "                            col=(0,0,255)\n",
    "                        if AI_output==0:\n",
    "                            textAI='Not Fire'\n",
    "                            col=(0,255,0)\n",
    "                    image = cv2.putText(frame, textAI, bottom_point,  cv2.FONT_HERSHEY_SIMPLEX,1, col, 2, cv2.LINE_AA)\n",
    "                        \n",
    "                    \n",
    "                if center >200:\n",
    "    \n",
    "                    flame.append(BSIZE)\n",
    "                    if len(flame)>FL_SIZE:\n",
    "                        input1=flame[-1*FL_SIZE:]\n",
    "                        input1=input1/np.max(input1)\n",
    "                        input2=np.expand_dims(input1, axis=0)\n",
    "                        AI_output=(model.predict(input2))\n",
    "                        AI_output=np.round(AI_output)[0][0]\n",
    "                        if AI_output==1:\n",
    "                            textAI1='Fire'\n",
    "                            col1=(0,0,255)\n",
    "                        if AI_output==0:\n",
    "                            textAI1='Not Fire'\n",
    "                            col1=(0,255,0)\n",
    "                        image = cv2.putText(frame, textAI1, bottom_point,  cv2.FONT_HERSHEY_SIMPLEX,1, col1, 2, cv2.LINE_AA)\n",
    "                        \n",
    "                \n",
    "            \n",
    "                text= str(BSIZE)+'center:'+str(center) #str(leng)+' X '+str(wid)\n",
    "                \n",
    "    \n",
    "    prv = cv2.resize(B2, (1280, 960))\n",
    "    cv2.imshow(\"preview\",frame)\n",
    "        \n",
    "    k = cv.waitKey(30) & 0xff55\n",
    "    if k == 27:\n",
    "        break\n",
    "    dbc=img_counter%4\n",
    "    img_counter=img_counter+1\n",
    "    #if img_counter==100:\n",
    "    #    break\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
