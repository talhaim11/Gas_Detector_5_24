{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36e773a9",
   "metadata": {},
   "source": [
    "# Loading&Preprocessing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8348ddd9",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66140ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6cb528",
   "metadata": {},
   "source": [
    "## Image Processing - raw data from videos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6a8fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image processing\n",
    "\n",
    "\n",
    "def ensure_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def convert_to_binary(frame, threshold=60):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray[:125, :] = 0  # Ignore the top 40 pixels\n",
    "    _, binary = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)\n",
    "    return binary\n",
    "\n",
    "def merge_close_contours(contours, min_distance=70, max_area_ratio_diff=0.7):\n",
    "    merged_contours = []\n",
    "    used = [False] * len(contours)\n",
    "    \n",
    "    def get_centroid(contour):\n",
    "        M = cv2.moments(contour)\n",
    "        if M['m00'] == 0:\n",
    "            return None\n",
    "        return (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "    \n",
    "    for i, c1 in enumerate(contours):\n",
    "        if used[i]:\n",
    "            continue\n",
    "        merged = [c1]\n",
    "        centroid1 = get_centroid(c1)\n",
    "        if centroid1 is None:\n",
    "            continue\n",
    "        area1 = cv2.contourArea(c1)\n",
    "        for j, c2 in enumerate(contours):\n",
    "            if i != j and not used[j]:\n",
    "                centroid2 = get_centroid(c2)\n",
    "                if centroid2 is None:\n",
    "                    continue\n",
    "                dist = np.linalg.norm(np.array(centroid1) - np.array(centroid2))\n",
    "                area2 = cv2.contourArea(c2)\n",
    "                area_ratio_diff = abs(area1 - area2) / max(area1, area2)\n",
    "                \n",
    "                # Merge only if the contours are close and have a similar area\n",
    "                if dist < min_distance and area_ratio_diff < max_area_ratio_diff:\n",
    "                    merged.append(c2)\n",
    "                    used[j] = True\n",
    "        merged_contours.append(np.vstack(merged))\n",
    "        used[i] = True\n",
    "    return merged_contours\n",
    "\n",
    "\n",
    "def extract_contours(binary_frame):\n",
    "    contours, _ = cv2.findContours(binary_frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = merge_close_contours(contours)\n",
    "    return contours\n",
    "\n",
    "def frame_objects(contours):\n",
    "    objects = []\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 10:\n",
    "            rect = cv2.minAreaRect(contour)\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int_(box)  # Recommended NumPy equivalent\n",
    "            center, size, angle = rect\n",
    "            if angle == 0:\n",
    "                angle = 90\n",
    "            rect = (center, size, angle)\n",
    "            objects.append((rect, box, contour))\n",
    "    return objects\n",
    "\n",
    "\n",
    "def calculate_changes(new_object, old_object): # threshold calculations \n",
    "    changes = {}\n",
    "    changes['centerX'] = np.linalg.norm(np.array(new_object[0][0][0]) - np.array(old_object[0][0][0]))\n",
    "    changes['centerY'] = np.linalg.norm(np.array(new_object[0][0][1]) - np.array(old_object[0][0][1]))\n",
    "    changes['width'] = abs(new_object[0][1][0] - old_object[0][1][0])\n",
    "    changes['height'] = abs(new_object[0][1][1] - old_object[0][1][1])\n",
    "    changes['rect_area'] = abs((new_object[0][1][0] * new_object[0][1][1]) - (old_object[0][1][0] * old_object[0][1][1]))\n",
    "    changes['contour_area'] = abs(cv2.contourArea(cv2.convexHull(new_object[2])) - cv2.contourArea(cv2.convexHull(old_object[2])))\n",
    "    return changes\n",
    "\n",
    "def match_objects(objects, previous_objects, thresholds):\n",
    "    matched_objects = {}\n",
    "    for obj_id, (rect, _, contour) in previous_objects.items():\n",
    "        best_match = None\n",
    "        best_match_score = float('inf')\n",
    "        for i, (current_rect, _, current_contour) in enumerate(objects):\n",
    "            if i in matched_objects.values():\n",
    "                continue\n",
    "            current_object = (current_rect, current_rect[1], current_contour)\n",
    "            changes = calculate_changes(current_object, (rect, rect[1], contour))\n",
    "            match_score = 0\n",
    "            for key in changes:\n",
    "                if changes[key] > thresholds[key]:\n",
    "                    match_score += 1\n",
    "            if match_score < best_match_score:\n",
    "                best_match_score = match_score\n",
    "                best_match = i\n",
    "        if best_match is not None and best_match_score == 0:  # All changes are within thresholds\n",
    "            matched_objects[obj_id] = best_match\n",
    "    return matched_objects\n",
    "\n",
    "def save_object_parameters(objects, frame_idx, object_tracker):\n",
    "    features = []\n",
    "    for object_id, (rect, box, _) in object_tracker.items():\n",
    "        center, size, angle = rect\n",
    "        width, height = size\n",
    "        area = width * height\n",
    "        contour_area = cv2.contourArea(cv2.convexHull(box))\n",
    "        area_ratio = contour_area / area if area != 0 else 0\n",
    "\n",
    "        features.append({\n",
    "            'frame': frame_idx,\n",
    "            'object_id': object_id,\n",
    "            'center_x': center[0],\n",
    "            'center_y': center[1],\n",
    "            'width': width,\n",
    "            'height': height,\n",
    "            'angle' : angle,\n",
    "            'rect_area': area,\n",
    "            'contour_area': contour_area,\n",
    "            'area_ratio': area_ratio\n",
    "        })\n",
    "    return features\n",
    "\n",
    "def process_video(video_path, output_csv, thresholds):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "      print(f\"Error: Unable to open video {video_path}\")\n",
    "      return\n",
    "    \n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    all_features = []\n",
    "    object_tracker = {}\n",
    "    next_object_id = 1\n",
    "    history = {}\n",
    "\n",
    "    with tqdm(total=total_frames, desc=\"Processing video frames\") as pbar:\n",
    "        for frame_idx in range(total_frames):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(f\"Error: Unable to read frame {frame_idx} in video {video_path}\")\n",
    "                break\n",
    "            try:\n",
    "                binary_frame = convert_to_binary(frame, thresholds['binary_threshold'])\n",
    "                contours = extract_contours(binary_frame)\n",
    "                objects = frame_objects(contours)\n",
    "            except Exception as e:\n",
    "                print(f\"Error during processing frame {frame_idx}: {e}\")\n",
    "                continue         \n",
    "               \n",
    "            if frame_idx > 0:\n",
    "                matched_objects = match_objects(objects, object_tracker, thresholds)\n",
    "                new_object_tracker = {}\n",
    "                for obj_id, i in matched_objects.items():\n",
    "                    new_object_tracker[obj_id] = objects[i]\n",
    "                    center, size, _ = objects[i][0]\n",
    "                    history[obj_id] = (center, size)\n",
    "                for i, (rect, box, contour) in enumerate(objects):\n",
    "                    if i not in matched_objects.values():\n",
    "                        center, size, _ = rect\n",
    "                        best_match = None\n",
    "                        for hist_id, (hist_center, hist_size) in history.items():\n",
    "                            if np.linalg.norm(np.array(center) - np.array(hist_center)) < thresholds['centerX']:\n",
    "                                if abs((size[0] * size[1]) - (hist_size[0] * hist_size[1])) / (size[0] * size[1]) < thresholds['rect_area']:\n",
    "                                    best_match = hist_id\n",
    "                                    break\n",
    "                        if best_match is not None:\n",
    "                            new_object_tracker[best_match] = (rect, box, contour)\n",
    "                        else:\n",
    "                            new_object_tracker[next_object_id] = (rect, box, contour)\n",
    "                            history[next_object_id] = (center, size)\n",
    "                            next_object_id += 1\n",
    "                object_tracker = new_object_tracker\n",
    "            else:\n",
    "                for i, (rect, box, contour) in enumerate(objects):\n",
    "                    object_tracker[next_object_id] = (rect, box, contour)\n",
    "                    center, size, _ = rect\n",
    "                    history[next_object_id] = (center, size)\n",
    "                    next_object_id += 1\n",
    "\n",
    "            frame_features = save_object_parameters(objects, frame_idx, object_tracker)\n",
    "            all_features.extend(frame_features)\n",
    "\n",
    "            for _, box, _ in objects:\n",
    "                cv2.drawContours(frame, [box], 0, (0, 255, 0), 2)\n",
    "            \n",
    "            cv2.imshow(\"Processed Video\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "            pbar.update(1)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    df = pd.DataFrame(all_features)\n",
    "    df.sort_values(by=['object_id', 'frame'], inplace=True)\n",
    "    output_excel = output_csv.replace('.csv', '.xlsx')\n",
    "    df.to_excel(output_excel, index=False, engine='openpyxl')\n",
    "\n",
    "\n",
    "def process_all_videos(video_folder, output_folder, thresholds):\n",
    "    ensure_dir(output_folder)\n",
    "    for file in os.listdir(video_folder):\n",
    "        if file.endswith('.mp4'):\n",
    "            video_path = os.path.join(video_folder, file)\n",
    "            output_csv = os.path.join(output_folder, f\"{os.path.splitext(file)[0]}_features.csv\")\n",
    "            process_video(video_path, output_csv, thresholds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be80850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main image processing code\n",
    "video_folder = r\"C:\\Users\\thaim\\OneDrive\\Desktop\\דוחות\\test for flame ai\\videos for train\\fire\\regular fire or fire with interference\"\n",
    "output_folder = r\"c:\\Users\\thaim\\OneDrive\\Desktop\\דוחות\\test for flame ai\\videos for train after code\\fire\\regular fire or fire with interference\\test2\"\n",
    "# thresholds = {\n",
    "#     'binary_threshold': 60,\n",
    "#     'centerX': 10,\n",
    "#     'centerY': 10,\n",
    "#     'width': 5,\n",
    "#     'height': 5,\n",
    "#     'rect_area': 50,\n",
    "#     'contour_area': 50\n",
    "# }\n",
    "thresholds = {\n",
    "    'binary_threshold': 60,\n",
    "    'centerX': 20,  # \n",
    "    'centerY': 20,\n",
    "    'width': 10,  # \n",
    "    'height': 10,\n",
    "    'rect_area': 100,  #\n",
    "    'contour_area': 100\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "process_all_videos(video_folder, output_folder, thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2345e80",
   "metadata": {},
   "source": [
    "## Image Preprocessing - Erase unwanted data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce94f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 📌 הגדרת התיקייה שבה נמצאים קובצי ה-CSV שלך\n",
    "input_folder = r\"C:\\Users\\thaim\\OneDrive\\Desktop\\דוחות\\test for flame ai\\videos for train after code\\fire\\regular fire or fire with interference\\test_low_thresh\"  # 🔄 שנה לתיקייה שלך\n",
    "output_folder = os.path.join(input_folder, \"clean data\")\n",
    "param_output_folder = os.path.join(output_folder, \"parameters\")\n",
    "\n",
    "# 📂 יצירת תיקיות פלט אם הן לא קיימות\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(param_output_folder, exist_ok=True)\n",
    "\n",
    "# 🔍 קבלת רשימת כל קובצי ה-CSV בתיקייה\n",
    "csv_files = [f for f in os.listdir(input_folder) if f.endswith(\".csv\")]\n",
    "\n",
    "# 🔥 סף להפרדה (ניתן לשנות בהתאם לצורך)\n",
    "THRESHOLD_X = 50  # שינוי משמעותי ב-CENTER X\n",
    "THRESHOLD_Y = 50  # שינוי משמעותי ב-CENTER Y\n",
    "\n",
    "# 🚀 עיבוד כל קובץ בתיקייה\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(input_folder, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # 1️⃣ מחיקת Bounding Boxes לא תקינים\n",
    "    df_cleaned = df[\n",
    "        (df['width'] >= 5) & \n",
    "        (df['height'] >= 5) & \n",
    "        (df['area_ratio'].between(0.8, 1.2)) & \n",
    "        (df['rect_area'] >= 10) & \n",
    "        (df['contour_area'] >= 10)\n",
    "    ]\n",
    "\n",
    "    # 2️⃣ מחיקת Bounding Boxes קטנים ליד Bounding Box גדול בכל פריים\n",
    "    def filter_small_boxes(group):\n",
    "        max_area = group['rect_area'].max()\n",
    "        return group[group['rect_area'] >= 0.1 * max_area]\n",
    "\n",
    "    df_cleaned = df_cleaned.groupby('frame', group_keys=False).apply(filter_small_boxes)\n",
    "\n",
    "    # 3️⃣ מחיקת אובייקטים שהופיעו בפחות מ-30 פריימים\n",
    "    object_counts = df_cleaned['object_id'].value_counts()\n",
    "    valid_objects = object_counts[object_counts >= 30].index\n",
    "    df_cleaned = df_cleaned[df_cleaned['object_id'].isin(valid_objects)]\n",
    "\n",
    "    # 4️⃣ מחיקת שורות שבהן `center_x` ו-`center_y` לא משתנים בין פריימים (זיהוי הפרעות)\n",
    "    df_cleaned['prev_center_x'] = df_cleaned.groupby('object_id')['center_x'].shift(1)\n",
    "    df_cleaned['prev_center_y'] = df_cleaned.groupby('object_id')['center_y'].shift(1)\n",
    "\n",
    "    df_cleaned = df_cleaned[\n",
    "        (df_cleaned['center_x'] != df_cleaned['prev_center_x']) | \n",
    "        (df_cleaned['center_y'] != df_cleaned['prev_center_y'])\n",
    "    ]\n",
    "\n",
    "    # הסרת העמודות הזמניות\n",
    "    df_cleaned.drop(columns=['prev_center_x', 'prev_center_y'], inplace=True)\n",
    "\n",
    "    # **מיון לפי OBJECT ID תחילה, ולאחר מכן לפי FRAME**\n",
    "    df_cleaned.sort_values(by=['object_id', 'frame'], inplace=True)\n",
    "\n",
    "    # 5️⃣ הוספת שורות ריקות כאשר יש קפיצה גדולה במיקום הלהבה\n",
    "    new_rows = []\n",
    "    prev_row = None\n",
    "\n",
    "    for _, row in df_cleaned.iterrows():\n",
    "        if prev_row is not None:\n",
    "            diff_x = abs(row['center_x'] - prev_row['center_x'])\n",
    "            diff_y = abs(row['center_y'] - prev_row['center_y'])\n",
    "\n",
    "            if diff_x > THRESHOLD_X or diff_y > THRESHOLD_Y:\n",
    "                # הוספת שתי שורות ריקות\n",
    "                new_rows.append(pd.Series([None] * len(row), index=df_cleaned.columns))\n",
    "                new_rows.append(pd.Series([None] * len(row), index=df_cleaned.columns))\n",
    "\n",
    "        new_rows.append(row)\n",
    "        prev_row = row\n",
    "\n",
    "    df_final = pd.DataFrame(new_rows, columns=df_cleaned.columns)\n",
    "\n",
    "    # 6️⃣ שמירת הנתונים הנקיים לקובץ חדש בתיקייה \"clean data\"\n",
    "    cleaned_file_path = os.path.join(output_folder, f\"cleaned_{file}\")\n",
    "    df_final.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "    print(f\"✅ הקובץ '{file}' נשמר לאחר ניקוי בתיקייה: {cleaned_file_path}\")\n",
    "\n",
    "    # 7️⃣ **פיצול הנתונים לכל פרמטר לאחר שהקובץ עבר ניקוי**\n",
    "    for object_id in df_final['object_id'].dropna().unique():\n",
    "        df_obj = df_final[df_final['object_id'] == object_id]\n",
    "\n",
    "        for column in ['center_x', 'center_y', 'width', 'height', 'angle', 'rect_area', 'contour_area', 'area_ratio']:\n",
    "            df_param = df_obj[['frame', column]].copy()\n",
    "            param_file_path = os.path.join(param_output_folder, f\"{file.replace('.csv', '')}_object_{int(object_id)}_{column}.csv\")\n",
    "            df_param.to_csv(param_file_path, index=False)\n",
    "\n",
    "    print(f\"📂 כל הפרמטרים עבור הקובץ '{file}' נשמרו בתיקייה '{param_output_folder}'.\")\n",
    "\n",
    "print(\"🎉 כל הקבצים בתיקייה עברו ניקוי, פוצלו ונשמרו בתיקיית 'clean data'!\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9e0d52",
   "metadata": {},
   "source": [
    "## Vector Functions - normalized and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d316de76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def normalize_data(df):\n",
    "#     for column in df.columns:\n",
    "#         if column == \"area_ratio\":\n",
    "#             continue\n",
    "#         mean = df[column].mean()\n",
    "#         std = df[column].std()\n",
    "#         if std != 0:\n",
    "#             df[column] = (df[column] - mean) / std\n",
    "#         else:\n",
    "#             df[column] = 0\n",
    "\n",
    "#     return df\n",
    "\n",
    "def normalize_data(df):\n",
    "    for column in df.columns:  # Include all columns for normalization\n",
    "        if column == \"area_ratio\":  # Skip normalization for 'area_ratio'\n",
    "            continue    \n",
    "        min_value = df[column].min()\n",
    "        max_value = df[column].max()\n",
    "        if max_value != min_value:  # Avoid division by zero\n",
    "            df[column] = (df[column] - min_value) / (max_value - min_value)\n",
    "        else:\n",
    "            df[column] = 0  # If min and max are the same, set all entries to zero\n",
    "    return df\n",
    "\n",
    "def process_file(filepath, output_dir):\n",
    "    filename = os.path.basename(filepath)\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    if \"fire\" not in filename.lower():\n",
    "        object_ids = df['object_id'].unique()\n",
    "        for object_id in object_ids:\n",
    "            object_df = df[df['object_id'] == object_id]\n",
    "            process_and_save(object_df, filename, output_dir, object_id, is_fire=False)\n",
    "    else:\n",
    "        process_and_save(df, filename, output_dir, is_fire=True)\n",
    "\n",
    "def process_and_save(df, filename, output_dir, object_id=None, is_fire=False):\n",
    "    window_size = 20\n",
    "    step_size = 5 \n",
    "    folder = \"fire\" if is_fire else \"interrupt\"\n",
    "    folder_path = os.path.join(output_dir, folder)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    for start in range(0, len(df) - window_size + 1, step_size):\n",
    "        window_df = df.iloc[start:start+window_size].copy()\n",
    "        if len(window_df) < window_size:\n",
    "            continue\n",
    "\n",
    "        window_df = window_df.drop(columns=[\"object_id\", \"frame\"])\n",
    "        window_df = window_df.reset_index(drop=True)\n",
    "        window_df = normalize_data(window_df)\n",
    "\n",
    "        output_filename = f\"{filename.split('.')[0]}_object{object_id if object_id is not None else ''}_window{start}.csv\"\n",
    "        output_filepath = os.path.join(folder_path, output_filename)\n",
    "        window_df.to_csv(output_filepath, index=False)\n",
    "\n",
    "def main(input_dir, output_dir):\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                process_file(os.path.join(root, file), output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5b9d81",
   "metadata": {},
   "source": [
    "## Labeled Data CSV Functions - for specific model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1804d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def natural_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "def load_data_from_folder(folder_path):\n",
    "    data_frames = []\n",
    "    parameters = {\n",
    "        'area_ratio': 1,\n",
    "        'contour_area': 2,\n",
    "        'rect_area': 3,\n",
    "        'angle': 4,\n",
    "        'height': 5,\n",
    "        'width': 6,\n",
    "        'centerX': 7,\n",
    "        'centerY': 8\n",
    "    }\n",
    "    \n",
    "    for parameter, label in parameters.items():\n",
    "        print(f\"Loading files for parameter: {parameter}\")\n",
    "        \n",
    "        # Initialize tqdm progress bar\n",
    "        parameter_files = [filename for filename in os.listdir(folder_path) if parameter in filename]\n",
    "        parameter_files.sort(key=natural_sort_key)\n",
    "        \n",
    "        for filename in tqdm(parameter_files, desc=f\"Processing {parameter} files\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "            \n",
    "            # Ensure we have 20 data points per file\n",
    "            if len(df) != 20:\n",
    "                raise ValueError(f\"File {filename} does not have 20 data points.\")\n",
    "            \n",
    "            df = df.T  # Transpose the DataFrame\n",
    "            df.columns = [f'value_{i}' for i in range(1, 21)]\n",
    "            df['label'] = label\n",
    "            data_frames.append(df)\n",
    "\n",
    "    combined_df = pd.concat(data_frames, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "def prepare_data(folder_path):\n",
    "    # Load data\n",
    "    df = load_data_from_folder(folder_path)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba93e50",
   "metadata": {},
   "source": [
    "# Main code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f63cad3",
   "metadata": {},
   "source": [
    "## Creating Full CSV From Videos - calling Image processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c932c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "thresholds = {\n",
    "    'centerX': 120,          # Adjust as needed\n",
    "    'centerY': 120,          # Adjust as needed\n",
    "    'width': 100,            # Adjust as needed\n",
    "    'height': 100,           # Adjust as needed\n",
    "    'rect_area': 400,       # Adjust as needed\n",
    "    'contour_area': 300     # Adjust as needed\n",
    "    }\n",
    "\n",
    "video_folder = r\"C:\\Users\\thaim\\OneDrive\\Desktop\\before done - videos for ai\\fire\"\n",
    "output_folder = r\"C:\\Users\\thaim\\OneDrive\\Desktop\\before done - videos for ai\\fire\\data\"\n",
    "process_all_videos(video_folder, output_folder, thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a988a89b",
   "metadata": {},
   "source": [
    "## Creating Vectors For Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe5688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating vectors for models\n",
    "input_directory = r\"C:\\Users\\thaim\\OneDrive\\Desktop\\before done - videos for ai\\fire\"\n",
    "output_directory = r\"C:\\Users\\thaim\\OneDrive\\Desktop\\before done - videos for ai\\vectors data\"\n",
    "main(input_directory, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced22f06",
   "metadata": {},
   "source": [
    "## Creating Prepared Data File With Labels - for specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b10e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# folders = [\n",
    "#     r\"C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\videos for train after code\\fire_1_features\",\n",
    "#     r\"C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\videos for train after code\\fire_2_features\",\n",
    "#     r\"C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\videos for train after code\\fire_3_features\",\n",
    "#     r\"C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\videos for train after code\\fire_4_features\",\n",
    "#     r\"C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\videos for train after code\\fire_5_features\",\n",
    "#     r\"C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\videos for train after code\\fire_6_features\",   \n",
    "# ]\n",
    "\n",
    "# # Output directory for saving CSV files\n",
    "# output_dir = r\"C:\\Users\\thaim\\OneDrive\\Desktop\\test for flame ai\\videos for train after code\\Interrupt_Objects\"\n",
    "\n",
    "# # Ensure the output directory exists\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # Loop through each folder and prepare data\n",
    "# for folder_path in folders:\n",
    "#     # Prepare data\n",
    "#     prepared_df = prepare_data(folder_path)\n",
    "    \n",
    "#     # Extract folder name to use in the output file name\n",
    "#     folder_name = os.path.basename(folder_path)\n",
    "    \n",
    "#     # Define the output file path\n",
    "#     output_file = os.path.join(output_dir, f\"{folder_name}_prepared_data.csv\")\n",
    "    \n",
    "#     # Save prepared data to CSV\n",
    "#     prepared_df.to_csv(output_file, index=False)\n",
    "    \n",
    "#     # Print a message indicating completion\n",
    "#     print(f\"Saved prepared data to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76713ad8",
   "metadata": {},
   "source": [
    "# Model codes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c40d958",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ed067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Concatenate, Dropout, Lambda\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def load_data(input_dir):\n",
    "    data = []\n",
    "    labels = []\n",
    "    processed_files = 0\n",
    "    skipped_files = 0\n",
    "    expected_shape = (20, 8)\n",
    "\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                df = pd.read_csv(file_path)\n",
    "\n",
    "                if df.shape != expected_shape:  # Validate the shape of the dataframe\n",
    "                    skipped_files += 1\n",
    "                    continue\n",
    "\n",
    "                if \"fire\" in file.lower():\n",
    "                    label = 1  # Fire label\n",
    "                else:\n",
    "                    label = 0  # Disturbance label\n",
    "\n",
    "                # Flatten the dataframe and append to data\n",
    "                flattened_data = df.values.flatten()\n",
    "                if flattened_data.shape[0] == np.prod(expected_shape):\n",
    "                    data.append(flattened_data)\n",
    "                    labels.append(label)\n",
    "                    processed_files += 1\n",
    "                else:\n",
    "                    skipped_files += 1\n",
    "                \n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Original model with improvements\n",
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=input_shape))\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(8, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # 2 classes: fire and disturbance\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Grouped model as alternative\n",
    "def create_grouped_model(input_shape):\n",
    "    inputTensor = Input(shape=input_shape)\n",
    "    \n",
    "    group_layers = []\n",
    "    for i in range(8):\n",
    "        group = Lambda(lambda x: x[:, i*20:(i+1)*20], output_shape=(20,))(inputTensor)\n",
    "        group = Dense(10, activation=\"relu\")(group)\n",
    "        group = Dense(5, activation=\"relu\")(group)\n",
    "        group = Dense(1, activation=\"relu\")(group)\n",
    "        group_layers.append(group)\n",
    "    \n",
    "    outputTensor = Concatenate()(group_layers)\n",
    "    outputTensor = Dense(1, activation='sigmoid')(outputTensor)\n",
    "    \n",
    "    model = Model(inputTensor, outputTensor)\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def main(input_directory, epochs=50, batch_size=32):\n",
    "    data, labels = load_data(input_directory)\n",
    "    \n",
    "    # Reshape data to (number of files, 20 frames * 8 parameters)\n",
    "    num_files = data.shape[0]\n",
    "    data = data.reshape(num_files, 20 * 8)\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Print the shape of the training data\n",
    "    print(f'X_train shape: {X_train.shape}')\n",
    "    \n",
    "    # Choose the model type: create_model or create_grouped_model\n",
    "    input_shape = (20 * 8,)\n",
    "    model = create_model(input_shape)\n",
    "    # model = create_grouped_model(input_shape)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    # Early stopping to prevent overfitting\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])\n",
    "\n",
    "    # Evaluate the model\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "    print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_acc}')\n",
    "    \n",
    "    # Save the model weights\n",
    "    model.save_weights(r\"C:\\Users\\thaim\\OneDrive\\Desktop\\before done - videos for ai\\vectors data\\model_weights.weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a13dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model\n",
    "if __name__ == \"__main__\":\n",
    "    input_directory = r\"C:\\Users\\thaim\\Downloads\\aivideo_20240818_060506_286.mp4\" \n",
    "    main(input_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8ee9ba",
   "metadata": {},
   "source": [
    "## testing model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d21aa",
   "metadata": {},
   "source": [
    "### testing model - with objects differentiate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46811c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing model 2 - ID separated\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from collections import deque\n",
    "\n",
    "# Configurable parameters\n",
    "THRESHOLD_BINARY = 150\n",
    "IGNORE_TOP_PIXELS = 125\n",
    "MIN_CONTOUR_AREA = 0.1\n",
    "MIN_DISTANCE_BETWEEN_CONTOURS = 120\n",
    "MAX_AREA_RATIO_DIFF = 0.7\n",
    "BUFFER_MAXLEN = 20\n",
    "DISAPPEARANCE_THRESHOLD = 10\n",
    "BORDER_THICKNESS = 5\n",
    "LEARNING_RATE = 0.001\n",
    "INPUT_SHAPE_MULTIPLIER = 8\n",
    "PREDICTION_THRESHOLD = 0.8\n",
    "\n",
    "\n",
    "\n",
    "# Initialize a global unique ID counter\n",
    "next_id = 0\n",
    "\n",
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=input_shape))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # 2 classes: fire and disturbance\n",
    "    optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def convert_to_binary(frame, threshold=THRESHOLD_BINARY):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray[:IGNORE_TOP_PIXELS, :] = 0  # Ignore the top pixels\n",
    "    _, binary = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)\n",
    "    return binary\n",
    "\n",
    "def merge_close_contours(contours, min_distance=MIN_DISTANCE_BETWEEN_CONTOURS, max_area_ratio_diff=MAX_AREA_RATIO_DIFF):\n",
    "    merged_contours = []\n",
    "    used = [False] * len(contours)\n",
    "\n",
    "    def get_centroid(contour):\n",
    "        M = cv2.moments(contour)\n",
    "        if M['m00'] == 0:\n",
    "            return None\n",
    "        return (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "\n",
    "    for i, c1 in enumerate(contours):\n",
    "        if used[i]:\n",
    "            continue\n",
    "        merged = [c1]\n",
    "        centroid1 = get_centroid(c1)\n",
    "        if centroid1 is None:\n",
    "            continue\n",
    "        area1 = cv2.contourArea(c1)\n",
    "        for j, c2 in enumerate(contours):\n",
    "            if i != j and not used[j]:\n",
    "                centroid2 = get_centroid(c2)\n",
    "                if centroid2 is None:\n",
    "                    continue\n",
    "                dist = np.linalg.norm(np.array(centroid1) - np.array(centroid2))\n",
    "                area2 = cv2.contourArea(c2)\n",
    "                area_ratio_diff = abs(area1 - area2) / max(area1, area2)\n",
    "\n",
    "                if dist < min_distance and area_ratio_diff < max_area_ratio_diff:\n",
    "                    merged.append(c2)\n",
    "                    used[j] = True\n",
    "        merged_contours.append(np.vstack(merged))\n",
    "        used[i] = True\n",
    "    return merged_contours\n",
    "\n",
    "def extract_contours(binary_frame):\n",
    "    contours, _ = cv2.findContours(binary_frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = merge_close_contours(contours)\n",
    "    return contours\n",
    "\n",
    "def frame_objects(contours, frame_shape):\n",
    "    objects = []\n",
    "    frame_height, frame_width = frame_shape\n",
    "\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > MIN_CONTOUR_AREA:\n",
    "            rect = cv2.minAreaRect(contour)\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int0(box)\n",
    "            center, size, angle = rect\n",
    "            if angle == 0:\n",
    "                angle = 90\n",
    "\n",
    "            if any(point[0] <= BORDER_THICKNESS or point[1] <= BORDER_THICKNESS or \n",
    "                   point[0] >= frame_width - BORDER_THICKNESS or \n",
    "                   point[1] >= frame_height - BORDER_THICKNESS for point in box):\n",
    "                continue\n",
    "\n",
    "            rect = (center, size, angle)\n",
    "            objects.append((rect, box, contour))\n",
    "    return objects\n",
    "\n",
    "def save_object_parameters(objects):\n",
    "    all_features = []\n",
    "    for rect, box, contour in objects:\n",
    "        center, size, angle = rect\n",
    "        width, height = size\n",
    "        area = width * height\n",
    "        contour_area = cv2.contourArea(cv2.convexHull(box))\n",
    "        area_ratio = contour_area / area if area != 0 else 0\n",
    "\n",
    "        features = [\n",
    "            center[0], center[1], width, height, angle,\n",
    "            area, contour_area, area_ratio\n",
    "        ]\n",
    "        all_features.append(features)\n",
    "    return all_features\n",
    "\n",
    "def normalize_features(feature_buffer):\n",
    "    feature_array = np.array(feature_buffer)\n",
    "    normalized_features = feature_array.copy()\n",
    "\n",
    "    # for i in range(8):\n",
    "    #     if i == 7: \n",
    "    #         continue\n",
    "    #     param_values = feature_array[:, i::8]\n",
    "    #     param_mean = param_values.mean()\n",
    "    #     param_std = param_values.std()\n",
    "    #     if param_std != 0:\n",
    "    #         normalized_features[:, i::8] = (param_values - param_mean) / param_std\n",
    "    #     else:\n",
    "    #         normalized_features[:, i::8] = 0\n",
    "\n",
    "    # return normalized_features\n",
    "\n",
    "    for i in range(8):\n",
    "        if i == 7: \n",
    "            continue\n",
    "        param_values = feature_array[:, i::8]\n",
    "        param_min = param_values.min()\n",
    "        param_max = param_values.max()\n",
    "        if param_max != param_min:\n",
    "            normalized_features[:, i::8] = (param_values - param_min) / (param_max - param_min)\n",
    "        else:\n",
    "            normalized_features[:, i::8] = 0\n",
    "\n",
    "    return normalized_features\n",
    "\n",
    "def get_object_key(center, object_buffers, threshold=MIN_DISTANCE_BETWEEN_CONTOURS):\n",
    "    for key, buffer in object_buffers.items():\n",
    "        existing_center = np.array(buffer[-1][:2])\n",
    "        if np.linalg.norm(np.array(center) - existing_center) < threshold:\n",
    "            return key\n",
    "    return None\n",
    "\n",
    "def process_frame(frame, model, frame_counter, object_buffers, last_seen_frame):\n",
    "    global next_id  # Use the global next_id to assign new unique IDs\n",
    "    binary_frame = convert_to_binary(frame)\n",
    "#    cv2.imshow('binary frame', binary_frame)\n",
    "    contours = extract_contours(binary_frame)\n",
    "    objects = frame_objects(contours, frame.shape[:2])\n",
    "\n",
    "    if len(objects) == 0:\n",
    "        return None, []\n",
    "\n",
    "    features = save_object_parameters(objects)\n",
    "\n",
    "    # Append features to the respective object's buffer\n",
    "    for obj_features in features:\n",
    "        if len(obj_features) == 8:\n",
    "            center = obj_features[:2]\n",
    "            key = get_object_key(center, object_buffers)\n",
    "            if key is None:\n",
    "                key = next_id\n",
    "                next_id += 1\n",
    "                object_buffers[key] = deque(maxlen=BUFFER_MAXLEN)\n",
    "            object_buffers[key].append(obj_features)\n",
    "            last_seen_frame[key] = frame_counter\n",
    "\n",
    "    # Make prediction for each object's buffer\n",
    "    predictions = {}\n",
    "    for key, buffer in object_buffers.items():\n",
    "        if len(buffer) == BUFFER_MAXLEN:\n",
    "            normalized_features = normalize_features(list(buffer))            \n",
    "            normalized_features = np.transpose(normalized_features)\n",
    "            normalized_features = normalized_features.flatten().reshape(1, -1)\n",
    "            prediction = model.predict(normalized_features)\n",
    "            predictions[key] = prediction[0][0]\n",
    "\n",
    "    return predictions, objects\n",
    "\n",
    "def draw_tracking_info(frame, object_buffers, predictions):\n",
    "    for key in object_buffers.keys():\n",
    "        buffer = object_buffers[key]\n",
    "        if len(buffer) > 0:\n",
    "            # Use the latest buffer data for drawing\n",
    "            obj_features = buffer[-1]\n",
    "            center_x, center_y, width, height, angle = obj_features[:5]\n",
    "            area, contour_area, area_ratio = obj_features[5:8]\n",
    "\n",
    "            # Calculate the box points from the rectangle parameters\n",
    "            rect = ((center_x, center_y), (width, height), angle)\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int0(box)\n",
    "\n",
    "            # Determine the color based on prediction\n",
    "            color = (0, 255, 0) if predictions.get(key, 0) < PREDICTION_THRESHOLD else (0, 0, 255)\n",
    "            cv2.drawContours(frame, [box], 0, color, 2)\n",
    "            cv2.putText(frame, f\"ID: {key}\", (int(center_x), int(center_y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "            cv2.putText(frame, f\"Pred: {predictions.get(key, 0):.2f}\", (int(center_x), int(center_y) + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "def main(model_path, video_source):\n",
    "    input_shape = (BUFFER_MAXLEN * INPUT_SHAPE_MULTIPLIER,)\n",
    "    model = create_model(input_shape)\n",
    "    model.load_weights(model_path)\n",
    "    time.sleep(0.1)\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video source.\")\n",
    "        return\n",
    "\n",
    "    frame_counter = 0\n",
    "    object_buffers = {}  # Dictionary to store buffers for each object\n",
    "    last_seen_frame = {}  # Dictionary to store the last frame an object was seen\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        time.sleep(0.1)\n",
    "        frame_counter += 1\n",
    "        predictions, _ = process_frame(frame, model, frame_counter, object_buffers, last_seen_frame)\n",
    "        \n",
    "        # Remove objects not seen for 50 frames\n",
    "        keys_to_delete = [key for key, last_frame in last_seen_frame.items() if frame_counter - last_frame > DISAPPEARANCE_THRESHOLD]\n",
    "        for key in keys_to_delete:\n",
    "            print(f\"Deleting object {key} from buffers and last seen frames.\")\n",
    "            del object_buffers[key]\n",
    "            del last_seen_frame[key]\n",
    "\n",
    "        if predictions:\n",
    "            draw_tracking_info(frame, object_buffers, predictions)\n",
    "\n",
    "        cv2.imshow('Real-time Fire Detection', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bf719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = r\"C:\\Users\\thaim\\OneDrive\\Desktop\\before done - videos for ai\\vectors data\\model_weights.weights.h5\"\n",
    "    video_path = r\"C:\\Users\\thaim\\Videos\\Recording 2024-08-18 141852 - IR_LED_1-5hz_5m_crop.mp4\"\n",
    "    main(model_path, video_path)  # Use 0 for webcam, or provide a video file path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
