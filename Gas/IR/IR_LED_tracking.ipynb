{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import deque\n",
    "from scipy.fft import fft\n",
    "import csv\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Configurable parameters\n",
    "THRESHOLD_BINARY = 240\n",
    "IGNORE_TOP_PIXELS = 125\n",
    "MIN_CONTOUR_AREA = 600\n",
    "MAX_CONTOUR_AREA = 1500  # Maximum contour area threshold\n",
    "MIN_DISTANCE_BETWEEN_CONTOURS = 10\n",
    "MAX_AREA_RATIO_DIFF = 0.7\n",
    "BUFFER_MAXLEN = 20\n",
    "DISAPPEARANCE_THRESHOLD = 10\n",
    "BORDER_THICKNESS = 5\n",
    "TOP_BORDER_PERCENTAGE = 0.30  # Ignore top 30% of the frame\n",
    "SIDE_BORDER_PERCENTAGE = 0.30  # Ignore 30% from each side of the frame\n",
    "# Coordinates for the area to crop (x1, y1: top-left, x2, y2: bottom-right)\n",
    "CROP_X1, CROP_Y1 = 50, 50\n",
    "CROP_X2, CROP_Y2 = 600, 600\n",
    "# Resize dimensions (width, height)\n",
    "RESIZE_WIDTH, RESIZE_HEIGHT = 600, 600\n",
    "\n",
    "MIN_CIRCULARITY = 0.7  # Minimum circularity to consider a shape as round\n",
    "\n",
    "# Initialize a global unique ID counter\n",
    "next_id = 0\n",
    "\n",
    "def convert_to_binary(frame, threshold=THRESHOLD_BINARY):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate the region to be ignored based on the percentages\n",
    "    height, width = gray.shape\n",
    "    ignore_top_pixels = int(height * TOP_BORDER_PERCENTAGE)\n",
    "    ignore_side_pixels = int(width * SIDE_BORDER_PERCENTAGE)\n",
    "    \n",
    "    # Set ignored regions to zero\n",
    "    gray[:ignore_top_pixels, :] = 0  # Ignore the top pixels\n",
    "    gray[:, :ignore_side_pixels] = 0  # Ignore left side\n",
    "    gray[:, width-ignore_side_pixels:] = 0  # Ignore right side\n",
    "    \n",
    "    _, binary = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)\n",
    "    return binary\n",
    "\n",
    "def merge_close_contours(contours, min_distance=MIN_DISTANCE_BETWEEN_CONTOURS, max_area_ratio_diff=MAX_AREA_RATIO_DIFF):\n",
    "    merged_contours = []\n",
    "    used = [False] * len(contours)\n",
    "\n",
    "    def get_centroid(contour):\n",
    "        M = cv2.moments(contour)\n",
    "        if M['m00'] == 0:\n",
    "            return None\n",
    "        return (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "\n",
    "    for i, c1 in enumerate(contours):\n",
    "        if used[i]:\n",
    "            continue\n",
    "        merged = [c1]\n",
    "        centroid1 = get_centroid(c1)\n",
    "        if centroid1 is None:\n",
    "            continue\n",
    "        area1 = cv2.contourArea(c1)\n",
    "        for j, c2 in enumerate(contours):\n",
    "            if i != j and not used[j]:\n",
    "                centroid2 = get_centroid(c2)\n",
    "                if centroid2 is None:\n",
    "                    continue\n",
    "                dist = np.linalg.norm(np.array(centroid1) - np.array(centroid2))\n",
    "                area2 = cv2.contourArea(c2)\n",
    "                area_ratio_diff = abs(area1 - area2) / max(area1, area2)\n",
    "\n",
    "                if dist < min_distance and area_ratio_diff < max_area_ratio_diff:\n",
    "                    merged.append(c2)\n",
    "                    used[j] = True\n",
    "        merged_contours.append(np.vstack(merged))\n",
    "        used[i] = True\n",
    "    return merged_contours\n",
    "\n",
    "def extract_contours(binary_frame):\n",
    "    contours, _ = cv2.findContours(binary_frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = merge_close_contours(contours)\n",
    "    return contours\n",
    "\n",
    "def frame_objects(contours, frame_shape):\n",
    "    objects = []\n",
    "    frame_height, frame_width = frame_shape\n",
    "\n",
    "    for contour in contours:\n",
    "        contour_area = cv2.contourArea(contour)\n",
    "        if MIN_CONTOUR_AREA < contour_area < MAX_CONTOUR_AREA:\n",
    "            rect = cv2.minAreaRect(contour)\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = box.astype(int)\n",
    "            center, size, angle = rect\n",
    "            if angle == 0:\n",
    "                angle = 90\n",
    "\n",
    "            if any(point[0] <= BORDER_THICKNESS or point[1] <= BORDER_THICKNESS or \n",
    "                   point[0] >= frame_width - BORDER_THICKNESS or \n",
    "                   point[1] >= frame_height - BORDER_THICKNESS for point in box):\n",
    "                continue\n",
    "\n",
    "            rect = (center, size, angle)\n",
    "            objects.append((rect, box, contour))\n",
    "    return objects\n",
    "\n",
    "def save_object_parameters(objects):\n",
    "    all_features = []\n",
    "    for rect, _, _ in objects:\n",
    "        center, size, _ = rect\n",
    "        width, height = size\n",
    "        area = width * height\n",
    "\n",
    "        features = [area]\n",
    "        all_features.append(features)\n",
    "    return all_features\n",
    "\n",
    "\n",
    "def get_object_key(center, object_buffers, last_known_centers, threshold=MIN_DISTANCE_BETWEEN_CONTOURS):\n",
    "    for key, last_center in last_known_centers.items():\n",
    "        if np.linalg.norm(np.array(center) - np.array(last_center)) < threshold:\n",
    "            return key\n",
    "    return None\n",
    "\n",
    "def draw_contours(frame, objects, object_buffers, frame_counter, last_seen_frame, last_known_centers):\n",
    "    max_len = BUFFER_MAXLEN\n",
    "    fps = 10  # Frames per second\n",
    "\n",
    "    for rect, box, _ in objects:\n",
    "        # Draw the bounding box (box) on the frame\n",
    "        cv2.drawContours(frame, [box], 0, (0, 255, 0), 2)\n",
    "\n",
    "        # Draw window progress bar\n",
    "        center = rect[0]  # Center of the object\n",
    "        key = get_object_key(center, object_buffers, last_known_centers)  # Pass last_known_centers here\n",
    "\n",
    "        if key is not None:\n",
    "            buffer_len = len(object_buffers[key])\n",
    "\n",
    "            # Calculate the position for the progress bar\n",
    "            x, y = int(center[0]), int(center[1])\n",
    "            bar_height = 10\n",
    "            bar_width = 50\n",
    "\n",
    "            # Draw the background of the bar\n",
    "            cv2.rectangle(frame, (x, y - 30), (x + bar_width, y - 30 + bar_height), (0, 0, 0), -1)\n",
    "            \n",
    "            # Draw the progress\n",
    "            progress = int((buffer_len / max_len) * bar_width)\n",
    "            cv2.rectangle(frame, (x, y - 30), (x + progress, y - 30 + bar_height), (0, 255, 0), -1)\n",
    "\n",
    "            # Draw the text indicator\n",
    "            cv2.putText(frame, f\"Window: {buffer_len}/{max_len}\", (x, y - 35), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "\n",
    "            # Display the actual window values in rows of 3\n",
    "            window_values = [f\"{value:.2f}\" for value in object_buffers[key]]  # Display the area values\n",
    "            for i in range(0, len(window_values), 3):\n",
    "                row_values = \" | \".join(window_values[i:i+3])\n",
    "                cv2.putText(frame, row_values, (x, y - 50 - (i//3) * 15), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "\n",
    "            # Perform FFT and find the dominant frequency if the buffer is full\n",
    "            if buffer_len == max_len:\n",
    "                func = np.array(object_buffers[key])\n",
    "                fftx = np.abs(np.fft.rfft(func))\n",
    "                f_axis = np.linspace(0, fps/2, int(0.5 * func.size) + 1)\n",
    "                Y1 = fftx / np.max(fftx)\n",
    "                x_fft = Y1[1:]\n",
    "                peaks, _ = find_peaks(x_fft, height=np.max(x_fft) * 0.5)  # Finding peaks above 50% of the max\n",
    "\n",
    "                if len(peaks) > 0:\n",
    "                    dominant_frequency = f_axis[peaks[0] + 1]  # Peaks[0] is the index in the frequency domain\n",
    "                    # Display the dominant frequency on the frame\n",
    "                    cv2.putText(frame, f\"Freq: {dominant_frequency:.2f} Hz\", (x+10, y +5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "    # Display windows even for objects that have disappeared but are within the threshold\n",
    "    for key, buffer in object_buffers.items():\n",
    "        if len(buffer) > 0:\n",
    "            # Draw window for objects not currently detected but within the threshold\n",
    "            if key not in objects and frame_counter - last_seen_frame[key] <= DISAPPEARANCE_THRESHOLD:\n",
    "                center = last_known_centers[key]\n",
    "                x, y = int(center[0]), int(center[1])\n",
    "                bar_height = 10\n",
    "                bar_width = 50\n",
    "\n",
    "                # Draw the background of the bar\n",
    "                cv2.rectangle(frame, (x, y - 30), (x + bar_width, y - 30 + bar_height), (0, 0, 0), -1)\n",
    "                \n",
    "                # Draw the progress\n",
    "                progress = int((len(buffer) / max_len) * bar_width)\n",
    "                cv2.rectangle(frame, (x, y - 30), (x + progress, y - 30 + bar_height), (0, 255, 0), -1)\n",
    "\n",
    "                # Draw the text indicator\n",
    "                cv2.putText(frame, f\"Window: {len(buffer)}/{max_len}\", (x, y - 35), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "\n",
    "                # Display the actual window values in rows of 3\n",
    "                window_values = [f\"{value:.2f}\" for value in buffer]  # Display the area values\n",
    "                for i in range(0, len(window_values), 3):\n",
    "                    row_values = \" | \".join(window_values[i:i+3])\n",
    "                    cv2.putText(frame, row_values, (x, y - 50 - (i//3) * 15), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "\n",
    "def process_frame(frame, frame_counter, object_buffers, last_seen_frame, last_known_centers):\n",
    "    global next_id\n",
    "    binary_frame = convert_to_binary(frame)\n",
    "    contours = extract_contours(binary_frame)\n",
    "    objects = frame_objects(contours, frame.shape[:2])\n",
    "\n",
    "    features = save_object_parameters(objects)\n",
    "\n",
    "    seen_keys = set()\n",
    "    if features:  # Check if features is not empty\n",
    "        for obj_features, obj in zip(features, objects):\n",
    "            area = obj_features[0]\n",
    "            center = obj[0][0]  # Extract the center from the object\n",
    "            key = get_object_key(center, object_buffers, last_known_centers)\n",
    "            if key is None:\n",
    "                key = next_id\n",
    "                next_id += 1\n",
    "                object_buffers[key] = deque(maxlen=BUFFER_MAXLEN)\n",
    "                # Create a new CSV file for the new object\n",
    "                with open(f'C:\\\\Users\\\\thaim\\\\OneDrive\\\\Desktop\\\\Tal_Projects\\\\Gas_detector\\\\General_Codes\\\\Gas_Detector_5_24\\\\LED_FREQUENCY_TEST\\\\window_{key}.csv', 'w', newline='') as csvfile:\n",
    "                    csvwriter = csv.writer(csvfile)\n",
    "                    csvwriter.writerow([f'Frame {frame_counter}'] + [area])  # First row with the first value\n",
    "            else:\n",
    "                # Save the current state of the deque for each frame, even if it's not full\n",
    "                with open(f'C:\\\\Users\\\\thaim\\\\OneDrive\\\\Desktop\\\\Tal_Projects\\\\Gas_detector\\\\General_Codes\\\\Gas_Detector_5_24\\\\LED_FREQUENCY_TEST\\\\window_{key}.csv', 'a', newline='') as csvfile:\n",
    "                    csvwriter = csv.writer(csvfile)\n",
    "                    csvwriter.writerow([f'Frame {frame_counter}'] + list(object_buffers[key]))\n",
    "                \n",
    "            object_buffers[key].append(area)  # Append only the area\n",
    "            last_seen_frame[key] = frame_counter\n",
    "            last_known_centers[key] = center  # Update the last known center\n",
    "            seen_keys.add(key)\n",
    "\n",
    "    # Add zero for missing objects up to DISAPPEARANCE_THRESHOLD\n",
    "    for key in list(object_buffers.keys()):\n",
    "        if key not in seen_keys:\n",
    "            frames_missing = frame_counter - last_seen_frame[key]\n",
    "            if frames_missing <= DISAPPEARANCE_THRESHOLD:\n",
    "                object_buffers[key].append(0)  # Add zero if the object is missing\n",
    "                # Update CSV file with the new zero value\n",
    "                with open(f'C:\\\\Users\\\\thaim\\\\OneDrive\\\\Desktop\\\\Tal_Projects\\\\Gas_detector\\\\General_Codes\\\\Gas_Detector_5_24\\\\LED_FREQUENCY_TEST\\\\window_{key}.csv', 'a', newline='') as csvfile:\n",
    "                    csvwriter = csv.writer(csvfile)\n",
    "                    csvwriter.writerow([f'Frame {frame_counter}'] + list(object_buffers[key]))\n",
    "            else:\n",
    "                # The buffer is not deleted immediately; it's up to draw_contours to handle display logic.\n",
    "                pass\n",
    "\n",
    "    return object_buffers, objects, binary_frame\n",
    "def crop_and_resize(frame, x1, y1, x2, y2, resize_width, resize_height):\n",
    "    # Crop the area based on provided coordinates\n",
    "    cropped_frame = frame[y1:y2, x1:x2]\n",
    "    \n",
    "    # Resize the cropped area\n",
    "    resized_frame = cv2.resize(cropped_frame, (resize_width, resize_height), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return resized_frame\n",
    "\n",
    "def main(video_source):\n",
    "    time.sleep(0.1)\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video source.\")\n",
    "        return\n",
    "\n",
    "    frame_counter = 0\n",
    "    object_buffers = {}  # Dictionary to store buffers for each object\n",
    "    last_seen_frame = {}  # Dictionary to store the last frame an object was seen\n",
    "    last_known_centers = {}  # Dictionary to store the last known centers of objects\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        time.sleep(0.1)\n",
    "        frame_counter += 1\n",
    "        object_buffers, objects, binary_frame = process_frame(frame, frame_counter, object_buffers, last_seen_frame, last_known_centers)  # Capture binary_frame\n",
    "        \n",
    "        # Analyze the buffers to find any frequency patterns\n",
    "        # analyze_buffers(object_buffers)\n",
    "        \n",
    "        # Draw the contours and the window indicators\n",
    "        draw_contours(frame, objects, object_buffers, frame_counter, last_seen_frame, last_known_centers)  # Pass last_known_centers here\n",
    "\n",
    "        # Crop and resize the specific area based on user input\n",
    "        cropped_resized_frame = crop_and_resize(frame, CROP_X1, CROP_Y1, CROP_X2, CROP_Y2, RESIZE_WIDTH, RESIZE_HEIGHT)\n",
    "\n",
    "        # Display the cropped and resized frame\n",
    "        cv2.imshow('Cropped and Resized Frame', binary_frame)\n",
    "\n",
    "        # Display the real-time frames      \n",
    "        cv2.imshow('Real-time Object Detection', frame)\n",
    "\n",
    "\n",
    "        # Display the binary frame\n",
    "        #cv2.imshow('Binary Frame', binary_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not open video source.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    video_path = r\"C:\\Users\\thaim\\OneDrive\\Desktop\\Leds for simulator\\3m - full shutter - 449  - trim.mp4\"\n",
    "    main(video_path)  # Use 0 for webcam, or provide a video file path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import deque\n",
    "from scipy.fft import fft\n",
    "import csv\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Configurable parameters\n",
    "THRESHOLD_BINARY = 160\n",
    "IGNORE_TOP_PIXELS = 125\n",
    "MIN_CONTOUR_AREA = 1\n",
    "MAX_CONTOUR_AREA = 2500  # Maximum contour area threshold\n",
    "MIN_DISTANCE_BETWEEN_CONTOURS = 10\n",
    "MAX_AREA_RATIO_DIFF = 0.7\n",
    "BUFFER_MAXLEN = 20\n",
    "DISAPPEARANCE_THRESHOLD = 10\n",
    "BORDER_THICKNESS = 5\n",
    "TOP_BORDER_PERCENTAGE = 0.30  # Ignore top 30% of the frame\n",
    "SIDE_BORDER_PERCENTAGE = 0.20  # Ignore 20% from each side of the frame\n",
    "MIN_CIRCULARITY = 0.7  # Minimum circularity to consider a shape as round\n",
    "\n",
    "# Initialize a global unique ID counter\n",
    "next_id = 0\n",
    "\n",
    "def convert_to_binary(frame, threshold=THRESHOLD_BINARY):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate the region to be ignored based on the percentages\n",
    "    height, width = gray.shape\n",
    "    ignore_top_pixels = int(height * TOP_BORDER_PERCENTAGE)\n",
    "    ignore_side_pixels = int(width * SIDE_BORDER_PERCENTAGE)\n",
    "    \n",
    "    # Set ignored regions to zero\n",
    "    gray[:ignore_top_pixels, :] = 0  # Ignore the top pixels\n",
    "    gray[:, :ignore_side_pixels] = 0  # Ignore left side\n",
    "    gray[:, width-ignore_side_pixels:] = 0  # Ignore right side\n",
    "    \n",
    "    _, binary = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)\n",
    "    return binary\n",
    "\n",
    "def merge_close_contours(contours, min_distance=MIN_DISTANCE_BETWEEN_CONTOURS, max_area_ratio_diff=MAX_AREA_RATIO_DIFF):\n",
    "    merged_contours = []\n",
    "    used = [False] * len(contours)\n",
    "\n",
    "    def get_centroid(contour):\n",
    "        M = cv2.moments(contour)\n",
    "        if M['m00'] == 0:\n",
    "            return None\n",
    "        return (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "\n",
    "    for i, c1 in enumerate(contours):\n",
    "        if used[i]:\n",
    "            continue\n",
    "        merged = [c1]\n",
    "        centroid1 = get_centroid(c1)\n",
    "        if centroid1 is None:\n",
    "            continue\n",
    "        area1 = cv2.contourArea(c1)\n",
    "        for j, c2 in enumerate(contours):\n",
    "            if i != j and not used[j]:\n",
    "                centroid2 = get_centroid(c2)\n",
    "                if centroid2 is None:\n",
    "                    continue\n",
    "                dist = np.linalg.norm(np.array(centroid1) - np.array(centroid2))\n",
    "                area2 = cv2.contourArea(c2)\n",
    "                area_ratio_diff = abs(area1 - area2) / max(area1, area2)\n",
    "\n",
    "                if dist < min_distance and area_ratio_diff < max_area_ratio_diff:\n",
    "                    merged.append(c2)\n",
    "                    used[j] = True\n",
    "        merged_contours.append(np.vstack(merged))\n",
    "        used[i] = True\n",
    "    return merged_contours\n",
    "\n",
    "def extract_contours(binary_frame):\n",
    "    contours, _ = cv2.findContours(binary_frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = merge_close_contours(contours)\n",
    "    return contours\n",
    "\n",
    "def frame_objects(contours, frame_shape):\n",
    "    objects = []\n",
    "    frame_height, frame_width = frame_shape\n",
    "\n",
    "    for contour in contours:\n",
    "        contour_area = cv2.contourArea(contour)\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        if perimeter > 0:\n",
    "            circularity = 4 * np.pi * contour_area / (perimeter * perimeter)\n",
    "        else:\n",
    "            circularity = 0\n",
    "\n",
    "        if MIN_CONTOUR_AREA < contour_area < MAX_CONTOUR_AREA and circularity >= MIN_CIRCULARITY:\n",
    "            rect = cv2.minAreaRect(contour)\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = box.astype(int)\n",
    "            center, size, angle = rect\n",
    "            if angle == 0:\n",
    "                angle = 90\n",
    "\n",
    "            if any(point[0] <= BORDER_THICKNESS or point[1] <= BORDER_THICKNESS or \n",
    "                   point[0] >= frame_width - BORDER_THICKNESS or \n",
    "                   point[1] >= frame_height - BORDER_THICKNESS for point in box):\n",
    "                continue\n",
    "\n",
    "            rect = (center, size, angle)\n",
    "            objects.append((rect, box, contour))\n",
    "    return objects\n",
    "\n",
    "def save_object_parameters(objects):\n",
    "    all_features = []\n",
    "    for rect, _, _ in objects:\n",
    "        center, size, _ = rect\n",
    "        width, height = size\n",
    "        area = width * height\n",
    "\n",
    "        features = [area]\n",
    "        all_features.append(features)\n",
    "    return all_features\n",
    "\n",
    "\n",
    "def get_object_key(center, object_buffers, last_known_centers, threshold=MIN_DISTANCE_BETWEEN_CONTOURS):\n",
    "    for key, last_center in last_known_centers.items():\n",
    "        if np.linalg.norm(np.array(center) - np.array(last_center)) < threshold:\n",
    "            return key\n",
    "    return None\n",
    "\n",
    "def draw_contours(frame, objects, object_buffers, frame_counter, last_seen_frame, last_known_centers):\n",
    "    max_len = BUFFER_MAXLEN\n",
    "    fps = 10  # Frames per second\n",
    "\n",
    "    for rect, box, _ in objects:\n",
    "        # Draw the bounding box (box) on the frame\n",
    "        cv2.drawContours(frame, [box], 0, (0, 255, 0), 2)\n",
    "\n",
    "        # Draw window progress bar\n",
    "        center = rect[0]  # Center of the object\n",
    "        key = get_object_key(center, object_buffers, last_known_centers)  # Pass last_known_centers here\n",
    "\n",
    "        if key is not None:\n",
    "            buffer_len = len(object_buffers[key])\n",
    "\n",
    "            # Calculate the position for the progress bar\n",
    "            x, y = int(center[0]), int(center[1])\n",
    "            bar_height = 10\n",
    "            bar_width = 50\n",
    "\n",
    "            # Draw the background of the bar\n",
    "            cv2.rectangle(frame, (x, y - 30), (x + bar_width, y - 30 + bar_height), (0, 0, 0), -1)\n",
    "            \n",
    "            # Draw the progress\n",
    "            progress = int((buffer_len / max_len) * bar_width)\n",
    "            cv2.rectangle(frame, (x, y - 30), (x + progress, y - 30 + bar_height), (0, 255, 0), -1)\n",
    "\n",
    "            # Draw the text indicator\n",
    "            cv2.putText(frame, f\"Window: {buffer_len}/{max_len}\", (x, y - 35), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "\n",
    "            # Display the actual window values in rows of 3\n",
    "            window_values = [f\"{value:.2f}\" for value in object_buffers[key]]  # Display the area values\n",
    "            for i in range(0, len(window_values), 3):\n",
    "                row_values = \" | \".join(window_values[i:i+3])\n",
    "                cv2.putText(frame, row_values, (x, y - 50 - (i//3) * 15), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "\n",
    "            # Perform FFT and find the dominant frequency if the buffer is full\n",
    "            if buffer_len == max_len:\n",
    "                func = np.array(object_buffers[key])\n",
    "                fftx = np.abs(np.fft.rfft(func))\n",
    "                f_axis = np.linspace(0, fps/2, int(0.5 * func.size) + 1)\n",
    "                Y1 = fftx / np.max(fftx)\n",
    "                x_fft = Y1[1:]\n",
    "                peaks, _ = find_peaks(x_fft, height=np.max(x_fft) * 0.5)  # Finding peaks above 50% of the max\n",
    "\n",
    "                if len(peaks) > 0:\n",
    "                    dominant_frequency = f_axis[peaks[0] + 1]  # Peaks[0] is the index in the frequency domain\n",
    "                    # Display the dominant frequency on the frame\n",
    "                    cv2.putText(frame, f\"Freq: {dominant_frequency:.2f} Hz\", (x+10, y +5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "    # Display windows even for objects that have disappeared but are within the threshold\n",
    "    for key, buffer in object_buffers.items():\n",
    "        if len(buffer) > 0:\n",
    "            # Draw window for objects not currently detected but within the threshold\n",
    "            if key not in objects and frame_counter - last_seen_frame[key] <= DISAPPEARANCE_THRESHOLD:\n",
    "                center = last_known_centers[key]\n",
    "                x, y = int(center[0]), int(center[1])\n",
    "                bar_height = 10\n",
    "                bar_width = 50\n",
    "\n",
    "                # Draw the background of the bar\n",
    "                cv2.rectangle(frame, (x, y - 30), (x + bar_width, y - 30 + bar_height), (0, 0, 0), -1)\n",
    "                \n",
    "                # Draw the progress\n",
    "                progress = int((len(buffer) / max_len) * bar_width)\n",
    "                cv2.rectangle(frame, (x, y - 30), (x + progress, y - 30 + bar_height), (0, 255, 0), -1)\n",
    "\n",
    "                # Draw the text indicator\n",
    "                cv2.putText(frame, f\"Window: {len(buffer)}/{max_len}\", (x, y - 35), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "\n",
    "                # Display the actual window values in rows of 3\n",
    "                window_values = [f\"{value:.2f}\" for value in buffer]  # Display the area values\n",
    "                for i in range(0, len(window_values), 3):\n",
    "                    row_values = \" | \".join(window_values[i:i+3])\n",
    "                    cv2.putText(frame, row_values, (x, y - 50 - (i//3) * 15), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "\n",
    "def process_frame(frame, frame_counter, object_buffers, last_seen_frame, last_known_centers):\n",
    "    global next_id\n",
    "    binary_frame = convert_to_binary(frame)\n",
    "    contours = extract_contours(binary_frame)\n",
    "    objects = frame_objects(contours, frame.shape[:2])\n",
    "\n",
    "    features = save_object_parameters(objects)\n",
    "\n",
    "    seen_keys = set()\n",
    "    if features:  # Check if features is not empty\n",
    "        for obj_features, obj in zip(features, objects):\n",
    "            area = obj_features[0]\n",
    "            center = obj[0][0]  # Extract the center from the object\n",
    "            key = get_object_key(center, object_buffers, last_known_centers)\n",
    "            if key is None:\n",
    "                key = next_id\n",
    "                next_id += 1\n",
    "                object_buffers[key] = deque(maxlen=BUFFER_MAXLEN)\n",
    "                # Create a new CSV file for the new object\n",
    "                with open(f'C:\\\\Users\\\\thaim\\\\OneDrive\\\\Desktop\\\\Tal_Projects\\\\Gas_detector\\\\General_Codes\\\\Gas_Detector_5_24\\\\LED_FREQUENCY_TEST\\\\window_{key}.csv', 'w', newline='') as csvfile:\n",
    "                    csvwriter = csv.writer(csvfile)\n",
    "                    csvwriter.writerow([f'Frame {frame_counter}'] + [area])  # First row with the first value\n",
    "            else:\n",
    "                # Save the current state of the deque for each frame, even if it's not full\n",
    "                with open(f'C:\\\\Users\\\\thaim\\\\OneDrive\\\\Desktop\\\\Tal_Projects\\\\Gas_detector\\\\General_Codes\\\\Gas_Detector_5_24\\\\LED_FREQUENCY_TEST\\\\window_{key}.csv', 'a', newline='') as csvfile:\n",
    "                    csvwriter = csv.writer(csvfile)\n",
    "                    csvwriter.writerow([f'Frame {frame_counter}'] + list(object_buffers[key]))\n",
    "                \n",
    "            object_buffers[key].append(area)  # Append only the area\n",
    "            last_seen_frame[key] = frame_counter\n",
    "            last_known_centers[key] = center  # Update the last known center\n",
    "            seen_keys.add(key)\n",
    "\n",
    "    # Add zero for missing objects up to DISAPPEARANCE_THRESHOLD\n",
    "    for key in list(object_buffers.keys()):\n",
    "        if key not in seen_keys:\n",
    "            frames_missing = frame_counter - last_seen_frame[key]\n",
    "            if frames_missing <= DISAPPEARANCE_THRESHOLD:\n",
    "                object_buffers[key].append(0)  # Add zero if the object is missing\n",
    "                # Update CSV file with the new zero value\n",
    "                with open(f'C:\\\\Users\\\\thaim\\\\OneDrive\\\\Desktop\\\\Tal_Projects\\\\Gas_detector\\\\General_Codes\\\\Gas_Detector_5_24\\\\LED_FREQUENCY_TEST\\\\window_{key}.csv', 'a', newline='') as csvfile:\n",
    "                    csvwriter = csv.writer(csvfile)\n",
    "                    csvwriter.writerow([f'Frame {frame_counter}'] + list(object_buffers[key]))\n",
    "            else:\n",
    "                # The buffer is not deleted immediately; it's up to draw_contours to handle display logic.\n",
    "                pass\n",
    "\n",
    "    return object_buffers, objects, binary_frame\n",
    "\n",
    "def main(video_source):\n",
    "    time.sleep(0.1)\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video source.\")\n",
    "        return\n",
    "\n",
    "    frame_counter = 0\n",
    "    object_buffers = {}  # Dictionary to store buffers for each object\n",
    "    last_seen_frame = {}  # Dictionary to store the last frame an object was seen\n",
    "    last_known_centers = {}  # Dictionary to store the last known centers of objects\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        time.sleep(0.6)\n",
    "        frame_counter += 1\n",
    "        object_buffers, objects, binary_frame = process_frame(frame, frame_counter, object_buffers, last_seen_frame, last_known_centers)  # Capture binary_frame\n",
    "        \n",
    "        # Analyze the buffers to find any frequency patterns\n",
    "        # analyze_buffers(object_buffers)\n",
    "        \n",
    "        # Draw the contours and the window indicators\n",
    "        draw_contours(frame, objects, object_buffers, frame_counter, last_seen_frame, last_known_centers)  # Pass last_known_centers here\n",
    "\n",
    "        # Display the binary frame\n",
    "        # cv2.imshow('Binary Frame', binary_frame)\n",
    "        cv2.imshow('Frame', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\thaim\\\\OneDrive\\\\Desktop\\\\Tal_Projects\\\\Gas_detector\\\\General_Codes\\\\Gas_Detector_5_24\\\\LED_FREQUENCY_TEST\\\\window_0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      2\u001b[0m     video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mthaim\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mVideos\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mIR\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mRecording 2024-08-18 141852 - IR_LED_1-5hz_1m.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Use 0 for webcam, or provide a video file path\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 272\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(video_source)\u001b[0m\n\u001b[0;32m    270\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.6\u001b[39m)\n\u001b[0;32m    271\u001b[0m frame_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 272\u001b[0m object_buffers, objects, binary_frame \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_counter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_buffers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_seen_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_known_centers\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Capture binary_frame\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;66;03m# Analyze the buffers to find any frequency patterns\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;66;03m# analyze_buffers(object_buffers)\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m# Draw the contours and the window indicators\u001b[39;00m\n\u001b[0;32m    278\u001b[0m draw_contours(frame, objects, object_buffers, frame_counter, last_seen_frame, last_known_centers)  \u001b[38;5;66;03m# Pass last_known_centers here\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 224\u001b[0m, in \u001b[0;36mprocess_frame\u001b[1;34m(frame, frame_counter, object_buffers, last_seen_frame, last_known_centers)\u001b[0m\n\u001b[0;32m    222\u001b[0m object_buffers[key] \u001b[38;5;241m=\u001b[39m deque(maxlen\u001b[38;5;241m=\u001b[39mBUFFER_MAXLEN)\n\u001b[0;32m    223\u001b[0m \u001b[38;5;66;03m# Create a new CSV file for the new object\u001b[39;00m\n\u001b[1;32m--> 224\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mthaim\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mOneDrive\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mDesktop\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mTal_Projects\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mGas_detector\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mGeneral_Codes\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mGas_Detector_5_24\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mLED_FREQUENCY_TEST\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mwindow_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[0;32m    225\u001b[0m     csvwriter \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(csvfile)\n\u001b[0;32m    226\u001b[0m     csvwriter\u001b[38;5;241m.\u001b[39mwriterow([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrame \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframe_counter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m [area])  \u001b[38;5;66;03m# First row with the first value\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\thaim\\\\OneDrive\\\\Desktop\\\\Tal_Projects\\\\Gas_detector\\\\General_Codes\\\\Gas_Detector_5_24\\\\LED_FREQUENCY_TEST\\\\window_0.csv'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    video_path = r\"C:\\Users\\thaim\\Videos\\IR\\Recording 2024-08-18 141852 - IR_LED_1-5hz_1m.mp4\"\n",
    "    main(video_path)  # Use 0 for webcam, or provide a video file path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FROM GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Rate: 30 FPS\n",
      "Total Frames: 949\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.fft import fft, fftfreq\n",
    "from collections import defaultdict, deque\n",
    "from scipy.spatial.distance import euclidean\n",
    "import time\n",
    "\n",
    "def detect_blinking_frequency_with_fixed_window(\n",
    "        video_source, expected_frequency, tolerance=2, max_distance=30, disappearance_grace=30, fft_window_size=20):\n",
    "    \"\"\"\n",
    "    Detects the blinking frequency of individual objects in a video, adding zeros for disappeared frames.\n",
    "\n",
    "    :param video_source: Path to the video file or integer for live camera feed.\n",
    "    :param expected_frequency: Expected blinking frequency of LEDs (Hz).\n",
    "    :param tolerance: Allowable deviation from expected frequency (Hz).\n",
    "    :param max_distance: Maximum distance to match objects across frames.\n",
    "    :param disappearance_grace: Maximum frames an object can disappear before being removed.\n",
    "    :param fft_window_size: Number of frames used for FFT analysis.\n",
    "    :return: Dictionary with objects' IDs and their detected frequencies.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "    frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    active_objects = {}  # {object_id: (x, y, brightness_history)}\n",
    "    pending_objects = {}  # {object_id: (x, y, brightness_history, missing_frames)}\n",
    "    object_frequencies = {}  # {object_id: detected_frequency}\n",
    "    next_object_id = 0\n",
    "\n",
    "    print(f\"Frame Rate: {frame_rate} FPS\")\n",
    "    print(f\"Total Frames: {total_frames}\")\n",
    "\n",
    "    while cap.isOpened():\n",
    "        time.sleep(0.01)\n",
    "        for frame_idx in range(total_frames):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Preprocessing\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
    "            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # Detect objects in the current frame\n",
    "            current_frame_objects = []\n",
    "            for contour in contours:\n",
    "                (x, y), radius = cv2.minEnclosingCircle(contour)\n",
    "                if radius > 2:  # Filter out noise by size\n",
    "                    brightness = np.sum(thresh[int(y - radius):int(y + radius), int(x - radius):int(x + radius)])\n",
    "                    current_frame_objects.append((int(x), int(y), brightness))\n",
    "\n",
    "            # Update active objects\n",
    "            updated_objects = {}\n",
    "            for x, y, brightness in current_frame_objects:\n",
    "                matched_id = None\n",
    "                best_match_distance = float('inf')\n",
    "\n",
    "                # Match with active objects\n",
    "                for obj_id, (prev_x, prev_y, brightness_history) in active_objects.items():\n",
    "                    distance = euclidean((x, y), (prev_x, prev_y))\n",
    "                    if distance < max_distance and distance < best_match_distance:\n",
    "                        matched_id = obj_id\n",
    "                        best_match_distance = distance\n",
    "\n",
    "                # Match with pending objects if no active match\n",
    "                if matched_id is None:\n",
    "                    for obj_id, (prev_x, prev_y, brightness_history, missing_frames) in pending_objects.items():\n",
    "                        distance = euclidean((x, y), (prev_x, prev_y))\n",
    "                        if distance < max_distance and distance < best_match_distance:\n",
    "                            matched_id = obj_id\n",
    "                            best_match_distance = distance\n",
    "\n",
    "                # Assign a new ID if no match found\n",
    "                if matched_id is None:\n",
    "                    matched_id = next_object_id\n",
    "                    next_object_id += 1\n",
    "\n",
    "                # Update object information\n",
    "                if matched_id in pending_objects:\n",
    "                    # Move from pending to active\n",
    "                    _, _, brightness_history, _ = pending_objects.pop(matched_id)\n",
    "                else:\n",
    "                    brightness_history = deque([0] * fft_window_size, maxlen=fft_window_size)\n",
    "\n",
    "                brightness_history.append(brightness)\n",
    "                updated_objects[matched_id] = (x, y, brightness_history)\n",
    "\n",
    "                # Visualize the object\n",
    "                cv2.circle(frame, (x, y), 10, (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"ID: {matched_id}\", (x - 20, y - 20),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "\n",
    "                # Display brightness history on the frame\n",
    "                brightness_text = ', '.join(map(str, map(int, brightness_history)))\n",
    "                cv2.putText(frame, f\"Window: [{brightness_text}]\", (x - 50, y + 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)\n",
    "\n",
    "            # Handle objects that disappeared\n",
    "            for obj_id in list(active_objects.keys()):\n",
    "                if obj_id not in updated_objects:\n",
    "                    if obj_id in pending_objects:\n",
    "                        # Add zeros for each missing frame\n",
    "                        _, _, brightness_history, missing_frames = pending_objects[obj_id]\n",
    "                        brightness_history.append(0)\n",
    "                        missing_frames += 1\n",
    "                    else:\n",
    "                        # Start tracking disappearance\n",
    "                        _, _, brightness_history = active_objects[obj_id]\n",
    "                        brightness_history.append(0)\n",
    "                        missing_frames = 1\n",
    "                    if missing_frames <= disappearance_grace:\n",
    "                        pending_objects[obj_id] = (*active_objects[obj_id][:2], brightness_history, missing_frames)\n",
    "                    else:\n",
    "                        # Permanently remove the object\n",
    "                        object_frequencies.pop(obj_id, None)\n",
    "\n",
    "            # Update active objects for next frame\n",
    "            active_objects = updated_objects\n",
    "\n",
    "            # Show the frame with frame counter and detected objects\n",
    "            cv2.putText(frame, f\"Frame: {frame_idx + 1}/{total_frames}\", (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "            cv2.imshow(\"LED Frequency Detection\", frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to exit\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return object_frequencies\n",
    "        \n",
    "        # Frequency Analysis\n",
    "        for obj_id, (_, _, brightness_history) in active_objects.items():\n",
    "            if len(brightness_history) == fft_window_size:  # Ensure sufficient data\n",
    "                fft_result = fft(list(brightness_history))\n",
    "                freqs = fftfreq(len(fft_result), 1 / frame_rate)\n",
    "                positive_freqs = freqs[:len(freqs) // 2]\n",
    "                magnitude = np.abs(fft_result[:len(freqs) // 2])\n",
    "                dominant_frequency = positive_freqs[np.argmax(magnitude)]\n",
    "                object_frequencies[obj_id] = dominant_frequency\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return object_frequencies\n",
    "\n",
    "\n",
    "# Example usage\n",
    "video_path = r\"C:\\Users\\thaim\\Videos\\IR\\Recording 2024-08-18 141852 - IR_LED_1-5hz_1m.mp4\"\n",
    "expected_blinking_frequency = 3  # Hz\n",
    "\n",
    "result = detect_blinking_frequency_with_fixed_window(video_path, expected_blinking_frequency)\n",
    "for obj_id, freq in result.items():\n",
    "    print(f\"Object {obj_id}: Frequency {freq:.2f} Hz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
