{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04275bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports loaded\n",
      "System: Advanced LED Detection for 2Hz DC LEDs (10-120m range)\n",
      "Features: Adaptive preprocessing, FFT analysis, multi-range color detection, flicker tracking, temporal confirmation\n"
     ]
    }
   ],
   "source": [
    "# ===== REQUIRED IMPORTS =====\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "print(\"‚úÖ All imports loaded\")\n",
    "print(\"System: Advanced LED Detection for 2Hz DC LEDs (10-120m range)\")\n",
    "print(\"Features: Adaptive preprocessing, FFT analysis, multi-range color detection, flicker tracking, temporal confirmation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9c2f6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Detection parameters initialized\n",
      "üéØ Target: 2.0 Hz LEDs at 10-120m range\n"
     ]
    }
   ],
   "source": [
    "# ===== ADVANCED LED DETECTION SYSTEM =====\n",
    "# Multi-stage detection: Adaptive preprocessing + Frequency + Color + Flicker\n",
    "# Optimized for 2Hz DC-powered LEDs at 10-120m distance\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "from collections import deque\n",
    "from scipy.signal import find_peaks\n",
    "from scipy import ndimage\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# ===== SYSTEM PARAMETERS =====\n",
    "\n",
    "class DetectionParams:\n",
    "    \"\"\"Centralized parameter management\"\"\"\n",
    "    def __init__(self):\n",
    "        # General\n",
    "        self.LED_FREQ_TARGET = 2.0  # Target LED frequency (Hz)\n",
    "        self.FREQ_TOLERANCE = 0.5   # Frequency tolerance\n",
    "        self.FPS = 30.0             # Camera FPS\n",
    "        \n",
    "        # Grid settings\n",
    "        self.GRID_SIZE = 80         # Grid cell size (pixels)\n",
    "        self.MIN_GRID_SIZE = 40\n",
    "        self.MAX_GRID_SIZE = 200\n",
    "        \n",
    "        # Adaptive thresholding\n",
    "        self.ADAPTIVE_METHOD = 'gaussian'  # 'gaussian' or 'mean'\n",
    "        self.ADAPTIVE_BLOCK_SIZE = 11      # Must be odd\n",
    "        self.ADAPTIVE_C = 2                 # Constant subtracted\n",
    "        \n",
    "        # Frequency analysis\n",
    "        self.FREQ_BUFFER_SIZE = 60   # Frames to analyze (2 sec at 30fps)\n",
    "        self.MIN_FREQ = 0.5          # Minimum detectable frequency\n",
    "        self.MAX_FREQ = 10.0         # Maximum detectable frequency\n",
    "        self.FFT_THRESHOLD = 3.0     # Peak detection threshold\n",
    "        \n",
    "        # HSV Color ranges (multiple for robustness)\n",
    "        self.HSV_RANGES = [\n",
    "            # Range 1: Bright yellow\n",
    "            ([20, 100, 150], [35, 255, 255]),\n",
    "            # Range 2: Orange-yellow\n",
    "            ([15, 80, 120], [40, 255, 255]),\n",
    "            # Range 3: Dim yellow (shadow)\n",
    "            ([18, 50, 80], [38, 255, 200])\n",
    "        ]\n",
    "        \n",
    "        # LAB Color space (better for illumination)\n",
    "        self.LAB_L_MIN = 100         # Minimum lightness\n",
    "        self.LAB_A_RANGE = (120, 135) # Yellow in A channel\n",
    "        self.LAB_B_RANGE = (135, 160) # Yellow in B channel\n",
    "        \n",
    "        # Flicker detection\n",
    "        self.FLICKER_BUFFER_SIZE = 30  # Frames for flicker analysis\n",
    "        self.FLICKER_STD_THRESHOLD = 15.0  # Std dev threshold\n",
    "        self.INTENSITY_CHANGE_THRESHOLD = 20  # Min intensity change\n",
    "        \n",
    "        # Size filtering (distance-adaptive)\n",
    "        self.MIN_AREA = 25           # Minimum LED area (pixels)\n",
    "        self.MAX_AREA = 10000        # Maximum LED area (pixels)\n",
    "        self.ASPECT_RATIO_MAX = 3.0  # Width/height ratio limit\n",
    "        \n",
    "        # Temporal tracking\n",
    "        self.TEMPORAL_BUFFER_SIZE = 10  # Frames to confirm detection\n",
    "        self.MIN_DETECTIONS = 5         # Minimum detections to confirm\n",
    "        self.POSITION_TOLERANCE = 20    # Max position change (pixels)\n",
    "        \n",
    "        # Confidence scoring weights\n",
    "        self.WEIGHT_FREQUENCY = 0.35\n",
    "        self.WEIGHT_COLOR = 0.25\n",
    "        self.WEIGHT_FLICKER = 0.25\n",
    "        self.WEIGHT_TEMPORAL = 0.15\n",
    "        self.CONFIDENCE_THRESHOLD = 0.5  # Minimum confidence to report\n",
    "\n",
    "params = DetectionParams()\n",
    "print(\"‚úÖ Detection parameters initialized\")\n",
    "print(f\"üéØ Target: {params.LED_FREQ_TARGET} Hz LEDs at 10-120m range\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8c7af83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Adaptive preprocessor initialized\n"
     ]
    }
   ],
   "source": [
    "# ===== STAGE 1: ADAPTIVE PREPROCESSING =====\n",
    "\n",
    "class AdaptivePreprocessor:\n",
    "    \"\"\"Handles varying lighting conditions with adaptive methods\"\"\"\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        \n",
    "    def preprocess_frame(self, frame):\n",
    "        \"\"\"Apply adaptive preprocessing to handle lighting variations\"\"\"\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        enhanced = clahe.apply(gray)\n",
    "        \n",
    "        # Adaptive thresholding\n",
    "        if self.params.ADAPTIVE_METHOD == 'gaussian':\n",
    "            binary = cv2.adaptiveThreshold(\n",
    "                enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                cv2.THRESH_BINARY, self.params.ADAPTIVE_BLOCK_SIZE, \n",
    "                self.params.ADAPTIVE_C\n",
    "            )\n",
    "        else:\n",
    "            binary = cv2.adaptiveThreshold(\n",
    "                enhanced, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                cv2.THRESH_BINARY, self.params.ADAPTIVE_BLOCK_SIZE,\n",
    "                self.params.ADAPTIVE_C\n",
    "            )\n",
    "        \n",
    "        return gray, enhanced, binary\n",
    "    \n",
    "    def get_local_statistics(self, gray, grid_size):\n",
    "        \"\"\"Calculate local mean and std for each grid cell\"\"\"\n",
    "        h, w = gray.shape\n",
    "        grid_h = h // grid_size\n",
    "        grid_w = w // grid_size\n",
    "        \n",
    "        stats = []\n",
    "        for i in range(grid_h):\n",
    "            for j in range(grid_w):\n",
    "                y1, y2 = i * grid_size, min((i + 1) * grid_size, h)\n",
    "                x1, x2 = j * grid_size, min((j + 1) * grid_size, w)\n",
    "                roi = gray[y1:y2, x1:x2]\n",
    "                \n",
    "                stats.append({\n",
    "                    'position': (j, i),\n",
    "                    'bbox': (x1, y1, x2, y2),\n",
    "                    'mean': np.mean(roi),\n",
    "                    'std': np.std(roi),\n",
    "                    'max': np.max(roi),\n",
    "                    'min': np.min(roi)\n",
    "                })\n",
    "        \n",
    "        return stats\n",
    "\n",
    "preprocessor = AdaptivePreprocessor(params)\n",
    "print(\"‚úÖ Adaptive preprocessor initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2710dc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Frequency analyzer initialized - detects ALL frequencies\n"
     ]
    }
   ],
   "source": [
    "# ===== STAGE 2: FREQUENCY ANALYZER =====\n",
    "\n",
    "class FrequencyAnalyzer:\n",
    "    \"\"\"FFT-based frequency detection for ALL frequencies\"\"\"\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.buffers = {}  # Store intensity buffer per grid cell\n",
    "        \n",
    "    def add_intensity(self, grid_id, intensity):\n",
    "        \"\"\"Add intensity value to grid cell buffer\"\"\"\n",
    "        if grid_id not in self.buffers:\n",
    "            self.buffers[grid_id] = deque(maxlen=self.params.FREQ_BUFFER_SIZE)\n",
    "        self.buffers[grid_id].append(intensity)\n",
    "    \n",
    "    def analyze_frequency(self, grid_id):\n",
    "        \"\"\"Perform FFT and return ALL detected frequencies\"\"\"\n",
    "        if grid_id not in self.buffers or len(self.buffers[grid_id]) < 30:\n",
    "            return []\n",
    "        \n",
    "        signal = np.array(self.buffers[grid_id])\n",
    "        \n",
    "        # Remove DC component\n",
    "        signal = signal - np.mean(signal)\n",
    "        \n",
    "        if np.std(signal) < 1e-6:\n",
    "            return []\n",
    "        \n",
    "        # Apply FFT\n",
    "        fft_result = np.fft.rfft(signal)\n",
    "        fft_magnitude = np.abs(fft_result)[1:]  # Skip DC\n",
    "        \n",
    "        # Frequency axis\n",
    "        freq_axis = np.fft.rfftfreq(len(signal), 1.0 / self.params.FPS)[1:]\n",
    "        \n",
    "        # Find all peaks\n",
    "        threshold = np.max(fft_magnitude) * (self.params.FFT_THRESHOLD / 10.0)\n",
    "        peaks, properties = find_peaks(fft_magnitude, height=threshold)\n",
    "        \n",
    "        # Extract frequencies with confidence\n",
    "        detected_freqs = []\n",
    "        for peak_idx in peaks:\n",
    "            if 0 <= peak_idx < len(freq_axis):\n",
    "                freq = freq_axis[peak_idx]\n",
    "                if self.params.MIN_FREQ <= freq <= self.params.MAX_FREQ:\n",
    "                    magnitude = fft_magnitude[peak_idx]\n",
    "                    confidence = min(magnitude / (np.max(fft_magnitude) + 1e-6), 1.0)\n",
    "                    \n",
    "                    # Check if close to target frequency\n",
    "                    is_target = abs(freq - self.params.LED_FREQ_TARGET) < self.params.FREQ_TOLERANCE\n",
    "                    \n",
    "                    detected_freqs.append({\n",
    "                        'frequency': float(freq),\n",
    "                        'magnitude': float(magnitude),\n",
    "                        'confidence': float(confidence),\n",
    "                        'is_target': is_target\n",
    "                    })\n",
    "        \n",
    "        # Sort by magnitude (strongest first)\n",
    "        detected_freqs.sort(key=lambda x: x['magnitude'], reverse=True)\n",
    "        return detected_freqs\n",
    "    \n",
    "    def get_target_frequency_score(self, frequencies):\n",
    "        \"\"\"Calculate confidence score for target frequency (2Hz)\"\"\"\n",
    "        for freq_info in frequencies:\n",
    "            if freq_info['is_target']:\n",
    "                return freq_info['confidence']\n",
    "        return 0.0\n",
    "\n",
    "freq_analyzer = FrequencyAnalyzer(params)\n",
    "print(\"‚úÖ Frequency analyzer initialized - detects ALL frequencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11a05866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Multi-range color detector initialized (HSV + LAB)\n"
     ]
    }
   ],
   "source": [
    "# ===== STAGE 3: MULTI-HSV COLOR DETECTOR =====\n",
    "\n",
    "class ColorDetector:\n",
    "    \"\"\"Multi-range HSV + LAB color detection for robustness\"\"\"\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "    \n",
    "    def detect_by_color(self, frame):\n",
    "        \"\"\"Detect yellow objects using multiple HSV ranges + LAB\"\"\"\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
    "        \n",
    "        # Combine all HSV ranges\n",
    "        combined_mask = np.zeros(hsv.shape[:2], dtype=np.uint8)\n",
    "        \n",
    "        for lower, upper in self.params.HSV_RANGES:\n",
    "            lower_np = np.array(lower, dtype=np.uint8)\n",
    "            upper_np = np.array(upper, dtype=np.uint8)\n",
    "            mask = cv2.inRange(hsv, lower_np, upper_np)\n",
    "            combined_mask = cv2.bitwise_or(combined_mask, mask)\n",
    "        \n",
    "        # LAB color space filtering\n",
    "        l_channel, a_channel, b_channel = cv2.split(lab)\n",
    "        lab_mask = cv2.inRange(l_channel, self.params.LAB_L_MIN, 255)\n",
    "        lab_mask = cv2.bitwise_and(lab_mask, \n",
    "                                    cv2.inRange(a_channel, self.params.LAB_A_RANGE[0], self.params.LAB_A_RANGE[1]))\n",
    "        lab_mask = cv2.bitwise_and(lab_mask,\n",
    "                                    cv2.inRange(b_channel, self.params.LAB_B_RANGE[0], self.params.LAB_B_RANGE[1]))\n",
    "        \n",
    "        # Combine HSV and LAB masks\n",
    "        final_mask = cv2.bitwise_or(combined_mask, lab_mask)\n",
    "        \n",
    "        # Morphological operations to clean up\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        final_mask = cv2.morphologyEx(final_mask, cv2.MORPH_OPEN, kernel)\n",
    "        final_mask = cv2.morphologyEx(final_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(final_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Filter by size and aspect ratio\n",
    "        candidates = []\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if self.params.MIN_AREA <= area <= self.params.MAX_AREA:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                aspect_ratio = w / float(h) if h > 0 else 0\n",
    "                \n",
    "                if aspect_ratio <= self.params.ASPECT_RATIO_MAX:\n",
    "                    # Calculate color confidence (how much of object is in color range)\n",
    "                    roi_mask = final_mask[y:y+h, x:x+w]\n",
    "                    color_confidence = np.sum(roi_mask > 0) / (w * h * 255.0)\n",
    "                    \n",
    "                    candidates.append({\n",
    "                        'bbox': (x, y, w, h),\n",
    "                        'area': area,\n",
    "                        'center': (x + w // 2, y + h // 2),\n",
    "                        'color_confidence': color_confidence,\n",
    "                        'contour': contour\n",
    "                    })\n",
    "        \n",
    "        return candidates, final_mask\n",
    "\n",
    "color_detector = ColorDetector(params)\n",
    "print(\"‚úÖ Multi-range color detector initialized (HSV + LAB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2dd561dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Flicker detector initialized\n"
     ]
    }
   ],
   "source": [
    "# ===== STAGE 4: FLICKER DETECTOR =====\n",
    "\n",
    "class FlickerDetector:\n",
    "    \"\"\"Temporal intensity analysis to detect flickering\"\"\"\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.region_buffers = {}  # Store intensity history per region\n",
    "    \n",
    "    def add_region_intensity(self, region_id, mean_intensity):\n",
    "        \"\"\"Add intensity measurement for a region\"\"\"\n",
    "        if region_id not in self.region_buffers:\n",
    "            self.region_buffers[region_id] = deque(maxlen=self.params.FLICKER_BUFFER_SIZE)\n",
    "        self.region_buffers[region_id].append(mean_intensity)\n",
    "    \n",
    "    def analyze_flicker(self, region_id):\n",
    "        \"\"\"Analyze if region shows flickering behavior\"\"\"\n",
    "        if region_id not in self.region_buffers or len(self.region_buffers[region_id]) < 10:\n",
    "            return {'is_flickering': False, 'confidence': 0.0, 'std': 0.0}\n",
    "        \n",
    "        intensities = np.array(self.region_buffers[region_id])\n",
    "        \n",
    "        # Calculate statistics\n",
    "        std_dev = np.std(intensities)\n",
    "        mean_intensity = np.mean(intensities)\n",
    "        intensity_range = np.max(intensities) - np.min(intensities)\n",
    "        \n",
    "        # Flickering indicators\n",
    "        is_flickering = (std_dev > self.params.FLICKER_STD_THRESHOLD and \n",
    "                        intensity_range > self.params.INTENSITY_CHANGE_THRESHOLD)\n",
    "        \n",
    "        # Calculate confidence based on std deviation\n",
    "        confidence = min(std_dev / 50.0, 1.0) if is_flickering else 0.0\n",
    "        \n",
    "        # Check periodicity (optional: detect if flicker is periodic)\n",
    "        periodicity_score = 0.0\n",
    "        if len(intensities) >= 20:\n",
    "            # Simple autocorrelation check\n",
    "            normalized = (intensities - mean_intensity) / (std_dev + 1e-6)\n",
    "            autocorr = np.correlate(normalized, normalized, mode='same')\n",
    "            autocorr = autocorr[len(autocorr)//2:]\n",
    "            \n",
    "            # Look for peaks in autocorrelation (indicates periodicity)\n",
    "            if len(autocorr) > 5:\n",
    "                peaks, _ = find_peaks(autocorr[1:], height=0.3)\n",
    "                if len(peaks) > 0:\n",
    "                    periodicity_score = 0.5\n",
    "        \n",
    "        return {\n",
    "            'is_flickering': is_flickering,\n",
    "            'confidence': confidence + periodicity_score,\n",
    "            'std': std_dev,\n",
    "            'range': intensity_range,\n",
    "            'mean': mean_intensity\n",
    "        }\n",
    "    \n",
    "    def clear_old_regions(self, active_region_ids):\n",
    "        \"\"\"Remove buffers for regions no longer being tracked\"\"\"\n",
    "        to_remove = [rid for rid in self.region_buffers.keys() if rid not in active_region_ids]\n",
    "        for rid in to_remove:\n",
    "            del self.region_buffers[rid]\n",
    "\n",
    "flicker_detector = FlickerDetector(params)\n",
    "print(\"‚úÖ Flicker detector initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95e71dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Temporal tracker and confidence scorer initialized\n"
     ]
    }
   ],
   "source": [
    "# ===== STAGE 5: TEMPORAL TRACKER & CONFIDENCE SCORER =====\n",
    "\n",
    "class TemporalTracker:\n",
    "    \"\"\"Track detections over time to confirm LEDs\"\"\"\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.tracked_objects = {}  # {id: detection_history}\n",
    "        self.next_id = 0\n",
    "    \n",
    "    def update(self, current_detections):\n",
    "        \"\"\"Update tracking with current frame detections\"\"\"\n",
    "        # Match current detections with tracked objects\n",
    "        matched = {}\n",
    "        unmatched_current = list(range(len(current_detections)))\n",
    "        \n",
    "        for obj_id, history in self.tracked_objects.items():\n",
    "            if len(history) == 0:\n",
    "                continue\n",
    "            \n",
    "            last_det = history[-1]\n",
    "            last_pos = last_det['center']\n",
    "            \n",
    "            # Find closest unmatched detection\n",
    "            best_match = None\n",
    "            best_dist = self.params.POSITION_TOLERANCE\n",
    "            \n",
    "            for idx in unmatched_current:\n",
    "                curr_pos = current_detections[idx]['center']\n",
    "                dist = np.sqrt((curr_pos[0] - last_pos[0])**2 + (curr_pos[1] - last_pos[1])**2)\n",
    "                \n",
    "                if dist < best_dist:\n",
    "                    best_dist = dist\n",
    "                    best_match = idx\n",
    "            \n",
    "            if best_match is not None:\n",
    "                matched[obj_id] = best_match\n",
    "                unmatched_current.remove(best_match)\n",
    "        \n",
    "        # Update matched objects\n",
    "        new_tracked = {}\n",
    "        for obj_id, det_idx in matched.items():\n",
    "            detection = current_detections[det_idx].copy()\n",
    "            detection['timestamp'] = time.time()\n",
    "            \n",
    "            history = self.tracked_objects[obj_id]\n",
    "            history.append(detection)\n",
    "            if len(history) > self.params.TEMPORAL_BUFFER_SIZE:\n",
    "                history.pop(0)\n",
    "            new_tracked[obj_id] = history\n",
    "        \n",
    "        # Add new objects\n",
    "        for idx in unmatched_current:\n",
    "            detection = current_detections[idx].copy()\n",
    "            detection['timestamp'] = time.time()\n",
    "            new_tracked[self.next_id] = [detection]\n",
    "            self.next_id += 1\n",
    "        \n",
    "        # Remove stale objects (not seen for 2+ seconds)\n",
    "        current_time = time.time()\n",
    "        self.tracked_objects = {\n",
    "            obj_id: history for obj_id, history in new_tracked.items()\n",
    "            if current_time - history[-1]['timestamp'] < 2.0\n",
    "        }\n",
    "        \n",
    "        return self.tracked_objects\n",
    "    \n",
    "    def get_confirmed_objects(self):\n",
    "        \"\"\"Return objects confirmed over multiple frames\"\"\"\n",
    "        confirmed = []\n",
    "        for obj_id, history in self.tracked_objects.items():\n",
    "            if len(history) >= self.params.MIN_DETECTIONS:\n",
    "                # Calculate average position and confidence\n",
    "                avg_conf = np.mean([d.get('total_confidence', 0) for d in history])\n",
    "                last_det = history[-1]\n",
    "                \n",
    "                confirmed.append({\n",
    "                    'id': obj_id,\n",
    "                    'position': last_det['center'],\n",
    "                    'bbox': last_det['bbox'],\n",
    "                    'confidence': avg_conf,\n",
    "                    'detections': len(history),\n",
    "                    'stable': len(history) == self.params.TEMPORAL_BUFFER_SIZE\n",
    "                })\n",
    "        \n",
    "        return confirmed\n",
    "\n",
    "\n",
    "class ConfidenceScorer:\n",
    "    \"\"\"Combine all detection methods into final confidence score\"\"\"\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "    \n",
    "    def calculate_confidence(self, detection):\n",
    "        \"\"\"Calculate weighted confidence from all methods\"\"\"\n",
    "        # Frequency score (from FFT)\n",
    "        freq_score = detection.get('frequency_confidence', 0.0)\n",
    "        \n",
    "        # Color score (from HSV/LAB)\n",
    "        color_score = detection.get('color_confidence', 0.0)\n",
    "        \n",
    "        # Flicker score (from temporal analysis)\n",
    "        flicker_score = detection.get('flicker_confidence', 0.0)\n",
    "        \n",
    "        # Temporal score (from tracking history)\n",
    "        temporal_score = detection.get('temporal_confidence', 0.0)\n",
    "        \n",
    "        # Weighted combination\n",
    "        total_confidence = (\n",
    "            freq_score * self.params.WEIGHT_FREQUENCY +\n",
    "            color_score * self.params.WEIGHT_COLOR +\n",
    "            flicker_score * self.params.WEIGHT_FLICKER +\n",
    "            temporal_score * self.params.WEIGHT_TEMPORAL\n",
    "        )\n",
    "        \n",
    "        return total_confidence, {\n",
    "            'frequency': freq_score,\n",
    "            'color': color_score,\n",
    "            'flicker': flicker_score,\n",
    "            'temporal': temporal_score,\n",
    "            'total': total_confidence\n",
    "        }\n",
    "\n",
    "temporal_tracker = TemporalTracker(params)\n",
    "confidence_scorer = ConfidenceScorer(params)\n",
    "print(\"‚úÖ Temporal tracker and confidence scorer initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8697394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Advanced LED Detector ready!\n",
      "üìä Pipeline: Adaptive Preprocessing ‚Üí Frequency ‚Üí Color ‚Üí Flicker ‚Üí Temporal Tracking\n",
      "üéØ Optimized for 2.0Hz LEDs at 10-120m range\n"
     ]
    }
   ],
   "source": [
    "# ===== INTEGRATED DETECTION ENGINE =====\n",
    "\n",
    "class AdvancedLEDDetector:\n",
    "    \"\"\"Main detection engine combining all stages\"\"\"\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.preprocessor = AdaptivePreprocessor(params)\n",
    "        self.freq_analyzer = FrequencyAnalyzer(params)\n",
    "        self.color_detector = ColorDetector(params)\n",
    "        self.flicker_detector = FlickerDetector(params)\n",
    "        self.temporal_tracker = TemporalTracker(params)\n",
    "        self.confidence_scorer = ConfidenceScorer(params)\n",
    "        \n",
    "        self.frame_count = 0\n",
    "        self.grid_stats = []\n",
    "        \n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"Full detection pipeline on single frame\"\"\"\n",
    "        self.frame_count += 1\n",
    "        h, w = frame.shape[:2]\n",
    "        \n",
    "        # Stage 1: Adaptive preprocessing\n",
    "        gray, enhanced, binary = self.preprocessor.preprocess_frame(frame)\n",
    "        self.grid_stats = self.preprocessor.get_local_statistics(gray, self.params.GRID_SIZE)\n",
    "        \n",
    "        # Stage 2: Update frequency buffers for all grid cells\n",
    "        for stat in self.grid_stats:\n",
    "            grid_id = f\"{stat['position'][0]}_{stat['position'][1]}\"\n",
    "            self.freq_analyzer.add_intensity(grid_id, stat['mean'])\n",
    "        \n",
    "        # Stage 3: Color-based detection\n",
    "        color_candidates, color_mask = self.color_detector.detect_by_color(frame)\n",
    "        \n",
    "        # Stage 4: Combine with flicker analysis\n",
    "        detections = []\n",
    "        active_regions = []\n",
    "        \n",
    "        for candidate in color_candidates:\n",
    "            x, y, w, h = candidate['bbox']\n",
    "            center = candidate['center']\n",
    "            \n",
    "            # Get intensity from gray frame\n",
    "            roi = gray[y:y+h, x:x+w]\n",
    "            mean_intensity = np.mean(roi)\n",
    "            \n",
    "            # Create region ID\n",
    "            region_id = f\"reg_{center[0]}_{center[1]}\"\n",
    "            active_regions.append(region_id)\n",
    "            \n",
    "            # Update flicker detector\n",
    "            self.flicker_detector.add_region_intensity(region_id, mean_intensity)\n",
    "            flicker_result = self.flicker_detector.analyze_flicker(region_id)\n",
    "            \n",
    "            # Check frequency for grid cell containing this candidate\n",
    "            grid_x = center[0] // self.params.GRID_SIZE\n",
    "            grid_y = center[1] // self.params.GRID_SIZE\n",
    "            grid_id = f\"{grid_x}_{grid_y}\"\n",
    "            frequencies = self.freq_analyzer.analyze_frequency(grid_id)\n",
    "            freq_confidence = self.freq_analyzer.get_target_frequency_score(frequencies)\n",
    "            \n",
    "            # Build detection dict\n",
    "            detection = {\n",
    "                'bbox': candidate['bbox'],\n",
    "                'center': center,\n",
    "                'area': candidate['area'],\n",
    "                'color_confidence': candidate['color_confidence'],\n",
    "                'frequency_confidence': freq_confidence,\n",
    "                'flicker_confidence': flicker_result['confidence'],\n",
    "                'frequencies': frequencies[:3],  # Top 3 frequencies\n",
    "                'flicker_std': flicker_result['std']\n",
    "            }\n",
    "            \n",
    "            detections.append(detection)\n",
    "        \n",
    "        # Clean up old flicker regions\n",
    "        self.flicker_detector.clear_old_regions(active_regions)\n",
    "        \n",
    "        # Stage 5: Temporal tracking\n",
    "        tracked = self.temporal_tracker.update(detections)\n",
    "        \n",
    "        # Calculate final confidences\n",
    "        final_detections = []\n",
    "        for detection in detections:\n",
    "            total_conf, breakdown = self.confidence_scorer.calculate_confidence(detection)\n",
    "            detection['total_confidence'] = total_conf\n",
    "            detection['confidence_breakdown'] = breakdown\n",
    "            \n",
    "            if total_conf >= self.params.CONFIDENCE_THRESHOLD:\n",
    "                final_detections.append(detection)\n",
    "        \n",
    "        # Get confirmed objects\n",
    "        confirmed_leds = self.temporal_tracker.get_confirmed_objects()\n",
    "        \n",
    "        return {\n",
    "            'frame': frame,\n",
    "            'gray': gray,\n",
    "            'enhanced': enhanced,\n",
    "            'binary': binary,\n",
    "            'color_mask': color_mask,\n",
    "            'grid_stats': self.grid_stats,\n",
    "            'detections': final_detections,\n",
    "            'confirmed_leds': confirmed_leds,\n",
    "            'frame_count': self.frame_count\n",
    "        }\n",
    "    \n",
    "    def visualize_results(self, results, show_grid=True, show_frequencies=True, show_confidence=True):\n",
    "        \"\"\"Create visualization of detection results\"\"\"\n",
    "        frame = results['frame'].copy()\n",
    "        h, w = frame.shape[:2]\n",
    "        \n",
    "        # Draw grid (optional)\n",
    "        if show_grid:\n",
    "            for stat in results['grid_stats']:\n",
    "                x1, y1, x2, y2 = stat['bbox']\n",
    "                # Color code by intensity\n",
    "                if stat['mean'] > 200:\n",
    "                    color = (0, 255, 255)  # Yellow: bright\n",
    "                elif stat['mean'] > 150:\n",
    "                    color = (0, 165, 255)  # Orange: medium\n",
    "                else:\n",
    "                    color = (200, 200, 200)  # Gray: dim\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 1)\n",
    "        \n",
    "        # Draw detections\n",
    "        for det in results['detections']:\n",
    "            x, y, w, h = det['bbox']\n",
    "            conf = det['total_confidence']\n",
    "            \n",
    "            # Color by confidence\n",
    "            if conf > 0.7:\n",
    "                box_color = (0, 255, 0)  # Green: high confidence\n",
    "            elif conf > 0.5:\n",
    "                box_color = (0, 255, 255)  # Yellow: medium\n",
    "            else:\n",
    "                box_color = (0, 165, 255)  # Orange: low\n",
    "            \n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), box_color, 2)\n",
    "            \n",
    "            # Show confidence breakdown\n",
    "            if show_confidence:\n",
    "                breakdown = det['confidence_breakdown']\n",
    "                text = f\"C:{conf:.2f} F:{breakdown['frequency']:.2f} Col:{breakdown['color']:.2f} Fl:{breakdown['flicker']:.2f}\"\n",
    "                cv2.putText(frame, text, (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, box_color, 1)\n",
    "            \n",
    "            # Show frequencies\n",
    "            if show_frequencies and len(det['frequencies']) > 0:\n",
    "                freq_text = \", \".join([f\"{f['frequency']:.1f}Hz\" for f in det['frequencies'][:2]])\n",
    "                cv2.putText(frame, freq_text, (x, y+h+15), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "        \n",
    "        # Draw confirmed LEDs\n",
    "        for led in results['confirmed_leds']:\n",
    "            x, y, w, h = led['bbox']\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 3)  # Red: confirmed\n",
    "            cv2.putText(frame, f\"LED #{led['id']}\", (x, y-20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "        \n",
    "        # Add summary\n",
    "        summary = f\"Frame: {results['frame_count']} | Detections: {len(results['detections'])} | Confirmed LEDs: {len(results['confirmed_leds'])}\"\n",
    "        cv2.putText(frame, summary, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        return frame\n",
    "\n",
    "# Create detector instance\n",
    "detector = AdvancedLEDDetector(params)\n",
    "print(\"‚úÖ Advanced LED Detector ready!\")\n",
    "print(\"üìä Pipeline: Adaptive Preprocessing ‚Üí Frequency ‚Üí Color ‚Üí Flicker ‚Üí Temporal Tracking\")\n",
    "print(f\"üéØ Optimized for {params.LED_FREQ_TARGET}Hz LEDs at 10-120m range\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4709fbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Advanced GUI created\n"
     ]
    }
   ],
   "source": [
    "# ===== ADVANCED PARAMETER CONTROL GUI =====\n",
    "\n",
    "class AdvancedLEDDetectionGUI:\n",
    "    \"\"\"Comprehensive GUI with all parameter controls\"\"\"\n",
    "    \n",
    "    def __init__(self, master, detector):\n",
    "        self.master = master\n",
    "        self.detector = detector\n",
    "        self.params = detector.params\n",
    "        \n",
    "        self.master.title(\"Advanced LED Detection System - 2Hz DC LEDs (10-120m)\")\n",
    "        self.master.geometry(\"1600x900\")\n",
    "        \n",
    "        self.is_running = False\n",
    "        self.frame_queue = queue.Queue(maxsize=3)\n",
    "        self.show_grid = tk.BooleanVar(value=True)\n",
    "        self.show_frequencies = tk.BooleanVar(value=True)\n",
    "        self.show_confidence = tk.BooleanVar(value=True)\n",
    "        \n",
    "        # Video source (for testing - replace with camera)\n",
    "        self.test_mode = True\n",
    "        self.test_frame_count = 0\n",
    "        \n",
    "        self.create_widgets()\n",
    "        \n",
    "    def create_widgets(self):\n",
    "        \"\"\"Build main GUI layout\"\"\"\n",
    "        # Main container\n",
    "        main_container = ttk.Frame(self.master)\n",
    "        main_container.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "        \n",
    "        # Top: Control buttons\n",
    "        control_frame = ttk.Frame(main_container)\n",
    "        control_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "        \n",
    "        ttk.Button(control_frame, text=\"‚ñ∂ Start Detection\", command=self.start_detection, width=18).pack(side=tk.LEFT, padx=5)\n",
    "        ttk.Button(control_frame, text=\"‚èπ Stop Detection\", command=self.stop_detection, width=18).pack(side=tk.LEFT, padx=5)\n",
    "        ttk.Checkbutton(control_frame, text=\"Show Grid\", variable=self.show_grid).pack(side=tk.LEFT, padx=10)\n",
    "        ttk.Checkbutton(control_frame, text=\"Show Frequencies\", variable=self.show_frequencies).pack(side=tk.LEFT, padx=10)\n",
    "        ttk.Checkbutton(control_frame, text=\"Show Confidence\", variable=self.show_confidence).pack(side=tk.LEFT, padx=10)\n",
    "        \n",
    "        # Content area\n",
    "        content_frame = ttk.Frame(main_container)\n",
    "        content_frame.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Left: Video display\n",
    "        video_frame = ttk.LabelFrame(content_frame, text=\"Detection View\", padding=10)\n",
    "        video_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=(0, 10))\n",
    "        \n",
    "        self.video_canvas = tk.Canvas(video_frame, bg='black', width=960, height=720)\n",
    "        self.video_canvas.pack()\n",
    "        \n",
    "        # Status labels\n",
    "        status_frame = ttk.Frame(video_frame)\n",
    "        status_frame.pack(fill=tk.X, pady=(10, 0))\n",
    "        \n",
    "        self.fps_label = ttk.Label(status_frame, text=\"FPS: 0.0\")\n",
    "        self.fps_label.pack(side=tk.LEFT, padx=10)\n",
    "        \n",
    "        self.detections_label = ttk.Label(status_frame, text=\"Detections: 0\")\n",
    "        self.detections_label.pack(side=tk.LEFT, padx=10)\n",
    "        \n",
    "        self.confirmed_label = ttk.Label(status_frame, text=\"Confirmed LEDs: 0\")\n",
    "        self.confirmed_label.pack(side=tk.LEFT, padx=10)\n",
    "        \n",
    "        # Right: Parameters\n",
    "        params_frame = ttk.LabelFrame(content_frame, text=\"Detection Parameters\", padding=10)\n",
    "        params_frame.pack(side=tk.RIGHT, fill=tk.BOTH)\n",
    "        \n",
    "        # Create tabbed parameter interface\n",
    "        notebook = ttk.Notebook(params_frame)\n",
    "        notebook.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Tab 1: Grid & Preprocessing\n",
    "        tab1 = ttk.Frame(notebook)\n",
    "        notebook.add(tab1, text=\"Grid & Preprocessing\")\n",
    "        self.create_preprocessing_controls(tab1)\n",
    "        \n",
    "        # Tab 2: Frequency Analysis\n",
    "        tab2 = ttk.Frame(notebook)\n",
    "        notebook.add(tab2, text=\"Frequency Analysis\")\n",
    "        self.create_frequency_controls(tab2)\n",
    "        \n",
    "        # Tab 3: Color Detection\n",
    "        tab3 = ttk.Frame(notebook)\n",
    "        notebook.add(tab3, text=\"Color Detection\")\n",
    "        self.create_color_controls(tab3)\n",
    "        \n",
    "        # Tab 4: Flicker & Temporal\n",
    "        tab4 = ttk.Frame(notebook)\n",
    "        notebook.add(tab4, text=\"Flicker & Tracking\")\n",
    "        self.create_flicker_controls(tab4)\n",
    "        \n",
    "        # Tab 5: Confidence Weights\n",
    "        tab5 = ttk.Frame(notebook)\n",
    "        notebook.add(tab5, text=\"Confidence Scoring\")\n",
    "        self.create_confidence_controls(tab5)\n",
    "    \n",
    "    def create_preprocessing_controls(self, parent):\n",
    "        \"\"\"Preprocessing parameters\"\"\"\n",
    "        scroll_frame = self.create_scrollable(parent)\n",
    "        row = 0\n",
    "        \n",
    "        ttk.Label(scroll_frame, text=\"Adaptive Thresholding\", font=('Arial', 10, 'bold')).grid(row=row, column=0, columnspan=3, sticky=tk.W, pady=(0,10))\n",
    "        row += 1\n",
    "        \n",
    "        self.add_slider(scroll_frame, \"Grid Size\", self.params, 'GRID_SIZE', 40, 200, row)\n",
    "        row += 1\n",
    "        self.add_slider(scroll_frame, \"Block Size (odd)\", self.params, 'ADAPTIVE_BLOCK_SIZE', 3, 31, row, step=2)\n",
    "        row += 1\n",
    "        self.add_slider(scroll_frame, \"Adaptive C\", self.params, 'ADAPTIVE_C', -10, 10, row, resolution=0.5)\n",
    "        row += 1\n",
    "        \n",
    "        ttk.Label(scroll_frame, text=\"Method:\", font=('Arial', 9)).grid(row=row, column=0, sticky=tk.W)\n",
    "        method_var = tk.StringVar(value=self.params.ADAPTIVE_METHOD)\n",
    "        ttk.Radiobutton(scroll_frame, text=\"Gaussian\", variable=method_var, value='gaussian',\n",
    "                       command=lambda: setattr(self.params, 'ADAPTIVE_METHOD', method_var.get())).grid(row=row, column=1)\n",
    "        ttk.Radiobutton(scroll_frame, text=\"Mean\", variable=method_var, value='mean',\n",
    "                       command=lambda: setattr(self.params, 'ADAPTIVE_METHOD', method_var.get())).grid(row=row, column=2)\n",
    "    \n",
    "    def create_frequency_controls(self, parent):\n",
    "        \"\"\"Frequency analysis parameters\"\"\"\n",
    "        scroll_frame = self.create_scrollable(parent)\n",
    "        row = 0\n",
    "        \n",
    "        ttk.Label(scroll_frame, text=\"FFT Configuration\", font=('Arial', 10, 'bold')).grid(row=row, column=0, columnspan=3, sticky=tk.W, pady=(0,10))\n",
    "        row += 1\n",
    "        \n",
    "        self.add_slider(scroll_frame, \"Target Frequency (Hz)\", self.params, 'LED_FREQ_TARGET', 0.5, 10, row, resolution=0.1)\n",
    "        row += 1\n",
    "        self.add_slider(scroll_frame, \"Frequency Tolerance\", self.params, 'FREQ_TOLERANCE', 0.1, 2.0, row, resolution=0.1)\n",
    "        row += 1\n",
    "        self.add_slider(scroll_frame, \"Buffer Size (frames)\", self.params, 'FREQ_BUFFER_SIZE', 30, 120, row)\n",
    "        row += 1\n",
    "        self.add_slider(scroll_frame, \"FFT Threshold\", self.params, 'FFT_THRESHOLD', 1.0, 10.0, row, resolution=0.1)\n",
    "        row += 1\n",
    "        self.add_slider(scroll_frame, \"Min Frequency\", self.params, 'MIN_FREQ', 0.1, 5.0, row, resolution=0.1)\n",
    "        row += 1\n",
    "        self.add_slider(scroll_frame, \"Max Frequency\", self.params, 'MAX_FREQ', 5.0, 20.0, row, resolution=0.1)\n",
    "    \n",
    "    def create_color_controls(self, parent):\n",
    "        \"\"\"Color detection parameters\"\"\"\n",
    "        scroll_frame = self.create_scrollable(parent)\n",
    "        row = 0\n",
    "        \n",
    "        ttk.Label(scroll_frame, text=\"HSV Range 1 (Bright Yellow)\", font=('Arial', 10, 'bold')).grid(row=row, column=0, columnspan=3, sticky=tk.W, pady=(0,10))\n",
    "        row += 1\n",
    "        \n",
    "        # Simplified: show only first HSV range for adjustment\n",
    "        ttk.Label(scroll_frame, text=\"Lower: H\", font=('Arial', 8)).grid(row=row, column=0, sticky=tk.W)\n",
    "        h_lower = tk.IntVar(value=self.params.HSV_RANGES[0][0][0])\n",
    "        ttk.Scale(scroll_frame, from_=0, to=179, variable=h_lower, orient=tk.HORIZONTAL, length=150,\n",
    "                 command=lambda v: self.update_hsv_range(0, 0, 0, int(float(v)))).grid(row=row, column=1, columnspan=2)\n",
    "        row += 1\n",
    "        \n",
    "        ttk.Label(scroll_frame, text=\"LAB Color Space\", font=('Arial', 10, 'bold')).grid(row=row, column=0, columnspan=3, sticky=tk.W, pady=(10,10))\n",
    "        row += 1\n",
    "        self.add_slider(scroll_frame, \"Min Lightness\", self.params, 'LAB_L_MIN', 50, 200, row)\n",
    "        row += 1\n",
    "        \n",
    "        ttk.Label(scroll_frame, text=\"Size Filtering\", font=('Arial', 10, 'bold')).grid(row=row, column=0, columnspan=3, sticky=tk.W, pady=(10,10))\n",
    "        row += 1\n",
    "        self.add_slider(scroll_frame, \"Min Area (pixels)\", self.params, 'MIN_AREA', 10, 500, row)\n",
    "        row += 1\n",
    "        self.add_slider(scroll_frame, \"Max Area (pixels)\", self.params, 'MAX_AREA', 1000, 20000, row, step=100)\n",
    "        row += 1\n",
    "        self.add_slider(scroll_frame, \"Max Aspect Ratio\", self.params, 'ASPECT_RATIO_MAX', 1.0, 5.0, row, resolution=0.1)\n",
    "    \n",
    "    def create_flicker_controls(self, parent):\n",
    "        \"\"\"Flicker and temporal tracking parameters\"\"\"\n",
    "        scroll_frame = self.create_scrollable(parent)\n",
    "        row = 0\n",
    "        \n",
    "        ttk.Label(scroll_frame, text=\"Flicker Detection\", font=('Arial', 10, 'bold')).grid(row=row, column=0, columnspan=3, sticky=tk.W, pady=(0,10))\n",
    "        row += 1\n",
    "        \n",
    "        self.add_slider(scroll_frame, \"Flicker Buffer Size\", self.params, 'FLICKER_BUFFER_SIZE', 10, 60, row)\n",
    "        row += 1\n",
    "        self.add_slider(scroll_frame, \"Std Dev Threshold\", self.params, 'FLICKER_STD_THRESHOLD', 5.0, 50.0, row, resolution=1.0)\n",
    "        row += 1\n",
    "        self.add_slider(scroll_frame, \"Intensity Change Threshold\", self.params, 'INTENSITY_CHANGE_THRESHOLD', 10, 100, row)\n",
    "        row += 1\n",
    "        \n",
    "        ttk.Label(scroll_frame, text=\"Temporal Tracking\", font=('Arial', 10, 'bold')).grid(row=row, column=0, columnspan=3, sticky=tk.W, pady=(10,10))\n",
    "        row += 1\n",
    "        \n",
    "        self.add_slider(scroll_frame, \"Temporal Buffer Size\", self.params, 'TEMPORAL_BUFFER_SIZE', 5, 30, row)\n",
    "        row += 1\n",
    "        self.add_slider(scroll_frame, \"Min Detections to Confirm\", self.params, 'MIN_DETECTIONS', 3, 15, row)\n",
    "        row += 1\n",
    "        self.add_slider(scroll_frame, \"Position Tolerance\", self.params, 'POSITION_TOLERANCE', 10, 100, row)\n",
    "    \n",
    "    def create_confidence_controls(self, parent):\n",
    "        \"\"\"Confidence scoring weights\"\"\"\n",
    "        scroll_frame = self.create_scrollable(parent)\n",
    "        row = 0\n",
    "        \n",
    "        ttk.Label(scroll_frame, text=\"Method Weights (must sum to 1.0)\", font=('Arial', 10, 'bold')).grid(row=row, column=0, columnspan=3, sticky=tk.W, pady=(0,10))\n",
    "        row += 1\n",
    "        \n",
    "        self.add_slider(scroll_frame, \"Frequency Weight\", self.params, 'WEIGHT_FREQUENCY', 0.0, 1.0, row, resolution=0.05)\n",
    "        row += 1\n",
    "        self.add_slider(scroll_frame, \"Color Weight\", self.params, 'WEIGHT_COLOR', 0.0, 1.0, row, resolution=0.05)\n",
    "        row += 1\n",
    "        self.add_slider(scroll_frame, \"Flicker Weight\", self.params, 'WEIGHT_FLICKER', 0.0, 1.0, row, resolution=0.05)\n",
    "        row += 1\n",
    "        self.add_slider(scroll_frame, \"Temporal Weight\", self.params, 'WEIGHT_TEMPORAL', 0.0, 1.0, row, resolution=0.05)\n",
    "        row += 1\n",
    "        \n",
    "        ttk.Separator(scroll_frame, orient='horizontal').grid(row=row, column=0, columnspan=3, sticky='ew', pady=10)\n",
    "        row += 1\n",
    "        \n",
    "        self.add_slider(scroll_frame, \"Confidence Threshold\", self.params, 'CONFIDENCE_THRESHOLD', 0.0, 1.0, row, resolution=0.05)\n",
    "    \n",
    "    def create_scrollable(self, parent):\n",
    "        \"\"\"Create scrollable frame for parameters\"\"\"\n",
    "        canvas = tk.Canvas(parent, height=600)\n",
    "        scrollbar = ttk.Scrollbar(parent, orient=\"vertical\", command=canvas.yview)\n",
    "        scrollable_frame = ttk.Frame(canvas)\n",
    "        \n",
    "        scrollable_frame.bind(\"<Configure>\", lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\")))\n",
    "        canvas.create_window((0, 0), window=scrollable_frame, anchor=\"nw\")\n",
    "        canvas.configure(yscrollcommand=scrollbar.set)\n",
    "        \n",
    "        canvas.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "        scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "        \n",
    "        return scrollable_frame\n",
    "    \n",
    "    def add_slider(self, parent, label, params_obj, attr_name, min_val, max_val, row, resolution=1, step=1):\n",
    "        \"\"\"Add parameter slider with label and value display\"\"\"\n",
    "        ttk.Label(parent, text=label, font=('Arial', 8)).grid(row=row, column=0, sticky=tk.W, padx=5, pady=2)\n",
    "        \n",
    "        current_val = getattr(params_obj, attr_name)\n",
    "        var = tk.DoubleVar(value=current_val) if resolution < 1 else tk.IntVar(value=current_val)\n",
    "        \n",
    "        slider = ttk.Scale(parent, from_=min_val, to=max_val, variable=var, orient=tk.HORIZONTAL, length=200)\n",
    "        slider.grid(row=row, column=1, padx=5)\n",
    "        \n",
    "        value_label = ttk.Label(parent, text=f\"{current_val}\", font=('Arial', 9, 'bold'), width=8)\n",
    "        value_label.grid(row=row, column=2, padx=5)\n",
    "        \n",
    "        def update(val):\n",
    "            new_val = round(float(val) / step) * step if step != 1 else float(val)\n",
    "            if resolution >= 1:\n",
    "                new_val = int(new_val)\n",
    "            setattr(params_obj, attr_name, new_val)\n",
    "            value_label.config(text=f\"{new_val}\")\n",
    "        \n",
    "        slider.configure(command=update)\n",
    "    \n",
    "    def update_hsv_range(self, range_idx, bound_idx, channel, value):\n",
    "        \"\"\"Update HSV range values\"\"\"\n",
    "        self.params.HSV_RANGES[range_idx][bound_idx][channel] = value\n",
    "    \n",
    "    def start_detection(self):\n",
    "        \"\"\"Start detection loop\"\"\"\n",
    "        if not self.is_running:\n",
    "            self.is_running = True\n",
    "            threading.Thread(target=self.detection_loop, daemon=True).start()\n",
    "            self.update_display()\n",
    "    \n",
    "    def stop_detection(self):\n",
    "        \"\"\"Stop detection\"\"\"\n",
    "        self.is_running = False\n",
    "    \n",
    "    def detection_loop(self):\n",
    "        \"\"\"Main detection processing loop\"\"\"\n",
    "        fps_counter = 0\n",
    "        fps_start = time.time()\n",
    "        \n",
    "        while self.is_running:\n",
    "            try:\n",
    "                # Generate test frame (replace with camera frame)\n",
    "                test_frame = self.generate_test_frame()\n",
    "                \n",
    "                # Process frame\n",
    "                results = self.detector.process_frame(test_frame)\n",
    "                \n",
    "                # Visualize\n",
    "                vis_frame = self.detector.visualize_results(\n",
    "                    results,\n",
    "                    show_grid=self.show_grid.get(),\n",
    "                    show_frequencies=self.show_frequencies.get(),\n",
    "                    show_confidence=self.show_confidence.get()\n",
    "                )\n",
    "                \n",
    "                # Queue for display\n",
    "                if not self.frame_queue.full():\n",
    "                    self.frame_queue.put_nowait((vis_frame, results))\n",
    "                \n",
    "                # Calculate FPS\n",
    "                fps_counter += 1\n",
    "                if time.time() - fps_start >= 1.0:\n",
    "                    fps = fps_counter / (time.time() - fps_start)\n",
    "                    fps_counter = 0\n",
    "                    fps_start = time.time()\n",
    "                    self.master.after(0, lambda: self.fps_label.config(text=f\"FPS: {fps:.1f}\"))\n",
    "                \n",
    "                time.sleep(0.033)  # ~30 FPS\n",
    "            except Exception as e:\n",
    "                print(f\"Detection error: {e}\")\n",
    "                time.sleep(0.1)\n",
    "    \n",
    "    def update_display(self):\n",
    "        \"\"\"Update video display from queue\"\"\"\n",
    "        if self.is_running:\n",
    "            try:\n",
    "                while not self.frame_queue.empty():\n",
    "                    vis_frame, results = self.frame_queue.get_nowait()\n",
    "                    self.display_frame(vis_frame)\n",
    "                    \n",
    "                    # Update status\n",
    "                    self.detections_label.config(text=f\"Detections: {len(results['detections'])}\")\n",
    "                    self.confirmed_label.config(text=f\"Confirmed LEDs: {len(results['confirmed_leds'])}\")\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            self.master.after(30, self.update_display)\n",
    "    \n",
    "    def display_frame(self, frame):\n",
    "        \"\"\"Display frame on canvas\"\"\"\n",
    "        if frame is None:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Convert BGR to RGB\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Resize to fit canvas\n",
    "            h, w = frame_rgb.shape[:2]\n",
    "            canvas_w, canvas_h = 960, 720\n",
    "            scale = min(canvas_w/w, canvas_h/h)\n",
    "            new_w, new_h = int(w * scale), int(h * scale)\n",
    "            \n",
    "            resized = cv2.resize(frame_rgb, (new_w, new_h))\n",
    "            \n",
    "            # Convert to PhotoImage\n",
    "            img = Image.fromarray(resized)\n",
    "            photo = ImageTk.PhotoImage(img)\n",
    "            \n",
    "            # Display\n",
    "            self.video_canvas.delete(\"all\")\n",
    "            self.video_canvas.create_image(canvas_w//2, canvas_h//2, image=photo)\n",
    "            self.video_canvas.image = photo\n",
    "        except Exception as e:\n",
    "            print(f\"Display error: {e}\")\n",
    "    \n",
    "    def generate_test_frame(self):\n",
    "        \"\"\"Generate test frame with simulated LEDs (replace with camera)\"\"\"\n",
    "        self.test_frame_count += 1\n",
    "        \n",
    "        # Create blank frame\n",
    "        frame = np.random.randint(50, 100, (480, 640, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Add simulated LEDs (flickering yellow dots)\n",
    "        for i in range(3):\n",
    "            x, y = 150 + i * 200, 200 + i * 50\n",
    "            intensity = 200 + 55 * np.sin(2 * np.pi * 2 * self.test_frame_count / 30)  # 2 Hz flicker\n",
    "            color = (0, int(intensity), int(intensity))  # Yellow in BGR\n",
    "            cv2.circle(frame, (x, y), 15, color, -1)\n",
    "        \n",
    "        return frame\n",
    "\n",
    "print(\"‚úÖ Advanced GUI created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a83b9198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Application launcher ready\n",
      "\n",
      "To start:\n",
      "  launch_detection_system('test')  # Test mode with simulated LEDs\n",
      "  launch_detection_system('rtsp', 'rtsp://your_camera_ip')  # Real camera\n",
      "  launch_detection_system('file', 'path/to/video.mp4')  # Video file\n"
     ]
    }
   ],
   "source": [
    "# ===== CAMERA SERVICE & APPLICATION LAUNCHER =====\n",
    "\n",
    "class CameraService:\n",
    "    \"\"\"Handle video input from RTSP, file, or webcam\"\"\"\n",
    "    \n",
    "    def __init__(self, source_type='test', source_path=None):\n",
    "        self.source_type = source_type  # 'test', 'rtsp', 'file', 'webcam'\n",
    "        self.source_path = source_path\n",
    "        self.cap = None\n",
    "        self.is_connected = False\n",
    "        \n",
    "    def connect(self):\n",
    "        \"\"\"Initialize video source\"\"\"\n",
    "        try:\n",
    "            if self.source_type == 'rtsp':\n",
    "                self.cap = cv2.VideoCapture(self.source_path)\n",
    "            elif self.source_type == 'file':\n",
    "                self.cap = cv2.VideoCapture(self.source_path)\n",
    "            elif self.source_type == 'webcam':\n",
    "                self.cap = cv2.VideoCapture(0)\n",
    "            elif self.source_type == 'test':\n",
    "                self.is_connected = True\n",
    "                return True\n",
    "            \n",
    "            if self.cap and self.cap.isOpened():\n",
    "                self.is_connected = True\n",
    "                return True\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"Camera connection failed: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get_frame(self):\n",
    "        \"\"\"Read next frame\"\"\"\n",
    "        if self.source_type == 'test':\n",
    "            return self.generate_test_frame()\n",
    "        \n",
    "        if self.cap and self.is_connected:\n",
    "            ret, frame = self.cap.read()\n",
    "            return frame if ret else None\n",
    "        return None\n",
    "    \n",
    "    def generate_test_frame(self):\n",
    "        \"\"\"Generate test frame with simulated 2Hz LEDs\"\"\"\n",
    "        frame_num = int(time.time() * 30) % 1000\n",
    "        \n",
    "        # Background\n",
    "        frame = np.random.randint(40, 80, (480, 640, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Add 3 simulated LEDs with 2Hz flicker\n",
    "        led_positions = [(150, 200), (320, 180), (500, 250)]\n",
    "        for x, y in led_positions:\n",
    "            # 2Hz sine wave (60 frames per cycle at 30fps)\n",
    "            intensity = 180 + 75 * np.sin(2 * np.pi * 2 * frame_num / 30)\n",
    "            color = (0, int(intensity * 0.9), int(intensity))  # Yellow in BGR\n",
    "            size = np.random.randint(12, 18)\n",
    "            cv2.circle(frame, (x, y), size, color, -1)\n",
    "            # Add slight glow\n",
    "            cv2.circle(frame, (x, y), size + 5, color, 2)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def disconnect(self):\n",
    "        \"\"\"Release resources\"\"\"\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        self.is_connected = False\n",
    "\n",
    "\n",
    "class LEDDetectionApp:\n",
    "    \"\"\"Main application launcher\"\"\"\n",
    "    \n",
    "    def __init__(self, camera_source='test', camera_path=None):\n",
    "        self.root = tk.Tk()\n",
    "        \n",
    "        # Initialize detection system\n",
    "        self.params = DetectionParams()\n",
    "        self.detector = AdvancedLEDDetector(self.params)\n",
    "        \n",
    "        # Initialize camera\n",
    "        self.camera = CameraService(camera_source, camera_path)\n",
    "        if not self.camera.connect():\n",
    "            print(\"‚ö† Camera connection failed, using test mode\")\n",
    "            self.camera = CameraService('test')\n",
    "            self.camera.connect()\n",
    "        \n",
    "        # Create GUI\n",
    "        self.gui = AdvancedLEDDetectionGUI(self.root, self.detector)\n",
    "        \n",
    "        # Modify GUI to use camera service\n",
    "        self.gui.generate_test_frame = self.camera.get_frame\n",
    "        \n",
    "        print(\"‚úÖ LED Detection System initialized\")\n",
    "        print(f\"   Camera: {camera_source}\")\n",
    "        print(f\"   Target: 2Hz DC LEDs\")\n",
    "        print(f\"   Range: 10-120 meters\")\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"Start application\"\"\"\n",
    "        try:\n",
    "            print(\"\\nüöÄ Starting GUI...\")\n",
    "            self.root.mainloop()\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n‚èπ Shutting down...\")\n",
    "        finally:\n",
    "            self.camera.disconnect()\n",
    "\n",
    "\n",
    "# ===== LAUNCH APPLICATION =====\n",
    "\n",
    "def launch_detection_system(camera_type='test', camera_path=None):\n",
    "    \"\"\"\n",
    "    Launch LED detection system\n",
    "    \n",
    "    Args:\n",
    "        camera_type: 'test', 'rtsp', 'file', 'webcam'\n",
    "        camera_path: Path for RTSP/file sources\n",
    "    \n",
    "    Examples:\n",
    "        launch_detection_system('test')\n",
    "        launch_detection_system('rtsp', 'rtsp://192.168.1.100:8080/video')\n",
    "        launch_detection_system('file', 'video.mp4')\n",
    "        launch_detection_system('webcam')\n",
    "    \"\"\"\n",
    "    app = LEDDetectionApp(camera_type, camera_path)\n",
    "    app.run()\n",
    "\n",
    "\n",
    "print(\"‚úÖ Application launcher ready\")\n",
    "print(\"\\nTo start:\")\n",
    "print(\"  launch_detection_system('test')  # Test mode with simulated LEDs\")\n",
    "print(\"  launch_detection_system('rtsp', 'rtsp://your_camera_ip')  # Real camera\")\n",
    "print(\"  launch_detection_system('file', 'path/to/video.mp4')  # Video file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7e35eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LED Detection System initialized\n",
      "   Camera: test\n",
      "   Target: 2Hz DC LEDs\n",
      "   Range: 10-120 meters\n",
      "\n",
      "üöÄ Starting GUI...\n"
     ]
    }
   ],
   "source": [
    "# ===== LAUNCH THE APPLICATION =====\n",
    "\n",
    "# To start the GUI with test LEDs (simulated):\n",
    "launch_detection_system('test')\n",
    "\n",
    "# For real camera (RTSP):\n",
    "# launch_detection_system('rtsp', 'rtsp://192.168.1.100:8080/video')\n",
    "\n",
    "# For video file:\n",
    "# launch_detection_system('file', 'path/to/video.mp4')\n",
    "\n",
    "# For webcam:\n",
    "# launch_detection_system('webcam')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
