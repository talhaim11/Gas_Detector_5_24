{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456c734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dedd679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "# Dataset paths\n",
    "NO_DETECTOR_DIR = r\"C:\\Users\\thaim\\Videos\\AI_LEDS\\cropped_no_detector_pictures\"\n",
    "DETECTOR_DIR = r\"C:\\Users\\thaim\\Videos\\AI_LEDS\\cropped_detector_pictures\"\n",
    "\n",
    "# Output paths\n",
    "OUTPUT_DIR = r\"C:\\Users\\thaim\\Videos\\AI_LEDS\\model_output\"\n",
    "MODEL_NAME = \"detector_classifier_mobilenetv2\"\n",
    "\n",
    "# Image settings\n",
    "IMG_SIZE = 224  # MobileNetV2 standard input size\n",
    "BATCH_SIZE = 32  # Adjust based on GPU memory (16/32/64)\n",
    "\n",
    "# Training settings\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 0.001\n",
    "TEST_SIZE = 0.1      # 10% for test\n",
    "VAL_SIZE = 0.1       # 10% for validation (from remaining 90%)\n",
    "\n",
    "# Data augmentation for detector class (minority class)\n",
    "AUGMENTATION_ENABLED = True\n",
    "\n",
    "# Create output directory\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfe9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare dataset\n",
    "\n",
    "def load_image_paths(directory, label):\n",
    "    \"\"\"Load all image paths from directory recursively\"\"\"\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "    paths = []\n",
    "    \n",
    "    dir_path = Path(directory)\n",
    "    for ext in image_extensions:\n",
    "        paths.extend(dir_path.rglob(f'*{ext}'))\n",
    "    \n",
    "    return [(str(p), label) for p in paths]\n",
    "\n",
    "print(\"Loading image paths...\")\n",
    "no_detector_data = load_image_paths(NO_DETECTOR_DIR, 0)  # Label 0 = No detector\n",
    "detector_data = load_image_paths(DETECTOR_DIR, 1)        # Label 1 = Detector\n",
    "\n",
    "print(f\"No detector images: {len(no_detector_data)}\")\n",
    "print(f\"Detector images: {len(detector_data)}\")\n",
    "print(f\"Total images: {len(no_detector_data) + len(detector_data)}\")\n",
    "print(f\"Class imbalance ratio: {len(no_detector_data) / len(detector_data):.2f}:1\")\n",
    "\n",
    "# Combine and shuffle\n",
    "all_data = no_detector_data + detector_data\n",
    "np.random.shuffle(all_data)\n",
    "\n",
    "# Separate paths and labels\n",
    "image_paths = [d[0] for d in all_data]\n",
    "labels = np.array([d[1] for d in all_data])\n",
    "\n",
    "# Split: first 10% for test, then split remaining into train/val\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    image_paths, labels, test_size=TEST_SIZE, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Split remaining into train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=VAL_SIZE/(1-TEST_SIZE), stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset split:\")\n",
    "print(f\"Train: {len(X_train)} images\")\n",
    "print(f\"Validation: {len(X_val)} images\")\n",
    "print(f\"Test: {len(X_test)} images\")\n",
    "print(f\"\\nTrain class distribution:\")\n",
    "print(f\"  No detector: {np.sum(y_train == 0)}\")\n",
    "print(f\"  Detector: {np.sum(y_train == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4432604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators with augmentation\n",
    "\n",
    "# Augmentation for training detector images only (minority class)\n",
    "train_detector_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ") if AUGMENTATION_ENABLED else ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# No augmentation for no_detector class and validation/test\n",
    "train_no_detector_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "def create_generator(paths, labels, datagen, batch_size, augment_class=None):\n",
    "    \"\"\"Create data generator from image paths\"\"\"\n",
    "    def generator():\n",
    "        indices = np.arange(len(paths))\n",
    "        while True:\n",
    "            np.random.shuffle(indices)\n",
    "            for start in range(0, len(paths), batch_size):\n",
    "                end = min(start + batch_size, len(paths))\n",
    "                batch_indices = indices[start:end]\n",
    "                \n",
    "                batch_images = []\n",
    "                batch_labels = []\n",
    "                \n",
    "                for idx in batch_indices:\n",
    "                    img_path = paths[idx]\n",
    "                    label = labels[idx]\n",
    "                    \n",
    "                    img = tf.keras.preprocessing.image.load_img(\n",
    "                        img_path, target_size=(IMG_SIZE, IMG_SIZE)\n",
    "                    )\n",
    "                    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "                    \n",
    "                    # Apply augmentation only to specified class\n",
    "                    if augment_class is None or label == augment_class:\n",
    "                        img_array = datagen.random_transform(img_array)\n",
    "                    \n",
    "                    img_array = img_array / 255.0\n",
    "                    batch_images.append(img_array)\n",
    "                    batch_labels.append(label)\n",
    "                \n",
    "                yield np.array(batch_images), np.array(batch_labels)\n",
    "    \n",
    "    return generator\n",
    "\n",
    "# Create generators\n",
    "train_generator = create_generator(\n",
    "    X_train, y_train, train_detector_datagen, BATCH_SIZE, augment_class=1\n",
    ")\n",
    "\n",
    "val_generator = create_generator(\n",
    "    X_val, y_val, val_test_datagen, BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    train_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, IMG_SIZE, IMG_SIZE, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
    "    )\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    val_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, IMG_SIZE, IMG_SIZE, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
    "    )\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Calculate steps per epoch\n",
    "steps_per_epoch = len(X_train) // BATCH_SIZE\n",
    "validation_steps = len(X_val) // BATCH_SIZE\n",
    "\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"Validation steps: {validation_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cac851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model with MobileNetV2 transfer learning\n",
    "\n",
    "# Load pre-trained MobileNetV2 (without top classification layer)\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Freeze base model layers (transfer learning)\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build model\n",
    "model = keras.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "# Calculate class weights to handle imbalance\n",
    "total_samples = len(y_train)\n",
    "n_class_0 = np.sum(y_train == 0)\n",
    "n_class_1 = np.sum(y_train == 1)\n",
    "\n",
    "weight_0 = total_samples / (2 * n_class_0)\n",
    "weight_1 = total_samples / (2 * n_class_1)\n",
    "\n",
    "class_weights = {0: weight_0, 1: weight_1}\n",
    "\n",
    "print(f\"\\nClass weights:\")\n",
    "print(f\"  No detector (class 0): {weight_0:.4f}\")\n",
    "print(f\"  Detector (class 1): {weight_1:.4f}\")\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "print(f\"\\nTotal parameters: {model.count_params():,}\")\n",
    "print(f\"Trainable parameters: {sum([tf.size(w).numpy() for w in model.trainable_weights]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bffe2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    # Early stopping - stop if validation loss doesn't improve for 5 epochs\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Reduce learning rate if validation loss plateaus\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Save best model during training\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_best.h5'),\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # TensorBoard logging\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir=os.path.join(OUTPUT_DIR, 'logs'),\n",
    "        histogram_freq=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258bf561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and save model\n",
    "\n",
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 0].plot(history.history['accuracy'], label='Train')\n",
    "axes[0, 0].plot(history.history['val_accuracy'], label='Validation')\n",
    "axes[0, 0].set_title('Model Accuracy')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Loss\n",
    "axes[0, 1].plot(history.history['loss'], label='Train')\n",
    "axes[0, 1].plot(history.history['val_loss'], label='Validation')\n",
    "axes[0, 1].set_title('Model Loss')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Precision\n",
    "axes[1, 0].plot(history.history['precision'], label='Train')\n",
    "axes[1, 0].plot(history.history['val_precision'], label='Validation')\n",
    "axes[1, 0].set_title('Model Precision')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Precision')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Recall\n",
    "axes[1, 1].plot(history.history['recall'], label='Train')\n",
    "axes[1, 1].plot(history.history['val_recall'], label='Validation')\n",
    "axes[1, 1].set_title('Model Recall')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Recall')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'training_history.png'), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_generator = create_generator(X_test, y_test, val_test_datagen, BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    test_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, IMG_SIZE, IMG_SIZE, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
    "    )\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_steps = len(X_test) // BATCH_SIZE\n",
    "test_results = model.evaluate(test_dataset, steps=test_steps, verbose=1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Loss: {test_results[0]:.4f}\")\n",
    "print(f\"Accuracy: {test_results[1]:.4f}\")\n",
    "print(f\"Precision: {test_results[2]:.4f}\")\n",
    "print(f\"Recall: {test_results[3]:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save final model in multiple formats\n",
    "print(\"\\nSaving model...\")\n",
    "\n",
    "# Save as .h5 (single file)\n",
    "h5_path = os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_final.h5')\n",
    "model.save(h5_path)\n",
    "print(f\"✓ Saved as .h5: {h5_path}\")\n",
    "\n",
    "# Save as SavedModel (folder)\n",
    "savedmodel_path = os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_savedmodel')\n",
    "model.save(savedmodel_path)\n",
    "print(f\"✓ Saved as SavedModel: {savedmodel_path}\")\n",
    "\n",
    "# Save model architecture as JSON\n",
    "model_json = model.to_json()\n",
    "json_path = os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_architecture.json')\n",
    "with open(json_path, 'w') as f:\n",
    "    f.write(model_json)\n",
    "print(f\"✓ Saved architecture: {json_path}\")\n",
    "\n",
    "# Save training configuration\n",
    "config = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'img_size': IMG_SIZE,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'epochs': EPOCHS,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'test_accuracy': float(test_results[1]),\n",
    "    'test_precision': float(test_results[2]),\n",
    "    'test_recall': float(test_results[3]),\n",
    "    'total_images': len(all_data),\n",
    "    'train_images': len(X_train),\n",
    "    'val_images': len(X_val),\n",
    "    'test_images': len(X_test),\n",
    "    'class_weights': {0: float(weight_0), 1: float(weight_1)},\n",
    "    'no_detector_count': len(no_detector_data),\n",
    "    'detector_count': len(detector_data)\n",
    "}\n",
    "\n",
    "config_path = os.path.join(OUTPUT_DIR, f'{MODEL_NAME}_config.json')\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "print(f\"✓ Saved config: {config_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL FILES SAVED SUCCESSFULLY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nOutput directory: {OUTPUT_DIR}\")\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"  - {MODEL_NAME}_final.h5 (model weights)\")\n",
    "print(f\"  - {MODEL_NAME}_savedmodel/ (TensorFlow SavedModel)\")\n",
    "print(f\"  - {MODEL_NAME}_best.h5 (best model during training)\")\n",
    "print(f\"  - {MODEL_NAME}_architecture.json (model structure)\")\n",
    "print(f\"  - {MODEL_NAME}_config.json (training configuration)\")\n",
    "print(f\"  - training_history.png (training plots)\")\n",
    "print(f\"  - logs/ (TensorBoard logs)\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
