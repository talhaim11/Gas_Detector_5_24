{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\thaim\\Videos\\לדים מהבהבים 80 מטר\\לדים מהבהבים - לבן - 80 מטר - כיסוי שחור מאחור - הזזת מצלמה -  Trim1.mp4\")\n",
    "# PARAMS & DEFINITIONS\n",
    "img_counter = 0\n",
    "fps = 25\n",
    "calc_length = 60\n",
    "T = 0\n",
    "Led_freq = 4.58\n",
    "Box_size = 50  # Adjusted box size for better precision\n",
    "freq_counter_th = 5\n",
    "freq_th = 0.7\n",
    "Mode = 1\n",
    "max_history_length = 30\n",
    "pixel_count_idx = 0\n",
    "P = []\n",
    "freq = []\n",
    "freq_history = []\n",
    "frame_count = 0  # To track how many frames we've processed so far\n",
    "\n",
    "# Get frame parameters\n",
    "frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Video writer setup (if needed for saving)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "\n",
    "# Calculate grid size\n",
    "WI = int(frameWidth / Box_size)\n",
    "HE = int(frameHeight / Box_size)\n",
    "\n",
    "# Initialize necessary buffers and counters\n",
    "pixel_count_buff = np.zeros(calc_length)\n",
    "freq_counter = np.zeros((HE, WI))\n",
    "fourier_buff = np.zeros((calc_length, HE, WI))\n",
    "\n",
    "# Initialize tracker\n",
    "tracker = cv2.TrackerMIL_create()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video or error reading frame.\")\n",
    "        break\n",
    "\n",
    "    # Increment the frame count\n",
    "    frame_count += 1\n",
    "\n",
    "    # Convert frame to grayscale\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply binary threshold\n",
    "    _, B2 = cv2.threshold(img, 230, 255, cv2.THRESH_BINARY)  # Lowered threshold for better detection\n",
    "\n",
    "    # Apply dilation\n",
    "    B3 = cv2.dilate(B2, np.ones((4, 4), np.uint8), iterations=3)  # Same dilation for noise reduction\n",
    "\n",
    "    # Store the sum of white pixels for frequency analysis\n",
    "    freq.append(np.sum(B2))\n",
    "\n",
    "    # **STEP 3: Skip all processing until we have 60 frames**\n",
    "    if frame_count < calc_length:\n",
    "        # Update the buffer but skip FFT and image processing\n",
    "        for h in range(HE):\n",
    "            for w in range(WI):\n",
    "                b2 = B2[h * Box_size:h * Box_size + Box_size, w * Box_size:w * Box_size + Box_size]\n",
    "                fourier_buff[:, h, w] = np.roll(fourier_buff[:, h, w], -1)\n",
    "                fourier_buff[0, h, w] = np.sum(b2)\n",
    "\n",
    "        continue  # Skip to the next frame until we have 60 frames\n",
    "    Mode = 2\n",
    "    # Once we have accumulated 60 frames, continue with regular processing\n",
    "    if Mode == 1:\n",
    "        # Loop through grid cells\n",
    "        for h in range(HE):            \n",
    "            for w in range(WI):\n",
    "                # Get current block in the grid\n",
    "                b2 = B2[h * Box_size:h * Box_size + Box_size, w * Box_size:w * Box_size + Box_size]\n",
    "                b3 = B3[h * Box_size:h * Box_size + Box_size, w * Box_size:w * Box_size + Box_size]\n",
    "\n",
    "                # Shift and update the Fourier buffer using np.roll\n",
    "                fourier_buff[:, h, w] = np.roll(fourier_buff[:, h, w], -1)\n",
    "                fourier_buff[0, h, w] = np.sum(b2)\n",
    "\n",
    "                # Subtract the mean and apply FFT\n",
    "                func = fourier_buff[:, h, w] - np.mean(fourier_buff[:, h, w])\n",
    "                fftx = np.abs(np.fft.rfft(func))[3:]  # Start from 3 to skip low frequencies\n",
    "                f_axis = np.linspace(0, fps / 2, len(fftx) + 3)[3:]\n",
    "\n",
    "                # Find peaks in the FFT\n",
    "                peaks, _ = find_peaks(fftx, height=np.max(fftx) * 0.5)  # Reduce peak sensitivity\n",
    "\n",
    "                # Determine the dominant frequency (if any)\n",
    "                if len(peaks) > 0 and fftx[peaks[0]] > 4 * np.median(fftx):\n",
    "                    T = f_axis[peaks[0]]\n",
    "                else:\n",
    "                    T = 0\n",
    "\n",
    "                # Draw rectangles around each grid cell\n",
    "                cv2.rectangle(frame, (w * Box_size, h * Box_size), (w * Box_size + Box_size, h * Box_size + Box_size), (0, 0, 255), 2)\n",
    "\n",
    "                # If frequency matches LED frequency\n",
    "                if np.abs(T - Led_freq) < freq_th:\n",
    "                    freq_counter[h, w] += 1\n",
    "                    if freq_counter[h, w] > freq_counter_th:\n",
    "                        contours, _ = cv2.findContours(b3, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                        if contours:\n",
    "                            c = max(contours, key=cv2.contourArea)\n",
    "                            top_point = (np.min(c[:, :, 0]) + w * Box_size, np.min(c[:, :, 1]) + h * Box_size)\n",
    "                            bottom_point = (np.max(c[:, :, 0]) + w * Box_size, np.max(c[:, :, 1]) + h * Box_size)\n",
    "                            bbox = (top_point[0], top_point[1], bottom_point[0] - top_point[0], bottom_point[1] - top_point[1])\n",
    "\n",
    "                            # Initialize the tracker\n",
    "                            tracker.init(frame, bbox)\n",
    "                            Mode = 2\n",
    "                            freq_counter[h, w] = 0\n",
    "\n",
    "                            # BREAK OUT OF BOTH LOOPS ONCE TRACKING STARTS\n",
    "                            break  # Break out of inner loop\n",
    "            if Mode == 2:\n",
    "                break  # Break out of outer loop\n",
    "\n",
    "    elif Mode == 2:\n",
    "        # Tracking mode\n",
    "        success, bbox = tracker.update(frame)\n",
    "        if success:\n",
    "            x, y, w, h = [int(v) for v in bbox]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            # Count non-zero pixels inside the current bounding box\n",
    "            roi_binary = B2[y:y + h, x:x + w]\n",
    "            non_zero_pixel_count = cv2.countNonZero(roi_binary)\n",
    "\n",
    "            # Update pixel count buffer (shift and update)\n",
    "            pixel_count_buff = np.roll(pixel_count_buff, -1)\n",
    "            pixel_count_buff[-1] = non_zero_pixel_count\n",
    "\n",
    "            # Perform FFT on the pixel count buffer to detect object frequency\n",
    "            pixel_count_fft = np.abs(np.fft.rfft(pixel_count_buff - np.mean(pixel_count_buff)))[1:]\n",
    "            f_axis = np.linspace(0, fps / 2, len(pixel_count_fft) + 1)[1:]\n",
    "\n",
    "            # Find peaks in the FFT to detect the dominant frequency\n",
    "            peaks, _ = find_peaks(pixel_count_fft, height=np.max(pixel_count_fft))\n",
    "\n",
    "            if len(peaks) > 0 and pixel_count_fft[peaks[0]] > 4 * np.median(pixel_count_fft):\n",
    "                detected_freq = f_axis[peaks[0]]\n",
    "            else:\n",
    "                detected_freq = 0\n",
    "\n",
    "            # Update frequency history\n",
    "            freq_history.append(detected_freq)\n",
    "            if len(freq_history) > max_history_length:\n",
    "                freq_history.pop(0)\n",
    "\n",
    "            mean_freq = np.mean(freq_history)\n",
    "            std_freq = np.std(freq_history)\n",
    "\n",
    "            # Check if detected frequency is outside historical range\n",
    "            if abs(detected_freq - mean_freq) > (2 * std_freq + freq_th) :\n",
    "                print(f\"Frequency {detected_freq:.2f} Hz deviates from mean {mean_freq:.2f} Hz with std {std_freq:.2f}. Switching back to Mode 1.\")\n",
    "                Mode = 1\n",
    "                tracker = cv2.TrackerMIL.create()  # Reinitialize the tracker if necessary\n",
    "                freq_history = []\n",
    "\n",
    "            # Display the tracking information\n",
    "            cv2.putText(frame, f'Pixels > 0: {int(non_zero_pixel_count)}', (x, y - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, f'Freq: {detected_freq:.2f} Hz', (x, y - 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, f'Mean Freq: {mean_freq:.2f} Hz', (x, y - 70), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        else:\n",
    "            Mode = 1\n",
    "            tracker = cv2.TrackerMIL.create()  # Reinitialize the tracker if necessary\n",
    "\n",
    "    # Show the processed binary image (B3) or frame\n",
    "    cv2.imshow(\"preview\", frame)  # Or cv2.imshow(\"preview\", frame) if you want the full frame\n",
    "\n",
    "    # Handle keypress\n",
    "    k = cv2.waitKey(30)\n",
    "    if k == 27 or k == ord('q'):  # ESC or 'q' to quit\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image, ImageDraw\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as patches\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# from matplotlib import pyplot as plt\n",
    "# from matplotlib.pyplot import figure\n",
    "# \n",
    "# \n",
    "# import cv2 as cv\n",
    "# import colorsys\n",
    "# import matplotlib.pyplot as plt\n",
    "# import sys\n",
    "# \n",
    "# from scipy.ndimage import shift\n",
    "# from scipy.signal import find_peaks\n",
    "# \n",
    "# # Add a parameter for the minimum contour size\n",
    "# min_contour_area = 5  # Define minimum contour area (you can adjust this value as needed)\n",
    "# zero_freq_threshold = 200  # Number of consecutive frames with zero frequency to switch back to Mode 1\n",
    "# movement_threshold = 20  # Define the threshold for bbox movement to return to mode 1\n",
    "# \n",
    "# # Initialize a counter for zero frequency frames\n",
    "# zero_freq_counter = 0\n",
    "# previous_bbox = None  # To track previous bbox position\n",
    "# \n",
    "# # Open the video file\n",
    "# cap = cv2.VideoCapture(r\"C:\\Users\\thaim\\Videos\\לדים מהבהבים 80 מטר\\ניסוי מצלמה - 80 מטר - לד לבן - 0930- 1.mp4\")\n",
    "# \n",
    "# \n",
    "# # PARAMS & DEFINITIONS\n",
    "# img_counter = 0\n",
    "# fps = 25\n",
    "# calc_length = 60\n",
    "# T = 0\n",
    "# Led_freq = 4.58\n",
    "# Box_size = 50  # Adjusted box size for better precision\n",
    "# freq_counter_th = 5\n",
    "# freq_th = 0.7\n",
    "# Mode = 1\n",
    "# max_history_length = 30\n",
    "# pixel_count_idx = 0\n",
    "# P = []\n",
    "# freq = []\n",
    "# freq_history = []\n",
    "# frame_count = 0  # To track how many frames we've processed so far\n",
    "# \n",
    "# # Get frame parameters\n",
    "# frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "# frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "# \n",
    "# # Video writer setup (if needed for saving)\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "# \n",
    "# # Calculate grid size\n",
    "# WI = int(frameWidth / Box_size)\n",
    "# HE = int(frameHeight / Box_size)\n",
    "# \n",
    "# # Initialize necessary buffers and counters\n",
    "# pixel_count_buff = np.zeros(calc_length)\n",
    "# freq_counter = np.zeros((HE, WI))\n",
    "# fourier_buff = np.zeros((calc_length, HE, WI))\n",
    "# \n",
    "# # Initialize tracker\n",
    "# tracker = cv2.TrackerMIL_create()\n",
    "# \n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         print(\"End of video or error reading frame.\")\n",
    "#         break\n",
    "# \n",
    "#     # Increment the frame count\n",
    "#     frame_count += 1\n",
    "# \n",
    "#     # Convert frame to grayscale\n",
    "#     img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "# \n",
    "#     # Apply binary threshold\n",
    "#     _, B2 = cv2.threshold(img, 190, 255, cv2.THRESH_BINARY)  # Lowered threshold for better detection\n",
    "# \n",
    "#     # Apply dilation\n",
    "#     B3 = cv2.dilate(B2, np.ones((4, 4), np.uint8), iterations=3)  # Same dilation for noise reduction\n",
    "# \n",
    "#     # Store the sum of white pixels for frequency analysis\n",
    "#     freq.append(np.sum(B2))\n",
    "# \n",
    "#     # **STEP 3: Skip all processing until we have 60 frames**\n",
    "#     if frame_count < calc_length:\n",
    "#         # Update the buffer but skip FFT and image processing\n",
    "#         for h in range(HE):\n",
    "#             for w in range(WI):\n",
    "#                 b2 = B2[h * Box_size:h * Box_size + Box_size, w * Box_size:w * Box_size + Box_size]\n",
    "#                 fourier_buff[:, h, w] = np.roll(fourier_buff[:, h, w], -1)\n",
    "#                 fourier_buff[0, h, w] = np.sum(b2)\n",
    "# \n",
    "#         continue  # Skip to the next frame until we have 60 frames\n",
    "# \n",
    "#     # Once we have accumulated 60 frames, continue with regular processing\n",
    "#     if Mode == 1:\n",
    "#         # Loop through grid cells\n",
    "#         for h in range(HE):            \n",
    "#             for w in range(WI):\n",
    "#                 # Get current block in the grid\n",
    "#                 b2 = B2[h * Box_size:h * Box_size + Box_size, w * Box_size:w * Box_size + Box_size]\n",
    "#                 b3 = B3[h * Box_size:h * Box_size + Box_size, w * Box_size:w * Box_size + Box_size]\n",
    "# \n",
    "#                 # Shift and update the Fourier buffer using np.roll\n",
    "#                 fourier_buff[:, h, w] = np.roll(fourier_buff[:, h, w], -1)\n",
    "#                 fourier_buff[0, h, w] = np.sum(b2)\n",
    "# \n",
    "#                 # Subtract the mean and apply FFT\n",
    "#                 func = fourier_buff[:, h, w] - np.mean(fourier_buff[:, h, w])\n",
    "#                 fftx = np.abs(np.fft.rfft(func))[3:]  # Start from 3 to skip low frequencies\n",
    "#                 f_axis = np.linspace(0, fps / 2, len(fftx) + 3)[3:]\n",
    "# \n",
    "#                 # Find peaks in the FFT\n",
    "#                 peaks, _ = find_peaks(fftx, height=np.max(fftx) * 0.5)  # Reduce peak sensitivity\n",
    "# \n",
    "#                 # Determine the dominant frequency (if any)\n",
    "#                 if len(peaks) > 0 and fftx[peaks[0]] > 4 * np.median(fftx):\n",
    "#                     T = f_axis[peaks[0]]\n",
    "#                 else:\n",
    "#                     T = 0\n",
    "# \n",
    "#                 # Draw rectangles around each grid cell\n",
    "#                 cv2.rectangle(frame, (w * Box_size, h * Box_size), (w * Box_size + Box_size, h * Box_size + Box_size), (0, 0, 255), 2)\n",
    "# \n",
    "#                 # If frequency matches LED frequency\n",
    "#                 if np.abs(T - Led_freq) < freq_th:\n",
    "#                     freq_counter[h, w] += 1\n",
    "#                     if freq_counter[h, w] > freq_counter_th:\n",
    "#                         contours, _ = cv2.findContours(b3, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#                         if contours:\n",
    "#                             # Filter contours based on the minimum contour size\n",
    "#                             valid_contours = [c for c in contours if cv2.contourArea(c) > min_contour_area]\n",
    "#                             \n",
    "#                             if valid_contours:\n",
    "#                                 c = max(valid_contours, key=cv2.contourArea)\n",
    "#                                 top_point = (np.min(c[:, :, 0]) + w * Box_size, np.min(c[:, :, 1]) + h * Box_size)\n",
    "#                                 bottom_point = (np.max(c[:, :, 0]) + w * Box_size, np.max(c[:, :, 1]) + h * Box_size)\n",
    "#                                 bbox = (top_point[0], top_point[1], bottom_point[0] - top_point[0], bottom_point[1] - top_point[1])\n",
    "# \n",
    "#                                 # Initialize the tracker\n",
    "#                                 tracker.init(frame, bbox)\n",
    "#                                 previous_bbox = bbox  # Store the initial bbox position\n",
    "#                                 Mode = 2\n",
    "#                                 freq_counter[h, w] = 0\n",
    "# \n",
    "#                                 # BREAK OUT OF BOTH LOOPS ONCE TRACKING STARTS\n",
    "#                                 break  # Break out of inner loop\n",
    "#             if Mode == 2:\n",
    "#                 break  # Break out of outer loop\n",
    "# \n",
    "#     elif Mode == 2:\n",
    "#         # Tracking mode\n",
    "#         success, bbox = tracker.update(frame)\n",
    "#         if success:\n",
    "#             x, y, w, h = [int(v) for v in bbox]\n",
    "#             cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "# \n",
    "#             # Calculate bbox movement\n",
    "#             if previous_bbox is not None:\n",
    "#                 previous_x, previous_y, previous_w, previous_h = previous_bbox\n",
    "#                 movement = np.sqrt((x - previous_x) ** 2 + (y - previous_y) ** 2)\n",
    "# \n",
    "#                 if movement > movement_threshold:\n",
    "#                     print(f\"Bbox moved {movement:.2f} pixels, exceeding threshold. Switching back to Mode 1.\")\n",
    "#                     Mode = 1\n",
    "#                     tracker = cv2.TrackerMIL_create()  # Reinitialize tracker if needed\n",
    "#                     previous_bbox = None\n",
    "#                     continue\n",
    "# \n",
    "#             # Update the previous bbox position\n",
    "#             previous_bbox = bbox\n",
    "# \n",
    "#             # Count non-zero pixels inside the current bounding box\n",
    "#             roi_binary = B2[y:y + h, x:x + w]\n",
    "#             non_zero_pixel_count = cv2.countNonZero(roi_binary)\n",
    "# \n",
    "#             # Update pixel count buffer (shift and update)\n",
    "#             pixel_count_buff = np.roll(pixel_count_buff, -1)\n",
    "#             pixel_count_buff[-1] = non_zero_pixel_count\n",
    "# \n",
    "#             # Perform FFT on the pixel count buffer to detect object frequency\n",
    "#             pixel_count_fft = np.abs(np.fft.rfft(pixel_count_buff - np.mean(pixel_count_buff)))[1:]\n",
    "#             f_axis = np.linspace(0, fps / 2, len(pixel_count_fft) + 1)[1:]\n",
    "# \n",
    "#             # Find peaks in the FFT to detect the dominant frequency\n",
    "#             peaks, _ = find_peaks(pixel_count_fft, height=np.max(pixel_count_fft))\n",
    "# \n",
    "#             if len(peaks) > 0 and pixel_count_fft[peaks[0]] > 4 * np.median(pixel_count_fft):\n",
    "#                 detected_freq = f_axis[peaks[0]]\n",
    "#             else:\n",
    "#                 detected_freq = 0\n",
    "# \n",
    "#             # Update frequency history\n",
    "#             freq_history.append(detected_freq)\n",
    "#             if len(freq_history) > max_history_length:\n",
    "#                 freq_history.pop(0)\n",
    "# \n",
    "#             mean_freq = np.mean(freq_history)\n",
    "#             std_freq = np.std(freq_history)\n",
    "# \n",
    "#             # Check if detected frequency is outside historical range\n",
    "#             if abs(detected_freq - mean_freq) > (2 * std_freq + freq_th):\n",
    "#                 print(f\"Frequency {detected_freq:.2f} Hz deviates from mean {mean_freq:.2f} Hz with std {std_freq:.2f}. Switching back to Mode 1.\")\n",
    "#                 Mode = 1\n",
    "#                 tracker = cv2.TrackerMIL_create()  # Reinitialize the tracker if necessary\n",
    "#                 freq_history = []\n",
    "# \n",
    "#             # Increment zero frequency counter if no frequency detected\n",
    "#             if detected_freq == 0:\n",
    "#                 zero_freq_counter += 1\n",
    "#             else:\n",
    "#                 zero_freq_counter = 0  # Reset counter if frequency detected\n",
    "# \n",
    "#             # Check if zero frequency has persisted for too long\n",
    "#             if zero_freq_counter >= zero_freq_threshold:\n",
    "#                 print(f\"Frequency has been zero for {zero_freq_threshold} consecutive frames. Switching back to Mode 1.\")\n",
    "#                 Mode = 1\n",
    "#                 zero_freq_counter = 0  # Reset counter\n",
    "#                 tracker = cv2.TrackerMIL_create()  # Reinitialize tracker if needed\n",
    "# \n",
    "#             # Display the tracking information\n",
    "#             cv2.putText(frame, f'Pixels > 0: {int(non_zero_pixel_count)}', (x, y - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "#             cv2.putText(frame, f'Freq: {detected_freq:.2f} Hz', (x, y - 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "#             cv2.putText(frame, f'Mean Freq: {mean_freq:.2f} Hz', (x, y - 70), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "#         else:\n",
    "#             Mode = 1\n",
    "#             tracker = cv2.TrackerMIL_create()\n",
    "# \n",
    "#     # Show the processed binary image (B3) or frame\n",
    "#     cv2.imshow(\"preview\", frame)\n",
    "# \n",
    "#     # Handle keypress\n",
    "#     k = cv2.waitKey(30)\n",
    "#     if k == 27 or k == ord('q'):  # ESC or 'q' to quit\n",
    "#         break\n",
    "# \n",
    "# # Cleanup\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HSV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test3 - no calc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Open the video file (RTSP stream in your case)\n",
    "cap = cv2.VideoCapture(r\"rtsp://fgcam:admin@169.254.203.185:8554/0/unicast\")\n",
    "\n",
    "# Trackbar callback function\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Create trackbars for HSV adjustments (now in percentages)\n",
    "cv2.namedWindow('Trackbars')\n",
    "cv2.createTrackbar('H Lower %', 'Trackbars', 0, 100, nothing)\n",
    "cv2.createTrackbar('H Upper %', 'Trackbars', 100, 100, nothing)\n",
    "cv2.createTrackbar('S Lower %', 'Trackbars', 0, 100, nothing)\n",
    "cv2.createTrackbar('S Upper %', 'Trackbars', 100, 100, nothing)\n",
    "cv2.createTrackbar('V Lower %', 'Trackbars', 0, 100, nothing)\n",
    "cv2.createTrackbar('V Upper %', 'Trackbars', 100, 100, nothing)\n",
    "c=0\n",
    "while True:\n",
    "    c=c+1\n",
    "    ret, frame = cap.read()\n",
    "    # Get trackbar positions for HSV percentages\n",
    "    h_lower_percent = cv2.getTrackbarPos('H Lower %', 'Trackbars')\n",
    "    h_upper_percent = cv2.getTrackbarPos('H Upper %', 'Trackbars')\n",
    "    s_lower_percent = cv2.getTrackbarPos('S Lower %', 'Trackbars')\n",
    "    s_upper_percent = cv2.getTrackbarPos('S Upper %', 'Trackbars')\n",
    "    v_lower_percent = cv2.getTrackbarPos('V Lower %', 'Trackbars')\n",
    "    v_upper_percent = cv2.getTrackbarPos('V Upper %', 'Trackbars')\n",
    "\n",
    "    # Convert percentage values back to the HSV scale\n",
    "    h_lower = int(h_lower_percent * 179 / 100)\n",
    "    h_upper = int(h_upper_percent * 179 / 100)\n",
    "    s_lower = int(s_lower_percent * 255 / 100)\n",
    "    s_upper = int(s_upper_percent * 255 / 100)\n",
    "    v_lower = int(v_lower_percent * 255 / 100)\n",
    "    v_upper = int(v_upper_percent * 255 / 100)\n",
    "\n",
    "    # Define the lower and upper bounds for HSV values\n",
    "    lower_hsv = np.array([h_lower, s_lower, v_lower])\n",
    "    upper_hsv = np.array([h_upper, s_upper, v_upper])\n",
    "\n",
    "    # Convert the frame to HSV color space\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Apply HSV threshold to isolate the object color range\n",
    "    mask = cv2.inRange(hsv_frame, lower_hsv, upper_hsv)\n",
    "\n",
    "    # Set all areas outside the mask to 0 (black) in the original frame\n",
    "    filtered_frame = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "    # Show the original frame and the filtered HSV frame\n",
    "    cv2.imshow(\"Filtered Frame\", filtered_frame)\n",
    "    cv2.imshow(\"Preview\", mask)\n",
    "    print(c)\n",
    "\n",
    "    # Handle keypress\n",
    "    k = cv2.waitKey(30)\n",
    "    if k == 27 or k == ord('q'):  # ESC or 'q' to quit\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test 3 - precentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency 1.67 Hz deviates from mean 0.06 Hz with std 0.30. Switching back to Mode 1.\n",
      "Frequency 5.00 Hz deviates from mean 0.17 Hz with std 0.90. Switching back to Mode 1.\n",
      "Frequency 5.00 Hz deviates from mean 0.17 Hz with std 0.90. Switching back to Mode 1.\n",
      "Frequency 5.00 Hz deviates from mean 0.17 Hz with std 0.90. Switching back to Mode 1.\n",
      "Frequency 1.25 Hz deviates from mean 0.04 Hz with std 0.22. Switching back to Mode 1.\n",
      "Frequency 1.25 Hz deviates from mean 0.04 Hz with std 0.22. Switching back to Mode 1.\n",
      "Frequency 4.58 Hz deviates from mean 0.15 Hz with std 0.82. Switching back to Mode 1.\n",
      "Frequency 10.00 Hz deviates from mean 0.33 Hz with std 1.80. Switching back to Mode 1.\n",
      "Frequency 5.00 Hz deviates from mean 0.24 Hz with std 1.06. Switching back to Mode 1.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Open the video file (RTSP stream in your case)\n",
    "cap = cv2.VideoCapture(r\"rtsp://fgcam:admin@169.254.203.185:8554/0/unicast\")\n",
    "\n",
    "# PARAMS & DEFINITIONS\n",
    "img_counter = 0\n",
    "fps = 25\n",
    "calc_length = 60\n",
    "T = 0\n",
    "Led_freq = 4.58\n",
    "Box_size = 50  # Adjusted box size for better precision\n",
    "freq_counter_th = 5\n",
    "freq_th = 0.7\n",
    "Mode = 1\n",
    "max_history_length = 30\n",
    "pixel_count_idx = 0\n",
    "P = []\n",
    "freq = []\n",
    "freq_history = []\n",
    "frame_count = 0  # To track how many frames we've processed so far\n",
    "\n",
    "# Trackbar callback function\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Create trackbars for HSV adjustments (now in percentages)\n",
    "cv2.namedWindow('Trackbars')\n",
    "cv2.createTrackbar('H Lower %', 'Trackbars', 0, 100, nothing)\n",
    "cv2.createTrackbar('H Upper %', 'Trackbars', 100, 100, nothing)\n",
    "cv2.createTrackbar('S Lower %', 'Trackbars', 0, 100, nothing)\n",
    "cv2.createTrackbar('S Upper %', 'Trackbars', 100, 100, nothing)\n",
    "cv2.createTrackbar('V Lower %', 'Trackbars', 0, 100, nothing)\n",
    "cv2.createTrackbar('V Upper %', 'Trackbars', 100, 100, nothing)\n",
    "\n",
    "# Get frame parameters\n",
    "frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Calculate grid size\n",
    "WI = int(frameWidth / Box_size)\n",
    "HE = int(frameHeight / Box_size)\n",
    "\n",
    "# Initialize necessary buffers and counters\n",
    "pixel_count_buff = np.zeros(calc_length)\n",
    "freq_counter = np.zeros((HE, WI))\n",
    "fourier_buff = np.zeros((calc_length, HE, WI))\n",
    "\n",
    "# Initialize tracker\n",
    "tracker = cv2.TrackerMIL_create()\n",
    "\n",
    "# Frame skip rate to reduce load\n",
    "frame_skip_rate = 5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video or error reading frame.\")\n",
    "        break\n",
    "\n",
    "    # Increment the frame count\n",
    "    frame_count += 1\n",
    "\n",
    "    # Skip frames to reduce processing load\n",
    "    if frame_count % frame_skip_rate != 0:\n",
    "        continue\n",
    "\n",
    "    # Get trackbar positions for HSV percentages\n",
    "    h_lower_percent = cv2.getTrackbarPos('H Lower %', 'Trackbars')\n",
    "    h_upper_percent = cv2.getTrackbarPos('H Upper %', 'Trackbars')\n",
    "    s_lower_percent = cv2.getTrackbarPos('S Lower %', 'Trackbars')\n",
    "    s_upper_percent = cv2.getTrackbarPos('S Upper %', 'Trackbars')\n",
    "    v_lower_percent = cv2.getTrackbarPos('V Lower %', 'Trackbars')\n",
    "    v_upper_percent = cv2.getTrackbarPos('V Upper %', 'Trackbars')\n",
    "\n",
    "    # Convert percentage values back to the HSV scale\n",
    "    h_lower = int(h_lower_percent * 179 / 100)\n",
    "    h_upper = int(h_upper_percent * 179 / 100)\n",
    "    s_lower = int(s_lower_percent * 255 / 100)\n",
    "    s_upper = int(s_upper_percent * 255 / 100)\n",
    "    v_lower = int(v_lower_percent * 255 / 100)\n",
    "    v_upper = int(v_upper_percent * 255 / 100)\n",
    "\n",
    "    # Define the lower and upper bounds for HSV values\n",
    "    lower_hsv = np.array([h_lower, s_lower, v_lower])\n",
    "    upper_hsv = np.array([h_upper, s_upper, v_upper])\n",
    "\n",
    "    # Convert the frame to HSV color space\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Apply HSV threshold to isolate the object color range\n",
    "    mask = cv2.inRange(hsv_frame, lower_hsv, upper_hsv)\n",
    "\n",
    "    # Set all areas outside the mask to 0 (black) in the original frame\n",
    "    filtered_frame = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    # **STEP 3: Skip all processing until we have 60 frames**\n",
    "    if frame_count < calc_length:\n",
    "        for h in range(HE):\n",
    "            for w in range(WI):\n",
    "                b2 = mask[h * Box_size:h * Box_size + Box_size, w * Box_size:w * Box_size + Box_size]\n",
    "                fourier_buff[:, h, w] = np.roll(fourier_buff[:, h, w], -1)\n",
    "                fourier_buff[0, h, w] = np.sum(b2)\n",
    "        continue  # Skip to the next frame until we have 60 frames\n",
    "\n",
    "    # Once we have accumulated 60 frames, continue with regular processing\n",
    "    if Mode == 1:\n",
    "        for h in range(HE):\n",
    "            for w in range(WI):\n",
    "                # Get current block in the grid\n",
    "                b2 = mask[h * Box_size:h * Box_size + Box_size, w * Box_size:w * Box_size + Box_size]\n",
    "                b3 = cv2.dilate(b2, np.ones((4, 4), np.uint8), iterations=3)\n",
    "\n",
    "                # Shift and update the Fourier buffer using np.roll\n",
    "                fourier_buff[:, h, w] = np.roll(fourier_buff[:, h, w], -1)\n",
    "                fourier_buff[0, h, w] = np.sum(b2)\n",
    "\n",
    "                # Subtract the mean and apply FFT\n",
    "                func = fourier_buff[:, h, w] - np.mean(fourier_buff[:, h, w])\n",
    "                fftx = np.abs(np.fft.rfft(func))[3:]  # Start from 3 to skip low frequencies\n",
    "                f_axis = np.linspace(0, fps / 2, len(fftx) + 3)[3:]\n",
    "\n",
    "                # Find peaks in the FFT\n",
    "                peaks, _ = find_peaks(fftx, height=np.max(fftx) * 0.5)  # Reduce peak sensitivity\n",
    "\n",
    "                # Determine the dominant frequency (if any)\n",
    "                if len(peaks) > 0 and fftx[peaks[0]] > 4 * np.median(fftx):\n",
    "                    T = f_axis[peaks[0]]\n",
    "                else:\n",
    "                    T = 0\n",
    "\n",
    "                # Draw rectangles around each grid cell\n",
    "                cv2.rectangle(frame, (w * Box_size, h * Box_size), (w * Box_size + Box_size, h * Box_size + Box_size), (0, 0, 255), 2)\n",
    "\n",
    "                # If frequency matches LED frequency\n",
    "                if np.abs(T - Led_freq) < freq_th:\n",
    "                    freq_counter[h, w] += 1\n",
    "                    if freq_counter[h, w] > freq_counter_th:\n",
    "                        contours, _ = cv2.findContours(b3, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                        if contours:\n",
    "                            c = max(contours, key=cv2.contourArea)\n",
    "                            top_point = (np.min(c[:, :, 0]) + w * Box_size, np.min(c[:, :, 1]) + h * Box_size)\n",
    "                            bottom_point = (np.max(c[:, :, 0]) + w * Box_size, np.max(c[:, :, 1]) + h * Box_size)\n",
    "                            bbox = (top_point[0], top_point[1], bottom_point[0] - top_point[0], bottom_point[1] - top_point[1])\n",
    "\n",
    "                            # Initialize the tracker\n",
    "                            tracker.init(frame, bbox)\n",
    "                            Mode = 2\n",
    "                            freq_counter[h, w] = 0\n",
    "\n",
    "                            # BREAK OUT OF BOTH LOOPS ONCE TRACKING STARTS\n",
    "                            break  # Break out of inner loop\n",
    "            if Mode == 2:\n",
    "                break  # Break out of outer loop\n",
    "\n",
    "    elif Mode == 2:\n",
    "        # Tracking mode\n",
    "        success, bbox = tracker.update(frame)\n",
    "        if success:\n",
    "            x, y, w, h = [int(v) for v in bbox]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            # Count non-zero pixels inside the current bounding box\n",
    "            roi_binary = mask[y:y + h, x:x + w]\n",
    "            non_zero_pixel_count = cv2.countNonZero(roi_binary)\n",
    "\n",
    "            # Update pixel count buffer (shift and update)\n",
    "            pixel_count_buff = np.roll(pixel_count_buff, -1)\n",
    "            pixel_count_buff[-1] = non_zero_pixel_count\n",
    "\n",
    "            # Perform FFT on the pixel count buffer to detect object frequency\n",
    "            pixel_count_fft = np.abs(np.fft.rfft(pixel_count_buff - np.mean(pixel_count_buff)))[1:]\n",
    "            f_axis = np.linspace(0, fps / 2, len(pixel_count_fft) + 1)[1:]\n",
    "\n",
    "            # Find peaks in the FFT to detect the dominant frequency\n",
    "            peaks, _ = find_peaks(pixel_count_fft, height=np.max(pixel_count_fft))\n",
    "\n",
    "            if len(peaks) > 0 and pixel_count_fft[peaks[0]] > 4 * np.median(pixel_count_fft):\n",
    "                detected_freq = f_axis[peaks[0]]\n",
    "            else:\n",
    "                detected_freq = 0\n",
    "\n",
    "            # Update frequency history\n",
    "            freq_history.append(detected_freq)\n",
    "            if len(freq_history) > max_history_length:\n",
    "                freq_history.pop(0)\n",
    "\n",
    "            mean_freq = np.mean(freq_history)\n",
    "            std_freq = np.std(freq_history)\n",
    "\n",
    "            # Check if detected frequency is outside historical range\n",
    "            if abs(detected_freq - mean_freq) > (2 * std_freq + freq_th):\n",
    "                print(f\"Frequency {detected_freq:.2f} Hz deviates from mean {mean_freq:.2f} Hz with std {std_freq:.2f}. Switching back to Mode 1.\")\n",
    "                Mode = 1\n",
    "                tracker = cv2.TrackerMIL_create()  # Reinitialize the tracker if necessary\n",
    "                freq_history = []\n",
    "\n",
    "            # Display the tracking information\n",
    "            cv2.putText(frame, f'Pixels > 0: {int(non_zero_pixel_count)}', (x, y - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, f'Freq: {detected_freq:.2f} Hz', (x, y - 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, f'Mean Freq: {mean_freq:.2f} Hz', (x, y - 70), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        else:\n",
    "            Mode = 1\n",
    "            tracker = cv2.TrackerMIL_create()  # Reinitialize the tracker if necessary\n",
    "\n",
    "    # Show the original frame and the filtered HSV frame\n",
    "    cv2.imshow(\"Filtered Frame\", filtered_frame)\n",
    "    cv2.imshow(\"Preview\", mask)\n",
    "\n",
    "    # Handle keypress\n",
    "    k = cv2.waitKey(30)\n",
    "    if k == 27 or k == ord('q'):  # ESC or 'q' to quit\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test 3 - % with one bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency 2.08 Hz deviates from mean 0.13 Hz with std 0.50. Switching back to Mode 1.\n",
      "Frequency 1.67 Hz deviates from mean 0.06 Hz with std 0.30. Switching back to Mode 1.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Open the video file (RTSP stream in your case)\n",
    "cap = cv2.VideoCapture(r\"rtsp://fgcam:admin@169.254.118.8:8554/0/unicast\")\n",
    "\n",
    "# PARAMS & DEFINITIONS\n",
    "img_counter = 0\n",
    "fps = 25\n",
    "calc_length = 60\n",
    "T = 0\n",
    "Led_freq = 4.58\n",
    "Box_size = 50  # Adjusted box size for better precision\n",
    "freq_counter_th = 5\n",
    "freq_th = 0.7\n",
    "Mode = 1\n",
    "max_history_length = 30\n",
    "pixel_count_idx = 0\n",
    "P = []\n",
    "freq = []\n",
    "freq_history = []\n",
    "frame_count = 0  # To track how many frames we've processed so far\n",
    "\n",
    "# Trackbar callback function\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Create trackbars for HSV adjustments (now just one for each)\n",
    "cv2.namedWindow('Trackbars')\n",
    "cv2.createTrackbar('H %', 'Trackbars', 50, 100, nothing)  # Hue\n",
    "cv2.createTrackbar('S %', 'Trackbars', 50, 100, nothing)  # Saturation\n",
    "cv2.createTrackbar('V %', 'Trackbars', 50, 100, nothing)  # Value\n",
    "\n",
    "# Define a fixed range for H, S, and V\n",
    "H_RANGE = 10  # Define a ± range for Hue\n",
    "S_RANGE = 40  # Define a ± range for Saturation\n",
    "V_RANGE = 40  # Define a ± range for Value\n",
    "\n",
    "# Get frame parameters\n",
    "frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Calculate grid size\n",
    "WI = int(frameWidth / Box_size)\n",
    "HE = int(frameHeight / Box_size)\n",
    "\n",
    "# Initialize necessary buffers and counters\n",
    "pixel_count_buff = np.zeros(calc_length)\n",
    "freq_counter = np.zeros((HE, WI))\n",
    "fourier_buff = np.zeros((calc_length, HE, WI))\n",
    "\n",
    "# Initialize tracker\n",
    "tracker = cv2.TrackerMIL_create()\n",
    "\n",
    "# Frame skip rate to reduce load\n",
    "frame_skip_rate = 5\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video or error reading frame.\")\n",
    "        break\n",
    "\n",
    "    # Increment the frame count\n",
    "    frame_count += 1\n",
    "\n",
    "    # Skip frames to reduce processing load\n",
    "    if frame_count % frame_skip_rate != 0:\n",
    "        continue\n",
    "\n",
    "    # Get trackbar positions for HSV percentages (now just one for each)\n",
    "    h_center_percent = cv2.getTrackbarPos('H %', 'Trackbars')\n",
    "    s_center_percent = cv2.getTrackbarPos('S %', 'Trackbars')\n",
    "    v_center_percent = cv2.getTrackbarPos('V %', 'Trackbars')\n",
    "\n",
    "    # Convert percentage values back to the HSV scale\n",
    "    h_center = int(h_center_percent * 179 / 100)\n",
    "    s_center = int(s_center_percent * 255 / 100)\n",
    "    v_center = int(v_center_percent * 255 / 100)\n",
    "\n",
    "    # Define the lower and upper bounds based on the fixed range\n",
    "    h_lower = max(0, h_center - H_RANGE)\n",
    "    h_upper = min(179, h_center + H_RANGE)\n",
    "    s_lower = max(0, s_center - S_RANGE)\n",
    "    s_upper = min(255, s_center + S_RANGE)\n",
    "    v_lower = max(0, v_center - V_RANGE)\n",
    "    v_upper = min(255, v_center + V_RANGE)\n",
    "\n",
    "    # Define the lower and upper bounds for HSV values\n",
    "    lower_hsv = np.array([h_lower, s_lower, v_lower])\n",
    "    upper_hsv = np.array([h_upper, s_upper, v_upper])\n",
    "\n",
    "    # Convert the frame to HSV color space\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Apply HSV threshold to isolate the object color range\n",
    "    mask = cv2.inRange(hsv_frame, lower_hsv, upper_hsv)\n",
    "\n",
    "    # Set all areas outside the mask to 0 (black) in the original frame\n",
    "    filtered_frame = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    # **STEP 3: Skip all processing until we have 60 frames**\n",
    "    if frame_count < calc_length:\n",
    "        for h in range(HE):\n",
    "            for w in range(WI):\n",
    "                b2 = mask[h * Box_size:h * Box_size + Box_size, w * Box_size:w * Box_size + Box_size]\n",
    "                fourier_buff[:, h, w] = np.roll(fourier_buff[:, h, w], -1)\n",
    "                fourier_buff[0, h, w] = np.sum(b2)\n",
    "        continue  # Skip to the next frame until we have 60 frames\n",
    "\n",
    "    # Once we have accumulated 60 frames, continue with regular processing\n",
    "    if Mode == 1:\n",
    "        for h in range(HE):\n",
    "            for w in range(WI):\n",
    "                # Get current block in the grid\n",
    "                b2 = mask[h * Box_size:h * Box_size + Box_size, w * Box_size:w * Box_size + Box_size]\n",
    "                b3 = cv2.dilate(b2, np.ones((4, 4), np.uint8), iterations=3)\n",
    "\n",
    "                # Shift and update the Fourier buffer using np.roll\n",
    "                fourier_buff[:, h, w] = np.roll(fourier_buff[:, h, w], -1)\n",
    "                fourier_buff[0, h, w] = np.sum(b2)\n",
    "\n",
    "                # Subtract the mean and apply FFT\n",
    "                func = fourier_buff[:, h, w] - np.mean(fourier_buff[:, h, w])\n",
    "                fftx = np.abs(np.fft.rfft(func))[3:]  # Start from 3 to skip low frequencies\n",
    "                f_axis = np.linspace(0, fps / 2, len(fftx) + 3)[3:]\n",
    "\n",
    "                # Find peaks in the FFT\n",
    "                peaks, _ = find_peaks(fftx, height=np.max(fftx) * 0.5)  # Reduce peak sensitivity\n",
    "\n",
    "                # Determine the dominant frequency (if any)\n",
    "                if len(peaks) > 0 and fftx[peaks[0]] > 4 * np.median(fftx):\n",
    "                    T = f_axis[peaks[0]]\n",
    "                else:\n",
    "                    T = 0\n",
    "\n",
    "                # Draw rectangles around each grid cell\n",
    "                cv2.rectangle(frame, (w * Box_size, h * Box_size), (w * Box_size + Box_size, h * Box_size + Box_size), (0, 0, 255), 2)\n",
    "\n",
    "                # If frequency matches LED frequency\n",
    "                if np.abs(T - Led_freq) < freq_th:\n",
    "                    freq_counter[h, w] += 1\n",
    "                    if freq_counter[h, w] > freq_counter_th:\n",
    "                        contours, _ = cv2.findContours(b3, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                        if contours:\n",
    "                            c = max(contours, key=cv2.contourArea)\n",
    "                            top_point = (np.min(c[:, :, 0]) + w * Box_size, np.min(c[:, :, 1]) + h * Box_size)\n",
    "                            bottom_point = (np.max(c[:, :, 0]) + w * Box_size, np.max(c[:, :, 1]) + h * Box_size)\n",
    "                            bbox = (top_point[0], top_point[1], bottom_point[0] - top_point[0], bottom_point[1] - top_point[1])\n",
    "\n",
    "                            # Initialize the tracker\n",
    "                            tracker.init(frame, bbox)\n",
    "                            Mode = 2\n",
    "                            freq_counter[h, w] = 0\n",
    "\n",
    "                            # BREAK OUT OF BOTH LOOPS ONCE TRACKING STARTS\n",
    "                            break  # Break out of inner loop\n",
    "            if Mode == 2:\n",
    "                break  # Break out of outer loop\n",
    "\n",
    "    elif Mode == 2:\n",
    "        # Tracking mode\n",
    "        success, bbox = tracker.update(frame)\n",
    "        if success:\n",
    "            x, y, w, h = [int(v) for v in bbox]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            # Count non-zero pixels inside the current bounding box\n",
    "            roi_binary = mask[y:y + h, x:x + w]\n",
    "            non_zero_pixel_count = cv2.countNonZero(roi_binary)\n",
    "\n",
    "            # Update pixel count buffer (shift and update)\n",
    "            pixel_count_buff = np.roll(pixel_count_buff, -1)\n",
    "            pixel_count_buff[-1] = non_zero_pixel_count\n",
    "\n",
    "            # Perform FFT on the pixel count buffer to detect object frequency\n",
    "            pixel_count_fft = np.abs(np.fft.rfft(pixel_count_buff - np.mean(pixel_count_buff)))[1:]\n",
    "            f_axis = np.linspace(0, fps / 2, len(pixel_count_fft) + 1)[1:]\n",
    "\n",
    "            # Find peaks in the FFT to detect the dominant frequency\n",
    "            peaks, _ = find_peaks(pixel_count_fft, height=np.max(pixel_count_fft))\n",
    "\n",
    "            if len(peaks) > 0 and pixel_count_fft[peaks[0]] > 4 * np.median(pixel_count_fft):\n",
    "                detected_freq = f_axis[peaks[0]]\n",
    "            else:\n",
    "                detected_freq = 0\n",
    "\n",
    "            # Update frequency history\n",
    "            freq_history.append(detected_freq)\n",
    "            if len(freq_history) > max_history_length:\n",
    "                freq_history.pop(0)\n",
    "\n",
    "            mean_freq = np.mean(freq_history)\n",
    "            std_freq = np.std(freq_history)\n",
    "\n",
    "            # Check if detected frequency is outside historical range\n",
    "            if abs(detected_freq - mean_freq) > (2 * std_freq + freq_th):\n",
    "                print(f\"Frequency {detected_freq:.2f} Hz deviates from mean {mean_freq:.2f} Hz with std {std_freq:.2f}. Switching back to Mode 1.\")\n",
    "                Mode = 1\n",
    "                tracker = cv2.TrackerMIL_create()  # Reinitialize the tracker if necessary\n",
    "                freq_history = []\n",
    "\n",
    "            # Display the tracking information\n",
    "            cv2.putText(frame, f'Pixels > 0: {int(non_zero_pixel_count)}', (x, y - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, f'Freq: {detected_freq:.2f} Hz', (x, y - 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, f'Mean Freq: {mean_freq:.2f} Hz', (x, y - 70), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        else:\n",
    "            Mode = 1\n",
    "            tracker = cv2.TrackerMIL_create()  # Reinitialize the tracker if necessary\n",
    "\n",
    "    # Show the original frame and the filtered HSV frame\n",
    "    cv2.imshow(\"Filtered Frame\", filtered_frame)\n",
    "    cv2.imshow(\"Preview\", mask)\n",
    "\n",
    "    # Handle keypress\n",
    "    k = cv2.waitKey(30)\n",
    "    if k == 27 or k == ord('q'):  # ESC or 'q' to quit\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T06:52:58.979783Z",
     "start_time": "2024-10-09T06:51:11.083321Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreview\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Handle keypress\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m27\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# ESC or 'q' to quit\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Open the video file (RTSP stream in your case)\n",
    "cap = cv2.VideoCapture(r\"rtsp://fgcam:admin@169.254.203.185:8554/1/unicast\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    cv2.imshow(\"Preview\", frame)\n",
    "\n",
    "    # Handle keypress\n",
    "    k = cv2.waitKey(30)\n",
    "    if k == 27 or k == ord('q'):  # ESC or 'q' to quit\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.ndimage import shift\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\thaim\\Videos\\LED - color change\\הקלטה - 50 מטר עם צבע כחול+ HSV שינוי פרמטרים.mp4\")\n",
    "\n",
    "#cap=cv2.VideoCapture(r\"C:\\Users\\user\\Videos\\vlc-record-2024-09-23-11h59m43s-Converting rtsp___fgcam_admin@169.254.118.8_8554_0_unicast-.mp4\")\n",
    "\n",
    "# PARAMS & DEFINITIONS\n",
    "img_counter = 0\n",
    "fps = 25\n",
    "calc_length = 60\n",
    "T = 0\n",
    "Led_freq = 4.4\n",
    "Box_size = 100  # Adjusted box size for better precision\n",
    "sBox_size = 20\n",
    "MAG=20\n",
    "freq_counter_th = 5\n",
    "\n",
    "freq_th = 0.25\n",
    "Mode = 1\n",
    "max_history_length = 30\n",
    "pixel_count_idx = 0\n",
    "P = []\n",
    "freq = []\n",
    "freq_history = []\n",
    "frame_count = 0  # To track how many frames we've processed so far\n",
    "\n",
    "# Counters\n",
    "scounter = 0\n",
    "tcounter = 0\n",
    "m2counter = 0\n",
    "\n",
    "# Get frame parameters\n",
    "frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Video writer setup (if needed for saving)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "\n",
    "# Calculate grid size\n",
    "WI = int(frameWidth / Box_size)\n",
    "HE = int(frameHeight / Box_size)\n",
    "sWI = int((Box_size+2*MAG)/ sBox_size)\n",
    "sHE = int((Box_size+2*MAG)/ sBox_size)\n",
    "\n",
    "# Initialize necessary buffers and counters\n",
    "pixel_count_buff = np.zeros(calc_length)\n",
    "freq_counter = np.zeros((HE, WI))\n",
    "fourier_buff = np.zeros((calc_length, HE, WI))\n",
    "sfourier_buff = np.zeros((calc_length, sHE, sWI))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of video or error reading frame.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize tracker\n",
    "tracker = cv2.TrackerMIL_create()\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    #print(Mode)\n",
    "    if not ret:\n",
    "        print(\"End of video or error reading frame.\")\n",
    "        break\n",
    "\n",
    "    # Increment the frame count\n",
    "    frame_count += 1\n",
    "\n",
    "    # Convert frame to grayscale\n",
    "    #img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    img = (0.5 * frame[:, :, 0] + 0.5 * frame[:, :, 2]).astype(\"uint8\")\n",
    "    #_, img = cv2.threshold(img, 254, 255, cv2.THRESH_TOZERO_INV)\n",
    "    #img=(img-np.min(img))/(np.max(img)-np.min(img))\n",
    "    #img=(255*img).astype(\"uint8\")\n",
    "    # Apply binary threshold\n",
    "    k = np.median(img) / np.std(img)\n",
    "    D_Th = np.average(img) + k * np.median(img)\n",
    "    D_Th=min(D_Th,245)\n",
    "    D_Th = max(D_Th, 180)\n",
    "\n",
    "    _, B2 = cv2.threshold(img, D_Th, 255, cv2.THRESH_BINARY)  # Lowered threshold for better detection\n",
    "    #print(D_Th)\n",
    "\n",
    "    # Apply dilation\n",
    "    #B3 = cv2.dilate(B2, np.ones((2, 2), np.uint8), iterations=2)  # Same dilation for noise reduction\n",
    "\n",
    "    # Store the sum of white pixels for frequency analysis\n",
    "    #freq.append(np.sum(B2))\n",
    "\n",
    "    # **STEP 3: Skip all processing until we have 60 frames**\n",
    "    if frame_count < calc_length:\n",
    "        # Update the buffer but skip FFT and image processing\n",
    "        for h in range(HE):\n",
    "            for w in range(WI):\n",
    "                b2 = B2[h * Box_size:h * Box_size + Box_size, w * Box_size:w * Box_size + Box_size]\n",
    "                fourier_buff[:, h, w] = np.roll(fourier_buff[:, h, w], -1)\n",
    "                fourier_buff[0, h, w] = np.sum(b2)\n",
    "\n",
    "        continue  # Skip to the next frame until we have 60 frames\n",
    "\n",
    "    # Once we have accumulated 60 frames, continue with regular processing\n",
    "    if Mode == 1:\n",
    "        # Loop through grid cells\n",
    "        for h in range(HE):\n",
    "            for w in range(WI):\n",
    "                # Get current block in the grid\n",
    "                b2 = B2[h * Box_size:h * Box_size + Box_size, w * Box_size:w * Box_size + Box_size]\n",
    "                #b3 = B3[h * Box_size:h * Box_size + Box_size, w * Box_size:w * Box_size + Box_size]\n",
    "\n",
    "                # Shift and update the Fourier buffer using np.roll\n",
    "                fourier_buff[:, h, w] = np.roll(fourier_buff[:, h, w], -1)\n",
    "                fourier_buff[0, h, w] = np.sum(b2)\n",
    "\n",
    "                # Subtract the mean and apply FFT\n",
    "                func = fourier_buff[:, h, w] - np.mean(fourier_buff[:, h, w])\n",
    "                fftx = np.abs(np.fft.rfft(func))[3:]  # Start from 3 to skip low frequencies\n",
    "                f_axis = np.linspace(0, fps / 2, len(fftx) + 3)[3:]\n",
    "\n",
    "                # Find peaks in the FFT\n",
    "                peaks, _ = find_peaks(fftx, height=np.max(fftx) * 0.5)  # Reduce peak sensitivity\n",
    "\n",
    "                # Determine the dominant frequency (if any)\n",
    "                if len(peaks) > 0 and fftx[peaks[0]] > 4 * np.median(fftx):\n",
    "                    T = f_axis[peaks[0]]\n",
    "                else:\n",
    "                    T = 0\n",
    "\n",
    "                # Draw rectangles around each grid cell\n",
    "                cv2.rectangle(frame, (w * Box_size, h * Box_size), (w * Box_size + Box_size, h * Box_size + Box_size),\n",
    "                              (0, 0, 255), 2)\n",
    "\n",
    "                # If frequency matches LED frequency\n",
    "                if np.abs(T - Led_freq) < freq_th:\n",
    "                    freq_counter[h, w] += 1\n",
    "                    if freq_counter[h, w] > freq_counter_th:\n",
    "                        # contours, _ = cv2.findContours(b3, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                        # if contours:\n",
    "                        # c = max(contours, key=cv2.contourArea)\n",
    "                        # top_point = (np.min(c[:, :, 0]) + w * Box_size, np.min(c[:, :, 1]) + h * Box_size)\n",
    "                        # bottom_point = (np.max(c[:, :, 0]) + w * Box_size, np.max(c[:, :, 1]) + h * Box_size)\n",
    "                        # bbox = (top_point[0], top_point[1], bottom_point[0] - top_point[0], bottom_point[1] - top_point[1])\n",
    "\n",
    "                        # Initialize the tracker\n",
    "                        # tracker.init(frame, bbox)\n",
    "                        top_point = (w * Box_size-MAG, h * Box_size-MAG)\n",
    "                        bottom_point = ((w + 1) * Box_size+MAG, (h + 1) * Box_size+MAG)\n",
    "                        Mode = 2\n",
    "                        freq_counter[h, w] = 0\n",
    "\n",
    "                        # BREAK OUT OF BOTH LOOPS ONCE TRACKING STARTS\n",
    "                        break  # Break out of inner loop\n",
    "            if Mode == 2:\n",
    "                break  # Break out of outer loop\n",
    "    elif Mode == 2:\n",
    "\n",
    "        TW = 1300\n",
    "        TH = 1300\n",
    "        BW = 0\n",
    "        BH = 0\n",
    "        start_h = top_point[1]\n",
    "        start_w = top_point[0]\n",
    "        for sh in range(sHE):\n",
    "\n",
    "            for sw in range(sWI):\n",
    "\n",
    "                b2 = B2[start_h + sh * sBox_size:start_h + sh * sBox_size + sBox_size,\n",
    "                     start_w + sw * sBox_size:start_w + sw * sBox_size + sBox_size]\n",
    "                #b3 = B3[start_h + sh * sBox_size:start_h + sh * sBox_size + sBox_size,\n",
    "                #     start_w + sw * sBox_size:start_w + sw * sBox_size + sBox_size]\n",
    "                img2 = frame[start_h + sh * sBox_size:start_h + sh * sBox_size + sBox_size,\n",
    "                       start_w + sw * sBox_size:start_w + sw * sBox_size + sBox_size]\n",
    "                z = shift(sfourier_buff[:, sw, sh], 1)\n",
    "                z[0] = np.sum(b2)\n",
    "                sfourier_buff[:, sw, sh] = z\n",
    "\n",
    "                func = sfourier_buff[:, sw, sh] - np.average(sfourier_buff[:, sw, sh])\n",
    "                fftx = np.abs(np.fft.rfft(sfourier_buff[:, sw, sh]))[1:]\n",
    "                f_axis = np.linspace(0, fps / 2, int(0.5 * len(sfourier_buff[:, sw, sh])) + 1)[1:]\n",
    "                peaks, _ = find_peaks(fftx, height=np.max(fftx))\n",
    "                cv2.rectangle(frame, (start_w + sw * sBox_size, start_h + sh * sBox_size),\n",
    "                              (start_w + sw * sBox_size + sBox_size, start_h + sh * sBox_size + sBox_size), (0, 0, 255),2)\n",
    "\n",
    "                # if fourier_thresh<fourier_TH:\n",
    "                if len(peaks) > 0 and fftx[peaks[0]] > 4 * np.median(fftx):\n",
    "                    sT = f_axis[peaks][0]\n",
    "                else:\n",
    "                    sT = 0\n",
    "\n",
    "                if np.abs(sT - Led_freq) < freq_th:  # fftx[int(calc_length/fps)]>fourier_thresh:\n",
    "                    stop_point = (sw * sBox_size + start_w, sh * sBox_size + start_h)\n",
    "                    sbottom_point = ((sw + 1) * sBox_size + start_w, (sh + 1) * sBox_size + start_h)\n",
    "\n",
    "                    TW = min(TW, stop_point[0])\n",
    "                    TH = min(TH, stop_point[1])\n",
    "                    BW = max(BW, sbottom_point[0])\n",
    "                    BH = max(BH, sbottom_point[1])\n",
    "\n",
    "                    #cv2.rectangle(frame, sbottom_point, stop_point, (0, 0, 255), 2)\n",
    "\n",
    "                    cv2.rectangle(frame, (TW, TH), (BW, BH), (0, 255, 0), 2)\n",
    "                    scounter = scounter + 1\n",
    "\n",
    "                    if (scounter > 10) and (stop_point[0] + sBox_size < frameWidth) and (\n",
    "                            stop_point[1] + sBox_size < frameHeight):\n",
    "                        Mode = 3\n",
    "                        bbox = (stop_point[0], stop_point[1], sbottom_point[0] - stop_point[0],\n",
    "                                sbottom_point[1] - stop_point[1])\n",
    "                        tracker.init(frame, bbox)\n",
    "                        scounter = 0\n",
    "                if (Mode == 3) or (Mode == 1):\n",
    "                    break\n",
    "\n",
    "        m2counter = m2counter + 1\n",
    "        cv2.putText(frame, str(m2counter), (start_w + sw * sBox_size, start_h + sh * sBox_size),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "        if (m2counter) > 1.5 * calc_length:\n",
    "            Mode = 1\n",
    "            m2counter = 0\n",
    "\n",
    "        # if (Mode==3) or (Mode==1):\n",
    "        #    break\n",
    "\n",
    "\n",
    "    elif Mode == 3:\n",
    "        # Tracking mode\n",
    "        print(bbox)\n",
    "        success, bbox = tracker.update(frame)\n",
    "        if success:\n",
    "            x, y, w, h = [int(v) for v in bbox]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            # Count non-zero pixels inside the current bounding box\n",
    "            roi_binary = B2[y:y + h, x:x + w]\n",
    "            non_zero_pixel_count = np.sum(roi_binary)\n",
    "\n",
    "            # Update pixel count buffer (shift and update)\n",
    "            pixel_count_buff = np.roll(pixel_count_buff, -1)\n",
    "            pixel_count_buff[-1] = non_zero_pixel_count\n",
    "            tcounter = tcounter + 1\n",
    "            if tcounter > calc_length:\n",
    "\n",
    "                # Perform FFT on the pixel count buffer to detect object frequency\n",
    "                pixel_count_fft = np.abs(np.fft.rfft(pixel_count_buff - np.mean(pixel_count_buff)))[1:]\n",
    "                f_axis = np.linspace(0, fps / 2, len(pixel_count_fft) + 1)[1:]\n",
    "\n",
    "                # Find peaks in the FFT to detect the dominant frequency\n",
    "                peaks, _ = find_peaks(pixel_count_fft, height=np.max(pixel_count_fft))\n",
    "\n",
    "                if len(peaks) > 0 and pixel_count_fft[peaks[0]] > 1.5 * np.median(pixel_count_fft):\n",
    "                    detected_freq = f_axis[peaks[0]]\n",
    "                else:\n",
    "                    detected_freq = 0\n",
    "\n",
    "                # # Update frequency history\n",
    "                # freq_history.append(detected_freq)\n",
    "                # if len(freq_history) > max_history_length:\n",
    "                #     freq_history.pop(0)\n",
    "\n",
    "                # mean_freq = np.mean(freq_history)\n",
    "                # std_freq = np.std(freq_history)\n",
    "\n",
    "                # Check if detected frequency is outside historical range\n",
    "                if abs(detected_freq - Led_freq) > freq_th:\n",
    "                    #print(\n",
    "                    #    f\"Frequency {detected_freq:.2f} Hz deviates from mean {mean_freq:.2f} Hz with std {std_freq:.2f}. Switching back to Mode 1.\")\n",
    "                    Mode = 1\n",
    "                    # tracker = cv2.TrackerMIL_create()  # Reinitialize the tracker if necessary\n",
    "                    freq_history = []\n",
    "                    tcounter = 0\n",
    "                else:\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, f'Freq: {detected_freq:.2f} Hz', (x, y - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                                (255, 255, 255), 2)\n",
    "\n",
    "            # Display the tracking information\n",
    "                #cv2.putText(frame, f'Pixels > 0: {int(non_zero_pixel_count)}', (x, y - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                #        (255, 255, 255), 2)\n",
    "\n",
    "            # cv2.putText(frame, f'Mean Freq: {mean_freq:.2f} Hz', (x, y - 70), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        else:\n",
    "            Mode = 1\n",
    "            # tracker = cv2.TrackerMIL_create()\n",
    "\n",
    "    # Show the processed binary image (B3) or frame\n",
    "    C2 = cv2.cvtColor(B2, cv2.COLOR_GRAY2RGB)\n",
    "    FRAMES = np.concatenate((frame, C2), axis=1)\n",
    "    prv = cv2.resize(FRAMES, (1280, 960))\n",
    "    cv2.imshow(\"preview\", frame)  # Or cv2.imshow(\"preview\", frame) if you want the full frame\n",
    "\n",
    "    # Handle keypress\n",
    "    k = cv2.waitKey(30)\n",
    "    if k == 27 or k == ord('q'):  # ESC or 'q' to quit\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
